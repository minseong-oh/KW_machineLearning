2025-06-08 18:08:02,801:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-08 18:08:02,801:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-08 18:08:02,801:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-08 18:08:02,801:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-08 18:10:22,151:INFO:PyCaret ClassificationExperiment
2025-06-08 18:10:22,151:INFO:Logging name: clf-default-name
2025-06-08 18:10:22,151:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-08 18:10:22,151:INFO:version 3.3.2
2025-06-08 18:10:22,151:INFO:Initializing setup()
2025-06-08 18:10:22,151:INFO:self.USI: 4afc
2025-06-08 18:10:22,151:INFO:self._variable_keys: {'data', 'gpu_n_jobs_param', 'pipeline', 'y_train', 'fold_generator', 'USI', '_ml_usecase', 'X', 'y_test', 'n_jobs_param', 'idx', 'exp_name_log', 'memory', 'html_param', 'gpu_param', 'X_test', 'fold_shuffle_param', 'exp_id', 'y', 'seed', 'fold_groups_param', '_available_plots', 'target_param', 'fix_imbalance', 'is_multiclass', 'log_plots_param', 'logging_param', 'X_train'}
2025-06-08 18:10:22,151:INFO:Checking environment
2025-06-08 18:10:22,151:INFO:python_version: 3.10.16
2025-06-08 18:10:22,151:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-08 18:10:22,151:INFO:machine: AMD64
2025-06-08 18:10:22,151:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-08 18:10:22,156:INFO:Memory: svmem(total=33885192192, available=19223142400, percent=43.3, used=14662049792, free=19223142400)
2025-06-08 18:10:22,156:INFO:Physical Core: 14
2025-06-08 18:10:22,156:INFO:Logical Core: 18
2025-06-08 18:10:22,156:INFO:Checking libraries
2025-06-08 18:10:22,156:INFO:System:
2025-06-08 18:10:22,156:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-08 18:10:22,156:INFO:executable: C:\Users\omslu\anaconda3\envs\pycaret_env\python.exe
2025-06-08 18:10:22,156:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-08 18:10:22,156:INFO:PyCaret required dependencies:
2025-06-08 18:10:22,188:INFO:                 pip: 25.1
2025-06-08 18:10:22,188:INFO:          setuptools: 78.1.1
2025-06-08 18:10:22,188:INFO:             pycaret: 3.3.2
2025-06-08 18:10:22,188:INFO:             IPython: 8.37.0
2025-06-08 18:10:22,188:INFO:          ipywidgets: 8.1.7
2025-06-08 18:10:22,188:INFO:                tqdm: 4.67.1
2025-06-08 18:10:22,188:INFO:               numpy: 1.26.4
2025-06-08 18:10:22,188:INFO:              pandas: 2.1.4
2025-06-08 18:10:22,188:INFO:              jinja2: 3.1.6
2025-06-08 18:10:22,188:INFO:               scipy: 1.11.4
2025-06-08 18:10:22,190:INFO:              joblib: 1.3.2
2025-06-08 18:10:22,190:INFO:             sklearn: 1.4.2
2025-06-08 18:10:22,190:INFO:                pyod: 2.0.5
2025-06-08 18:10:22,190:INFO:            imblearn: 0.13.0
2025-06-08 18:10:22,190:INFO:   category_encoders: 2.7.0
2025-06-08 18:10:22,190:INFO:            lightgbm: 4.6.0
2025-06-08 18:10:22,190:INFO:               numba: 0.61.2
2025-06-08 18:10:22,190:INFO:            requests: 2.32.3
2025-06-08 18:10:22,190:INFO:          matplotlib: 3.7.5
2025-06-08 18:10:22,190:INFO:          scikitplot: 0.3.7
2025-06-08 18:10:22,190:INFO:         yellowbrick: 1.5
2025-06-08 18:10:22,190:INFO:              plotly: 5.24.1
2025-06-08 18:10:22,190:INFO:    plotly-resampler: Not installed
2025-06-08 18:10:22,190:INFO:             kaleido: 0.2.1
2025-06-08 18:10:22,190:INFO:           schemdraw: 0.15
2025-06-08 18:10:22,190:INFO:         statsmodels: 0.14.4
2025-06-08 18:10:22,190:INFO:              sktime: 0.26.0
2025-06-08 18:10:22,190:INFO:               tbats: 1.1.3
2025-06-08 18:10:22,190:INFO:            pmdarima: 2.0.4
2025-06-08 18:10:22,190:INFO:              psutil: 7.0.0
2025-06-08 18:10:22,190:INFO:          markupsafe: 3.0.2
2025-06-08 18:10:22,190:INFO:             pickle5: Not installed
2025-06-08 18:10:22,190:INFO:         cloudpickle: 3.1.1
2025-06-08 18:10:22,190:INFO:         deprecation: 2.1.0
2025-06-08 18:10:22,190:INFO:              xxhash: 3.5.0
2025-06-08 18:10:22,190:INFO:           wurlitzer: Not installed
2025-06-08 18:10:22,190:INFO:PyCaret optional dependencies:
2025-06-08 18:10:22,326:INFO:                shap: 0.47.2
2025-06-08 18:10:22,326:INFO:           interpret: Not installed
2025-06-08 18:10:22,326:INFO:                umap: Not installed
2025-06-08 18:10:22,328:INFO:     ydata_profiling: Not installed
2025-06-08 18:10:22,328:INFO:  explainerdashboard: Not installed
2025-06-08 18:10:22,328:INFO:             autoviz: Not installed
2025-06-08 18:10:22,328:INFO:           fairlearn: Not installed
2025-06-08 18:10:22,328:INFO:          deepchecks: Not installed
2025-06-08 18:10:22,328:INFO:             xgboost: 3.0.2
2025-06-08 18:10:22,328:INFO:            catboost: Not installed
2025-06-08 18:10:22,328:INFO:              kmodes: Not installed
2025-06-08 18:10:22,328:INFO:             mlxtend: Not installed
2025-06-08 18:10:22,328:INFO:       statsforecast: Not installed
2025-06-08 18:10:22,328:INFO:        tune_sklearn: Not installed
2025-06-08 18:10:22,328:INFO:                 ray: Not installed
2025-06-08 18:10:22,328:INFO:            hyperopt: Not installed
2025-06-08 18:10:22,328:INFO:              optuna: Not installed
2025-06-08 18:10:22,330:INFO:               skopt: Not installed
2025-06-08 18:10:22,330:INFO:              mlflow: Not installed
2025-06-08 18:10:22,330:INFO:              gradio: Not installed
2025-06-08 18:10:22,330:INFO:             fastapi: Not installed
2025-06-08 18:10:22,330:INFO:             uvicorn: Not installed
2025-06-08 18:10:22,330:INFO:              m2cgen: Not installed
2025-06-08 18:10:22,330:INFO:           evidently: Not installed
2025-06-08 18:10:22,330:INFO:               fugue: Not installed
2025-06-08 18:10:22,330:INFO:           streamlit: Not installed
2025-06-08 18:10:22,330:INFO:             prophet: Not installed
2025-06-08 18:10:22,330:INFO:None
2025-06-08 18:10:22,330:INFO:Set up data.
2025-06-08 18:10:22,347:INFO:Set up folding strategy.
2025-06-08 18:10:22,349:INFO:Set up train/test split.
2025-06-08 18:10:34,177:INFO:PyCaret ClassificationExperiment
2025-06-08 18:10:34,177:INFO:Logging name: clf-default-name
2025-06-08 18:10:34,177:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-08 18:10:34,177:INFO:version 3.3.2
2025-06-08 18:10:34,177:INFO:Initializing setup()
2025-06-08 18:10:34,178:INFO:self.USI: 2fe8
2025-06-08 18:10:34,178:INFO:self._variable_keys: {'data', 'gpu_n_jobs_param', 'pipeline', 'y_train', 'fold_generator', 'USI', '_ml_usecase', 'X', 'y_test', 'n_jobs_param', 'idx', 'exp_name_log', 'memory', 'html_param', 'gpu_param', 'X_test', 'fold_shuffle_param', 'exp_id', 'y', 'seed', 'fold_groups_param', '_available_plots', 'target_param', 'fix_imbalance', 'is_multiclass', 'log_plots_param', 'logging_param', 'X_train'}
2025-06-08 18:10:34,178:INFO:Checking environment
2025-06-08 18:10:34,178:INFO:python_version: 3.10.16
2025-06-08 18:10:34,178:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-08 18:10:34,178:INFO:machine: AMD64
2025-06-08 18:10:34,178:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-08 18:10:34,182:INFO:Memory: svmem(total=33885192192, available=18887593984, percent=44.3, used=14997598208, free=18887593984)
2025-06-08 18:10:34,183:INFO:Physical Core: 14
2025-06-08 18:10:34,183:INFO:Logical Core: 18
2025-06-08 18:10:34,183:INFO:Checking libraries
2025-06-08 18:10:34,183:INFO:System:
2025-06-08 18:10:34,183:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-08 18:10:34,183:INFO:executable: C:\Users\omslu\anaconda3\envs\pycaret_env\python.exe
2025-06-08 18:10:34,183:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-08 18:10:34,183:INFO:PyCaret required dependencies:
2025-06-08 18:10:34,183:INFO:                 pip: 25.1
2025-06-08 18:10:34,183:INFO:          setuptools: 78.1.1
2025-06-08 18:10:34,183:INFO:             pycaret: 3.3.2
2025-06-08 18:10:34,183:INFO:             IPython: 8.37.0
2025-06-08 18:10:34,183:INFO:          ipywidgets: 8.1.7
2025-06-08 18:10:34,183:INFO:                tqdm: 4.67.1
2025-06-08 18:10:34,183:INFO:               numpy: 1.26.4
2025-06-08 18:10:34,183:INFO:              pandas: 2.1.4
2025-06-08 18:10:34,183:INFO:              jinja2: 3.1.6
2025-06-08 18:10:34,183:INFO:               scipy: 1.11.4
2025-06-08 18:10:34,184:INFO:              joblib: 1.3.2
2025-06-08 18:10:34,184:INFO:             sklearn: 1.4.2
2025-06-08 18:10:34,184:INFO:                pyod: 2.0.5
2025-06-08 18:10:34,184:INFO:            imblearn: 0.13.0
2025-06-08 18:10:34,184:INFO:   category_encoders: 2.7.0
2025-06-08 18:10:34,184:INFO:            lightgbm: 4.6.0
2025-06-08 18:10:34,184:INFO:               numba: 0.61.2
2025-06-08 18:10:34,184:INFO:            requests: 2.32.3
2025-06-08 18:10:34,184:INFO:          matplotlib: 3.7.5
2025-06-08 18:10:34,184:INFO:          scikitplot: 0.3.7
2025-06-08 18:10:34,184:INFO:         yellowbrick: 1.5
2025-06-08 18:10:34,184:INFO:              plotly: 5.24.1
2025-06-08 18:10:34,184:INFO:    plotly-resampler: Not installed
2025-06-08 18:10:34,184:INFO:             kaleido: 0.2.1
2025-06-08 18:10:34,184:INFO:           schemdraw: 0.15
2025-06-08 18:10:34,184:INFO:         statsmodels: 0.14.4
2025-06-08 18:10:34,184:INFO:              sktime: 0.26.0
2025-06-08 18:10:34,184:INFO:               tbats: 1.1.3
2025-06-08 18:10:34,184:INFO:            pmdarima: 2.0.4
2025-06-08 18:10:34,184:INFO:              psutil: 7.0.0
2025-06-08 18:10:34,184:INFO:          markupsafe: 3.0.2
2025-06-08 18:10:34,184:INFO:             pickle5: Not installed
2025-06-08 18:10:34,184:INFO:         cloudpickle: 3.1.1
2025-06-08 18:10:34,184:INFO:         deprecation: 2.1.0
2025-06-08 18:10:34,184:INFO:              xxhash: 3.5.0
2025-06-08 18:10:34,184:INFO:           wurlitzer: Not installed
2025-06-08 18:10:34,184:INFO:PyCaret optional dependencies:
2025-06-08 18:10:34,184:INFO:                shap: 0.47.2
2025-06-08 18:10:34,184:INFO:           interpret: Not installed
2025-06-08 18:10:34,184:INFO:                umap: Not installed
2025-06-08 18:10:34,184:INFO:     ydata_profiling: Not installed
2025-06-08 18:10:34,184:INFO:  explainerdashboard: Not installed
2025-06-08 18:10:34,184:INFO:             autoviz: Not installed
2025-06-08 18:10:34,184:INFO:           fairlearn: Not installed
2025-06-08 18:10:34,184:INFO:          deepchecks: Not installed
2025-06-08 18:10:34,185:INFO:             xgboost: 3.0.2
2025-06-08 18:10:34,185:INFO:            catboost: Not installed
2025-06-08 18:10:34,185:INFO:              kmodes: Not installed
2025-06-08 18:10:34,185:INFO:             mlxtend: Not installed
2025-06-08 18:10:34,185:INFO:       statsforecast: Not installed
2025-06-08 18:10:34,185:INFO:        tune_sklearn: Not installed
2025-06-08 18:10:34,185:INFO:                 ray: Not installed
2025-06-08 18:10:34,185:INFO:            hyperopt: Not installed
2025-06-08 18:10:34,185:INFO:              optuna: Not installed
2025-06-08 18:10:34,185:INFO:               skopt: Not installed
2025-06-08 18:10:34,185:INFO:              mlflow: Not installed
2025-06-08 18:10:34,185:INFO:              gradio: Not installed
2025-06-08 18:10:34,185:INFO:             fastapi: Not installed
2025-06-08 18:10:34,185:INFO:             uvicorn: Not installed
2025-06-08 18:10:34,185:INFO:              m2cgen: Not installed
2025-06-08 18:10:34,185:INFO:           evidently: Not installed
2025-06-08 18:10:34,185:INFO:               fugue: Not installed
2025-06-08 18:10:34,185:INFO:           streamlit: Not installed
2025-06-08 18:10:34,185:INFO:             prophet: Not installed
2025-06-08 18:10:34,185:INFO:None
2025-06-08 18:10:34,185:INFO:Set up data.
2025-06-08 18:10:34,191:INFO:Set up folding strategy.
2025-06-08 18:10:34,192:INFO:Set up train/test split.
2025-06-08 18:11:01,783:INFO:PyCaret ClassificationExperiment
2025-06-08 18:11:01,783:INFO:Logging name: clf-default-name
2025-06-08 18:11:01,783:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-08 18:11:01,783:INFO:version 3.3.2
2025-06-08 18:11:01,783:INFO:Initializing setup()
2025-06-08 18:11:01,783:INFO:self.USI: b991
2025-06-08 18:11:01,783:INFO:self._variable_keys: {'data', 'gpu_n_jobs_param', 'pipeline', 'y_train', 'fold_generator', 'USI', '_ml_usecase', 'X', 'y_test', 'n_jobs_param', 'idx', 'exp_name_log', 'memory', 'html_param', 'gpu_param', 'X_test', 'fold_shuffle_param', 'exp_id', 'y', 'seed', 'fold_groups_param', '_available_plots', 'target_param', 'fix_imbalance', 'is_multiclass', 'log_plots_param', 'logging_param', 'X_train'}
2025-06-08 18:11:01,783:INFO:Checking environment
2025-06-08 18:11:01,783:INFO:python_version: 3.10.16
2025-06-08 18:11:01,783:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-08 18:11:01,783:INFO:machine: AMD64
2025-06-08 18:11:01,784:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-08 18:11:01,787:INFO:Memory: svmem(total=33885192192, available=18903953408, percent=44.2, used=14981238784, free=18903953408)
2025-06-08 18:11:01,787:INFO:Physical Core: 14
2025-06-08 18:11:01,787:INFO:Logical Core: 18
2025-06-08 18:11:01,787:INFO:Checking libraries
2025-06-08 18:11:01,787:INFO:System:
2025-06-08 18:11:01,787:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-08 18:11:01,787:INFO:executable: C:\Users\omslu\anaconda3\envs\pycaret_env\python.exe
2025-06-08 18:11:01,787:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-08 18:11:01,787:INFO:PyCaret required dependencies:
2025-06-08 18:11:01,787:INFO:                 pip: 25.1
2025-06-08 18:11:01,787:INFO:          setuptools: 78.1.1
2025-06-08 18:11:01,787:INFO:             pycaret: 3.3.2
2025-06-08 18:11:01,787:INFO:             IPython: 8.37.0
2025-06-08 18:11:01,787:INFO:          ipywidgets: 8.1.7
2025-06-08 18:11:01,787:INFO:                tqdm: 4.67.1
2025-06-08 18:11:01,787:INFO:               numpy: 1.26.4
2025-06-08 18:11:01,787:INFO:              pandas: 2.1.4
2025-06-08 18:11:01,787:INFO:              jinja2: 3.1.6
2025-06-08 18:11:01,787:INFO:               scipy: 1.11.4
2025-06-08 18:11:01,787:INFO:              joblib: 1.3.2
2025-06-08 18:11:01,789:INFO:             sklearn: 1.4.2
2025-06-08 18:11:01,789:INFO:                pyod: 2.0.5
2025-06-08 18:11:01,789:INFO:            imblearn: 0.13.0
2025-06-08 18:11:01,789:INFO:   category_encoders: 2.7.0
2025-06-08 18:11:01,789:INFO:            lightgbm: 4.6.0
2025-06-08 18:11:01,789:INFO:               numba: 0.61.2
2025-06-08 18:11:01,789:INFO:            requests: 2.32.3
2025-06-08 18:11:01,789:INFO:          matplotlib: 3.7.5
2025-06-08 18:11:01,789:INFO:          scikitplot: 0.3.7
2025-06-08 18:11:01,789:INFO:         yellowbrick: 1.5
2025-06-08 18:11:01,789:INFO:              plotly: 5.24.1
2025-06-08 18:11:01,789:INFO:    plotly-resampler: Not installed
2025-06-08 18:11:01,789:INFO:             kaleido: 0.2.1
2025-06-08 18:11:01,789:INFO:           schemdraw: 0.15
2025-06-08 18:11:01,789:INFO:         statsmodels: 0.14.4
2025-06-08 18:11:01,789:INFO:              sktime: 0.26.0
2025-06-08 18:11:01,789:INFO:               tbats: 1.1.3
2025-06-08 18:11:01,789:INFO:            pmdarima: 2.0.4
2025-06-08 18:11:01,789:INFO:              psutil: 7.0.0
2025-06-08 18:11:01,789:INFO:          markupsafe: 3.0.2
2025-06-08 18:11:01,789:INFO:             pickle5: Not installed
2025-06-08 18:11:01,790:INFO:         cloudpickle: 3.1.1
2025-06-08 18:11:01,790:INFO:         deprecation: 2.1.0
2025-06-08 18:11:01,790:INFO:              xxhash: 3.5.0
2025-06-08 18:11:01,790:INFO:           wurlitzer: Not installed
2025-06-08 18:11:01,790:INFO:PyCaret optional dependencies:
2025-06-08 18:11:01,790:INFO:                shap: 0.47.2
2025-06-08 18:11:01,790:INFO:           interpret: Not installed
2025-06-08 18:11:01,790:INFO:                umap: Not installed
2025-06-08 18:11:01,790:INFO:     ydata_profiling: Not installed
2025-06-08 18:11:01,790:INFO:  explainerdashboard: Not installed
2025-06-08 18:11:01,790:INFO:             autoviz: Not installed
2025-06-08 18:11:01,790:INFO:           fairlearn: Not installed
2025-06-08 18:11:01,790:INFO:          deepchecks: Not installed
2025-06-08 18:11:01,790:INFO:             xgboost: 3.0.2
2025-06-08 18:11:01,790:INFO:            catboost: Not installed
2025-06-08 18:11:01,790:INFO:              kmodes: Not installed
2025-06-08 18:11:01,790:INFO:             mlxtend: Not installed
2025-06-08 18:11:01,790:INFO:       statsforecast: Not installed
2025-06-08 18:11:01,790:INFO:        tune_sklearn: Not installed
2025-06-08 18:11:01,790:INFO:                 ray: Not installed
2025-06-08 18:11:01,790:INFO:            hyperopt: Not installed
2025-06-08 18:11:01,790:INFO:              optuna: Not installed
2025-06-08 18:11:01,790:INFO:               skopt: Not installed
2025-06-08 18:11:01,790:INFO:              mlflow: Not installed
2025-06-08 18:11:01,790:INFO:              gradio: Not installed
2025-06-08 18:11:01,790:INFO:             fastapi: Not installed
2025-06-08 18:11:01,790:INFO:             uvicorn: Not installed
2025-06-08 18:11:01,790:INFO:              m2cgen: Not installed
2025-06-08 18:11:01,790:INFO:           evidently: Not installed
2025-06-08 18:11:01,790:INFO:               fugue: Not installed
2025-06-08 18:11:01,790:INFO:           streamlit: Not installed
2025-06-08 18:11:01,790:INFO:             prophet: Not installed
2025-06-08 18:11:01,790:INFO:None
2025-06-08 18:11:01,791:INFO:Set up data.
2025-06-08 18:11:01,796:INFO:Set up folding strategy.
2025-06-08 18:11:01,796:INFO:Set up train/test split.
2025-06-08 18:12:02,385:INFO:PyCaret ClassificationExperiment
2025-06-08 18:12:02,385:INFO:Logging name: clf-default-name
2025-06-08 18:12:02,386:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-08 18:12:02,386:INFO:version 3.3.2
2025-06-08 18:12:02,386:INFO:Initializing setup()
2025-06-08 18:12:02,386:INFO:self.USI: d5ac
2025-06-08 18:12:02,386:INFO:self._variable_keys: {'data', 'gpu_n_jobs_param', 'pipeline', 'y_train', 'fold_generator', 'USI', '_ml_usecase', 'X', 'y_test', 'n_jobs_param', 'idx', 'exp_name_log', 'memory', 'html_param', 'gpu_param', 'X_test', 'fold_shuffle_param', 'exp_id', 'y', 'seed', 'fold_groups_param', '_available_plots', 'target_param', 'fix_imbalance', 'is_multiclass', 'log_plots_param', 'logging_param', 'X_train'}
2025-06-08 18:12:02,386:INFO:Checking environment
2025-06-08 18:12:02,386:INFO:python_version: 3.10.16
2025-06-08 18:12:02,386:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-08 18:12:02,386:INFO:machine: AMD64
2025-06-08 18:12:02,386:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-08 18:12:02,390:INFO:Memory: svmem(total=33885192192, available=18941636608, percent=44.1, used=14943555584, free=18941636608)
2025-06-08 18:12:02,390:INFO:Physical Core: 14
2025-06-08 18:12:02,390:INFO:Logical Core: 18
2025-06-08 18:12:02,390:INFO:Checking libraries
2025-06-08 18:12:02,390:INFO:System:
2025-06-08 18:12:02,391:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-08 18:12:02,391:INFO:executable: C:\Users\omslu\anaconda3\envs\pycaret_env\python.exe
2025-06-08 18:12:02,391:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-08 18:12:02,391:INFO:PyCaret required dependencies:
2025-06-08 18:12:02,391:INFO:                 pip: 25.1
2025-06-08 18:12:02,391:INFO:          setuptools: 78.1.1
2025-06-08 18:12:02,391:INFO:             pycaret: 3.3.2
2025-06-08 18:12:02,391:INFO:             IPython: 8.37.0
2025-06-08 18:12:02,391:INFO:          ipywidgets: 8.1.7
2025-06-08 18:12:02,391:INFO:                tqdm: 4.67.1
2025-06-08 18:12:02,391:INFO:               numpy: 1.26.4
2025-06-08 18:12:02,391:INFO:              pandas: 2.1.4
2025-06-08 18:12:02,391:INFO:              jinja2: 3.1.6
2025-06-08 18:12:02,391:INFO:               scipy: 1.11.4
2025-06-08 18:12:02,391:INFO:              joblib: 1.3.2
2025-06-08 18:12:02,391:INFO:             sklearn: 1.4.2
2025-06-08 18:12:02,391:INFO:                pyod: 2.0.5
2025-06-08 18:12:02,391:INFO:            imblearn: 0.13.0
2025-06-08 18:12:02,391:INFO:   category_encoders: 2.7.0
2025-06-08 18:12:02,391:INFO:            lightgbm: 4.6.0
2025-06-08 18:12:02,391:INFO:               numba: 0.61.2
2025-06-08 18:12:02,391:INFO:            requests: 2.32.3
2025-06-08 18:12:02,391:INFO:          matplotlib: 3.7.5
2025-06-08 18:12:02,391:INFO:          scikitplot: 0.3.7
2025-06-08 18:12:02,391:INFO:         yellowbrick: 1.5
2025-06-08 18:12:02,391:INFO:              plotly: 5.24.1
2025-06-08 18:12:02,391:INFO:    plotly-resampler: Not installed
2025-06-08 18:12:02,391:INFO:             kaleido: 0.2.1
2025-06-08 18:12:02,391:INFO:           schemdraw: 0.15
2025-06-08 18:12:02,391:INFO:         statsmodels: 0.14.4
2025-06-08 18:12:02,393:INFO:              sktime: 0.26.0
2025-06-08 18:12:02,393:INFO:               tbats: 1.1.3
2025-06-08 18:12:02,393:INFO:            pmdarima: 2.0.4
2025-06-08 18:12:02,393:INFO:              psutil: 7.0.0
2025-06-08 18:12:02,393:INFO:          markupsafe: 3.0.2
2025-06-08 18:12:02,393:INFO:             pickle5: Not installed
2025-06-08 18:12:02,393:INFO:         cloudpickle: 3.1.1
2025-06-08 18:12:02,393:INFO:         deprecation: 2.1.0
2025-06-08 18:12:02,393:INFO:              xxhash: 3.5.0
2025-06-08 18:12:02,393:INFO:           wurlitzer: Not installed
2025-06-08 18:12:02,393:INFO:PyCaret optional dependencies:
2025-06-08 18:12:02,393:INFO:                shap: 0.47.2
2025-06-08 18:12:02,393:INFO:           interpret: Not installed
2025-06-08 18:12:02,393:INFO:                umap: Not installed
2025-06-08 18:12:02,393:INFO:     ydata_profiling: Not installed
2025-06-08 18:12:02,393:INFO:  explainerdashboard: Not installed
2025-06-08 18:12:02,393:INFO:             autoviz: Not installed
2025-06-08 18:12:02,393:INFO:           fairlearn: Not installed
2025-06-08 18:12:02,393:INFO:          deepchecks: Not installed
2025-06-08 18:12:02,393:INFO:             xgboost: 3.0.2
2025-06-08 18:12:02,393:INFO:            catboost: Not installed
2025-06-08 18:12:02,393:INFO:              kmodes: Not installed
2025-06-08 18:12:02,393:INFO:             mlxtend: Not installed
2025-06-08 18:12:02,393:INFO:       statsforecast: Not installed
2025-06-08 18:12:02,393:INFO:        tune_sklearn: Not installed
2025-06-08 18:12:02,393:INFO:                 ray: Not installed
2025-06-08 18:12:02,393:INFO:            hyperopt: Not installed
2025-06-08 18:12:02,393:INFO:              optuna: Not installed
2025-06-08 18:12:02,393:INFO:               skopt: Not installed
2025-06-08 18:12:02,393:INFO:              mlflow: Not installed
2025-06-08 18:12:02,393:INFO:              gradio: Not installed
2025-06-08 18:12:02,393:INFO:             fastapi: Not installed
2025-06-08 18:12:02,393:INFO:             uvicorn: Not installed
2025-06-08 18:12:02,393:INFO:              m2cgen: Not installed
2025-06-08 18:12:02,393:INFO:           evidently: Not installed
2025-06-08 18:12:02,393:INFO:               fugue: Not installed
2025-06-08 18:12:02,393:INFO:           streamlit: Not installed
2025-06-08 18:12:02,393:INFO:             prophet: Not installed
2025-06-08 18:12:02,393:INFO:None
2025-06-08 18:12:02,394:INFO:Set up data.
2025-06-08 18:12:02,404:INFO:Set up folding strategy.
2025-06-08 18:12:02,404:INFO:Set up train/test split.
2025-06-08 18:12:02,427:INFO:Set up index.
2025-06-08 18:12:02,442:INFO:Assigning column types.
2025-06-08 18:12:02,460:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-08 18:12:02,627:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-08 18:12:02,644:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-08 18:12:02,771:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-08 18:12:02,787:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-08 18:12:02,946:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-08 18:12:02,946:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-08 18:12:03,041:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-08 18:12:03,057:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-08 18:12:03,057:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-08 18:12:03,213:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-08 18:12:03,516:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-08 18:12:03,525:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-08 18:12:03,683:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-08 18:12:03,776:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-08 18:12:03,784:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-08 18:12:03,785:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-06-08 18:12:04,019:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-08 18:12:04,025:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-08 18:12:04,270:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-08 18:12:04,270:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-08 18:12:04,293:INFO:Preparing preprocessing pipeline...
2025-06-08 18:12:04,302:INFO:Set up simple imputation.
2025-06-08 18:12:04,440:INFO:Finished creating preprocessing pipeline.
2025-06-08 18:12:04,456:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\omslu\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['isSchool', 'rental_count',
                                             'return_count', 'apart',
                                             'closest_hospital_dist',
                                             'closest_convenience_dist',
                                             'closest_culture_dist', 'age_20s',
                                             'age_30s', 'age_40s',
                                             'crosswalk_count',
                                             'closest_cross_dist', 'bus_count'...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-06-08 18:12:04,458:INFO:Creating final display dataframe.
2025-06-08 18:12:04,733:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target        risk_level
2                   Target type        Multiclass
3           Original data shape        (7806, 28)
4        Transformed data shape        (7806, 28)
5   Transformed train set shape        (5464, 28)
6    Transformed test set shape        (2342, 28)
7              Numeric features                27
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              d5ac
2025-06-08 18:12:04,957:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-08 18:12:04,964:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-08 18:12:05,145:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-08 18:12:05,145:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-08 18:12:05,145:INFO:setup() successfully completed in 2.77s...............
2025-06-08 18:12:12,826:INFO:Initializing compare_models()
2025-06-08 18:12:12,826:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-06-08 18:12:12,826:INFO:Checking exceptions
2025-06-08 18:12:12,847:INFO:Preparing display monitor
2025-06-08 18:12:12,867:INFO:Initializing Logistic Regression
2025-06-08 18:12:12,867:INFO:Total runtime is 0.0 minutes
2025-06-08 18:12:12,867:INFO:SubProcess create_model() called ==================================
2025-06-08 18:12:12,867:INFO:Initializing create_model()
2025-06-08 18:12:12,867:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A6EBD22F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-08 18:12:12,867:INFO:Checking exceptions
2025-06-08 18:12:12,867:INFO:Importing libraries
2025-06-08 18:12:12,867:INFO:Copying training dataset
2025-06-08 18:12:12,895:INFO:Defining folds
2025-06-08 18:12:12,895:INFO:Declaring metric variables
2025-06-08 18:12:12,895:INFO:Importing untrained model
2025-06-08 18:12:12,911:INFO:Logistic Regression Imported successfully
2025-06-08 18:12:12,912:INFO:Starting cross validation
2025-06-08 18:12:12,926:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-08 18:12:21,263:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:21,392:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:21,397:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:21,400:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:21,422:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:21,450:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:12:21,577:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:21,591:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:12:21,598:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:21,629:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:21,693:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:21,726:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:21,740:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:12:21,759:INFO:Calculating mean and std
2025-06-08 18:12:21,763:INFO:Creating metrics dataframe
2025-06-08 18:12:21,768:INFO:Uploading results into container
2025-06-08 18:12:21,768:INFO:Uploading model into container now
2025-06-08 18:12:21,770:INFO:_master_model_container: 1
2025-06-08 18:12:21,770:INFO:_display_container: 2
2025-06-08 18:12:21,771:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-08 18:12:21,771:INFO:create_model() successfully completed......................................
2025-06-08 18:12:21,939:INFO:SubProcess create_model() end ==================================
2025-06-08 18:12:21,939:INFO:Creating metrics dataframe
2025-06-08 18:12:21,956:INFO:Initializing K Neighbors Classifier
2025-06-08 18:12:21,956:INFO:Total runtime is 0.15147292216618854 minutes
2025-06-08 18:12:21,968:INFO:SubProcess create_model() called ==================================
2025-06-08 18:12:21,968:INFO:Initializing create_model()
2025-06-08 18:12:21,968:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A6EBD22F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-08 18:12:21,972:INFO:Checking exceptions
2025-06-08 18:12:21,972:INFO:Importing libraries
2025-06-08 18:12:21,972:INFO:Copying training dataset
2025-06-08 18:12:22,004:INFO:Defining folds
2025-06-08 18:12:22,004:INFO:Declaring metric variables
2025-06-08 18:12:22,012:INFO:Importing untrained model
2025-06-08 18:12:22,019:INFO:K Neighbors Classifier Imported successfully
2025-06-08 18:12:22,034:INFO:Starting cross validation
2025-06-08 18:12:22,036:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-08 18:12:28,123:INFO:Calculating mean and std
2025-06-08 18:12:28,126:INFO:Creating metrics dataframe
2025-06-08 18:12:28,126:INFO:Uploading results into container
2025-06-08 18:12:28,126:INFO:Uploading model into container now
2025-06-08 18:12:28,126:INFO:_master_model_container: 2
2025-06-08 18:12:28,126:INFO:_display_container: 2
2025-06-08 18:12:28,126:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-08 18:12:28,126:INFO:create_model() successfully completed......................................
2025-06-08 18:12:28,324:INFO:SubProcess create_model() end ==================================
2025-06-08 18:12:28,324:INFO:Creating metrics dataframe
2025-06-08 18:12:28,341:INFO:Initializing Naive Bayes
2025-06-08 18:12:28,341:INFO:Total runtime is 0.2578975160916646 minutes
2025-06-08 18:12:28,347:INFO:SubProcess create_model() called ==================================
2025-06-08 18:12:28,347:INFO:Initializing create_model()
2025-06-08 18:12:28,347:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A6EBD22F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-08 18:12:28,347:INFO:Checking exceptions
2025-06-08 18:12:28,347:INFO:Importing libraries
2025-06-08 18:12:28,347:INFO:Copying training dataset
2025-06-08 18:12:28,376:INFO:Defining folds
2025-06-08 18:12:28,376:INFO:Declaring metric variables
2025-06-08 18:12:28,384:INFO:Importing untrained model
2025-06-08 18:12:28,391:INFO:Naive Bayes Imported successfully
2025-06-08 18:12:28,403:INFO:Starting cross validation
2025-06-08 18:12:28,405:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-08 18:12:28,553:INFO:Calculating mean and std
2025-06-08 18:12:28,553:INFO:Creating metrics dataframe
2025-06-08 18:12:28,559:INFO:Uploading results into container
2025-06-08 18:12:28,559:INFO:Uploading model into container now
2025-06-08 18:12:28,559:INFO:_master_model_container: 3
2025-06-08 18:12:28,559:INFO:_display_container: 2
2025-06-08 18:12:28,559:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-06-08 18:12:28,559:INFO:create_model() successfully completed......................................
2025-06-08 18:12:28,748:INFO:SubProcess create_model() end ==================================
2025-06-08 18:12:28,748:INFO:Creating metrics dataframe
2025-06-08 18:12:28,764:INFO:Initializing Decision Tree Classifier
2025-06-08 18:12:28,764:INFO:Total runtime is 0.2649453322092692 minutes
2025-06-08 18:12:28,771:INFO:SubProcess create_model() called ==================================
2025-06-08 18:12:28,772:INFO:Initializing create_model()
2025-06-08 18:12:28,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A6EBD22F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-08 18:12:28,772:INFO:Checking exceptions
2025-06-08 18:12:28,772:INFO:Importing libraries
2025-06-08 18:12:28,772:INFO:Copying training dataset
2025-06-08 18:12:28,798:INFO:Defining folds
2025-06-08 18:12:28,799:INFO:Declaring metric variables
2025-06-08 18:12:28,806:INFO:Importing untrained model
2025-06-08 18:12:28,813:INFO:Decision Tree Classifier Imported successfully
2025-06-08 18:12:28,825:INFO:Starting cross validation
2025-06-08 18:12:28,827:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-08 18:12:29,191:INFO:Calculating mean and std
2025-06-08 18:12:29,191:INFO:Creating metrics dataframe
2025-06-08 18:12:29,196:INFO:Uploading results into container
2025-06-08 18:12:29,196:INFO:Uploading model into container now
2025-06-08 18:12:29,196:INFO:_master_model_container: 4
2025-06-08 18:12:29,196:INFO:_display_container: 2
2025-06-08 18:12:29,196:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-06-08 18:12:29,196:INFO:create_model() successfully completed......................................
2025-06-08 18:12:29,381:INFO:SubProcess create_model() end ==================================
2025-06-08 18:12:29,381:INFO:Creating metrics dataframe
2025-06-08 18:12:29,397:INFO:Initializing SVM - Linear Kernel
2025-06-08 18:12:29,397:INFO:Total runtime is 0.27549552520116166 minutes
2025-06-08 18:12:29,414:INFO:SubProcess create_model() called ==================================
2025-06-08 18:12:29,415:INFO:Initializing create_model()
2025-06-08 18:12:29,415:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A6EBD22F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-08 18:12:29,415:INFO:Checking exceptions
2025-06-08 18:12:29,416:INFO:Importing libraries
2025-06-08 18:12:29,416:INFO:Copying training dataset
2025-06-08 18:12:29,449:INFO:Defining folds
2025-06-08 18:12:29,450:INFO:Declaring metric variables
2025-06-08 18:12:29,461:INFO:Importing untrained model
2025-06-08 18:12:29,472:INFO:SVM - Linear Kernel Imported successfully
2025-06-08 18:12:29,486:INFO:Starting cross validation
2025-06-08 18:12:29,489:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-08 18:12:29,943:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:29,987:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:12:30,001:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:30,023:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:30,026:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:30,043:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:30,043:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:30,050:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:12:30,055:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:30,056:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:12:30,059:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:30,096:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:30,112:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:30,143:INFO:Calculating mean and std
2025-06-08 18:12:30,146:INFO:Creating metrics dataframe
2025-06-08 18:12:30,150:INFO:Uploading results into container
2025-06-08 18:12:30,151:INFO:Uploading model into container now
2025-06-08 18:12:30,152:INFO:_master_model_container: 5
2025-06-08 18:12:30,152:INFO:_display_container: 2
2025-06-08 18:12:30,153:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-06-08 18:12:30,153:INFO:create_model() successfully completed......................................
2025-06-08 18:12:30,328:INFO:SubProcess create_model() end ==================================
2025-06-08 18:12:30,328:INFO:Creating metrics dataframe
2025-06-08 18:12:30,347:INFO:Initializing Ridge Classifier
2025-06-08 18:12:30,347:INFO:Total runtime is 0.2913384000460306 minutes
2025-06-08 18:12:30,354:INFO:SubProcess create_model() called ==================================
2025-06-08 18:12:30,354:INFO:Initializing create_model()
2025-06-08 18:12:30,355:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A6EBD22F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-08 18:12:30,355:INFO:Checking exceptions
2025-06-08 18:12:30,355:INFO:Importing libraries
2025-06-08 18:12:30,355:INFO:Copying training dataset
2025-06-08 18:12:30,381:INFO:Defining folds
2025-06-08 18:12:30,381:INFO:Declaring metric variables
2025-06-08 18:12:30,389:INFO:Importing untrained model
2025-06-08 18:12:30,397:INFO:Ridge Classifier Imported successfully
2025-06-08 18:12:30,410:INFO:Starting cross validation
2025-06-08 18:12:30,412:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-08 18:12:30,481:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:30,502:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:12:30,513:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:30,524:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:30,524:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:30,530:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:12:30,530:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:30,530:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:30,532:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:30,534:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:30,534:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:30,538:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:12:30,542:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:12:30,542:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:12:30,544:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:12:30,548:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:12:30,548:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:12:30,550:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:12:30,550:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:12:30,572:INFO:Calculating mean and std
2025-06-08 18:12:30,572:INFO:Creating metrics dataframe
2025-06-08 18:12:30,577:INFO:Uploading results into container
2025-06-08 18:12:30,581:INFO:Uploading model into container now
2025-06-08 18:12:30,582:INFO:_master_model_container: 6
2025-06-08 18:12:30,582:INFO:_display_container: 2
2025-06-08 18:12:30,583:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-06-08 18:12:30,583:INFO:create_model() successfully completed......................................
2025-06-08 18:12:30,758:INFO:SubProcess create_model() end ==================================
2025-06-08 18:12:30,759:INFO:Creating metrics dataframe
2025-06-08 18:12:30,776:INFO:Initializing Random Forest Classifier
2025-06-08 18:12:30,776:INFO:Total runtime is 0.2984808882077534 minutes
2025-06-08 18:12:30,783:INFO:SubProcess create_model() called ==================================
2025-06-08 18:12:30,783:INFO:Initializing create_model()
2025-06-08 18:12:30,783:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A6EBD22F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-08 18:12:30,783:INFO:Checking exceptions
2025-06-08 18:12:30,783:INFO:Importing libraries
2025-06-08 18:12:30,783:INFO:Copying training dataset
2025-06-08 18:12:30,811:INFO:Defining folds
2025-06-08 18:12:30,811:INFO:Declaring metric variables
2025-06-08 18:12:30,818:INFO:Importing untrained model
2025-06-08 18:12:30,827:INFO:Random Forest Classifier Imported successfully
2025-06-08 18:12:30,840:INFO:Starting cross validation
2025-06-08 18:12:30,842:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-08 18:12:34,726:INFO:Calculating mean and std
2025-06-08 18:12:34,727:INFO:Creating metrics dataframe
2025-06-08 18:12:34,727:INFO:Uploading results into container
2025-06-08 18:12:34,727:INFO:Uploading model into container now
2025-06-08 18:12:34,727:INFO:_master_model_container: 7
2025-06-08 18:12:34,727:INFO:_display_container: 2
2025-06-08 18:12:34,727:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-06-08 18:12:34,727:INFO:create_model() successfully completed......................................
2025-06-08 18:12:34,893:INFO:SubProcess create_model() end ==================================
2025-06-08 18:12:34,893:INFO:Creating metrics dataframe
2025-06-08 18:12:34,910:INFO:Initializing Quadratic Discriminant Analysis
2025-06-08 18:12:34,910:INFO:Total runtime is 0.3673786481221516 minutes
2025-06-08 18:12:34,929:INFO:SubProcess create_model() called ==================================
2025-06-08 18:12:34,929:INFO:Initializing create_model()
2025-06-08 18:12:34,929:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A6EBD22F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-08 18:12:34,929:INFO:Checking exceptions
2025-06-08 18:12:34,929:INFO:Importing libraries
2025-06-08 18:12:34,929:INFO:Copying training dataset
2025-06-08 18:12:34,959:INFO:Defining folds
2025-06-08 18:12:34,960:INFO:Declaring metric variables
2025-06-08 18:12:34,967:INFO:Importing untrained model
2025-06-08 18:12:34,973:INFO:Quadratic Discriminant Analysis Imported successfully
2025-06-08 18:12:34,987:INFO:Starting cross validation
2025-06-08 18:12:34,990:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-08 18:12:35,042:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-08 18:12:35,045:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:35,048:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:35,073:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-08 18:12:35,089:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:35,093:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:35,102:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:35,106:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:35,106:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:35,112:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:35,116:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:35,125:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:35,157:INFO:Calculating mean and std
2025-06-08 18:12:35,160:INFO:Creating metrics dataframe
2025-06-08 18:12:35,164:INFO:Uploading results into container
2025-06-08 18:12:35,164:INFO:Uploading model into container now
2025-06-08 18:12:35,164:INFO:_master_model_container: 8
2025-06-08 18:12:35,166:INFO:_display_container: 2
2025-06-08 18:12:35,166:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-06-08 18:12:35,166:INFO:create_model() successfully completed......................................
2025-06-08 18:12:35,347:INFO:SubProcess create_model() end ==================================
2025-06-08 18:12:35,347:INFO:Creating metrics dataframe
2025-06-08 18:12:35,369:INFO:Initializing Ada Boost Classifier
2025-06-08 18:12:35,370:INFO:Total runtime is 0.3750496387481688 minutes
2025-06-08 18:12:35,379:INFO:SubProcess create_model() called ==================================
2025-06-08 18:12:35,379:INFO:Initializing create_model()
2025-06-08 18:12:35,379:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A6EBD22F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-08 18:12:35,380:INFO:Checking exceptions
2025-06-08 18:12:35,380:INFO:Importing libraries
2025-06-08 18:12:35,380:INFO:Copying training dataset
2025-06-08 18:12:35,411:INFO:Defining folds
2025-06-08 18:12:35,411:INFO:Declaring metric variables
2025-06-08 18:12:35,419:INFO:Importing untrained model
2025-06-08 18:12:35,426:INFO:Ada Boost Classifier Imported successfully
2025-06-08 18:12:35,430:INFO:Starting cross validation
2025-06-08 18:12:35,430:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-08 18:12:35,462:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-08 18:12:35,496:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-08 18:12:35,498:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-08 18:12:35,504:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-08 18:12:35,513:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-08 18:12:35,516:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-08 18:12:35,518:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-08 18:12:35,521:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-08 18:12:35,524:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-08 18:12:35,531:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-08 18:12:36,973:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:37,010:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:37,012:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:37,014:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:37,020:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:37,030:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:37,034:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:12:37,036:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:37,057:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:37,059:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:37,071:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:37,082:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:12:37,113:INFO:Calculating mean and std
2025-06-08 18:12:37,116:INFO:Creating metrics dataframe
2025-06-08 18:12:37,120:INFO:Uploading results into container
2025-06-08 18:12:37,121:INFO:Uploading model into container now
2025-06-08 18:12:37,122:INFO:_master_model_container: 9
2025-06-08 18:12:37,122:INFO:_display_container: 2
2025-06-08 18:12:37,122:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-06-08 18:12:37,123:INFO:create_model() successfully completed......................................
2025-06-08 18:12:37,305:INFO:SubProcess create_model() end ==================================
2025-06-08 18:12:37,306:INFO:Creating metrics dataframe
2025-06-08 18:12:37,329:INFO:Initializing Gradient Boosting Classifier
2025-06-08 18:12:37,329:INFO:Total runtime is 0.40770099957784006 minutes
2025-06-08 18:12:37,332:INFO:SubProcess create_model() called ==================================
2025-06-08 18:12:37,332:INFO:Initializing create_model()
2025-06-08 18:12:37,332:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A6EBD22F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-08 18:12:37,332:INFO:Checking exceptions
2025-06-08 18:12:37,332:INFO:Importing libraries
2025-06-08 18:12:37,332:INFO:Copying training dataset
2025-06-08 18:12:37,368:INFO:Defining folds
2025-06-08 18:12:37,369:INFO:Declaring metric variables
2025-06-08 18:12:37,376:INFO:Importing untrained model
2025-06-08 18:12:37,384:INFO:Gradient Boosting Classifier Imported successfully
2025-06-08 18:12:37,393:INFO:Starting cross validation
2025-06-08 18:12:37,393:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-08 18:12:54,327:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:54,443:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:54,443:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:54,461:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:54,461:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:54,544:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:54,544:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:54,560:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:54,593:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:54,756:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:54,793:INFO:Calculating mean and std
2025-06-08 18:12:54,797:INFO:Creating metrics dataframe
2025-06-08 18:12:54,800:INFO:Uploading results into container
2025-06-08 18:12:54,800:INFO:Uploading model into container now
2025-06-08 18:12:54,800:INFO:_master_model_container: 10
2025-06-08 18:12:54,800:INFO:_display_container: 2
2025-06-08 18:12:54,800:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-08 18:12:54,800:INFO:create_model() successfully completed......................................
2025-06-08 18:12:54,994:INFO:SubProcess create_model() end ==================================
2025-06-08 18:12:54,995:INFO:Creating metrics dataframe
2025-06-08 18:12:55,015:INFO:Initializing Linear Discriminant Analysis
2025-06-08 18:12:55,015:INFO:Total runtime is 0.702468430995941 minutes
2025-06-08 18:12:55,024:INFO:SubProcess create_model() called ==================================
2025-06-08 18:12:55,026:INFO:Initializing create_model()
2025-06-08 18:12:55,026:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A6EBD22F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-08 18:12:55,026:INFO:Checking exceptions
2025-06-08 18:12:55,026:INFO:Importing libraries
2025-06-08 18:12:55,026:INFO:Copying training dataset
2025-06-08 18:12:55,051:INFO:Defining folds
2025-06-08 18:12:55,051:INFO:Declaring metric variables
2025-06-08 18:12:55,061:INFO:Importing untrained model
2025-06-08 18:12:55,066:INFO:Linear Discriminant Analysis Imported successfully
2025-06-08 18:12:55,082:INFO:Starting cross validation
2025-06-08 18:12:55,083:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-08 18:12:55,166:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:55,184:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:12:55,202:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:55,206:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:55,209:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:55,218:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:55,218:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:55,220:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:12:55,224:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:55,231:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:55,233:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:55,234:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-08 18:12:55,244:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:12:55,259:INFO:Calculating mean and std
2025-06-08 18:12:55,260:INFO:Creating metrics dataframe
2025-06-08 18:12:55,265:INFO:Uploading results into container
2025-06-08 18:12:55,266:INFO:Uploading model into container now
2025-06-08 18:12:55,267:INFO:_master_model_container: 11
2025-06-08 18:12:55,267:INFO:_display_container: 2
2025-06-08 18:12:55,268:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-06-08 18:12:55,268:INFO:create_model() successfully completed......................................
2025-06-08 18:12:55,444:INFO:SubProcess create_model() end ==================================
2025-06-08 18:12:55,445:INFO:Creating metrics dataframe
2025-06-08 18:12:55,466:INFO:Initializing Extra Trees Classifier
2025-06-08 18:12:55,466:INFO:Total runtime is 0.709975763161977 minutes
2025-06-08 18:12:55,484:INFO:SubProcess create_model() called ==================================
2025-06-08 18:12:55,485:INFO:Initializing create_model()
2025-06-08 18:12:55,485:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A6EBD22F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-08 18:12:55,485:INFO:Checking exceptions
2025-06-08 18:12:55,485:INFO:Importing libraries
2025-06-08 18:12:55,485:INFO:Copying training dataset
2025-06-08 18:12:55,512:INFO:Defining folds
2025-06-08 18:12:55,512:INFO:Declaring metric variables
2025-06-08 18:12:55,522:INFO:Importing untrained model
2025-06-08 18:12:55,532:INFO:Extra Trees Classifier Imported successfully
2025-06-08 18:12:55,551:INFO:Starting cross validation
2025-06-08 18:12:55,553:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-08 18:12:57,564:INFO:Calculating mean and std
2025-06-08 18:12:57,568:INFO:Creating metrics dataframe
2025-06-08 18:12:57,572:INFO:Uploading results into container
2025-06-08 18:12:57,573:INFO:Uploading model into container now
2025-06-08 18:12:57,574:INFO:_master_model_container: 12
2025-06-08 18:12:57,574:INFO:_display_container: 2
2025-06-08 18:12:57,575:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-06-08 18:12:57,575:INFO:create_model() successfully completed......................................
2025-06-08 18:12:57,743:INFO:SubProcess create_model() end ==================================
2025-06-08 18:12:57,744:INFO:Creating metrics dataframe
2025-06-08 18:12:57,765:INFO:Initializing Extreme Gradient Boosting
2025-06-08 18:12:57,765:INFO:Total runtime is 0.74830265045166 minutes
2025-06-08 18:12:57,770:INFO:SubProcess create_model() called ==================================
2025-06-08 18:12:57,771:INFO:Initializing create_model()
2025-06-08 18:12:57,771:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A6EBD22F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-08 18:12:57,771:INFO:Checking exceptions
2025-06-08 18:12:57,771:INFO:Importing libraries
2025-06-08 18:12:57,771:INFO:Copying training dataset
2025-06-08 18:12:57,796:INFO:Defining folds
2025-06-08 18:12:57,797:INFO:Declaring metric variables
2025-06-08 18:12:57,803:INFO:Importing untrained model
2025-06-08 18:12:57,811:INFO:Extreme Gradient Boosting Imported successfully
2025-06-08 18:12:57,823:INFO:Starting cross validation
2025-06-08 18:12:57,824:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-08 18:13:00,423:INFO:Calculating mean and std
2025-06-08 18:13:00,429:INFO:Creating metrics dataframe
2025-06-08 18:13:00,429:INFO:Uploading results into container
2025-06-08 18:13:00,429:INFO:Uploading model into container now
2025-06-08 18:13:00,429:INFO:_master_model_container: 13
2025-06-08 18:13:00,429:INFO:_display_container: 2
2025-06-08 18:13:00,429:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-06-08 18:13:00,429:INFO:create_model() successfully completed......................................
2025-06-08 18:13:00,608:INFO:SubProcess create_model() end ==================================
2025-06-08 18:13:00,608:INFO:Creating metrics dataframe
2025-06-08 18:13:00,630:INFO:Initializing Light Gradient Boosting Machine
2025-06-08 18:13:00,630:INFO:Total runtime is 0.7960417628288268 minutes
2025-06-08 18:13:00,640:INFO:SubProcess create_model() called ==================================
2025-06-08 18:13:00,641:INFO:Initializing create_model()
2025-06-08 18:13:00,641:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A6EBD22F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-08 18:13:00,642:INFO:Checking exceptions
2025-06-08 18:13:00,643:INFO:Importing libraries
2025-06-08 18:13:00,643:INFO:Copying training dataset
2025-06-08 18:13:00,661:INFO:Defining folds
2025-06-08 18:13:00,666:INFO:Declaring metric variables
2025-06-08 18:13:00,675:INFO:Importing untrained model
2025-06-08 18:13:00,683:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-08 18:13:00,697:INFO:Starting cross validation
2025-06-08 18:13:00,698:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-08 18:13:17,211:INFO:Calculating mean and std
2025-06-08 18:13:17,213:INFO:Creating metrics dataframe
2025-06-08 18:13:17,219:INFO:Uploading results into container
2025-06-08 18:13:17,219:INFO:Uploading model into container now
2025-06-08 18:13:17,221:INFO:_master_model_container: 14
2025-06-08 18:13:17,221:INFO:_display_container: 2
2025-06-08 18:13:17,223:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-06-08 18:13:17,223:INFO:create_model() successfully completed......................................
2025-06-08 18:13:17,393:INFO:SubProcess create_model() end ==================================
2025-06-08 18:13:17,393:INFO:Creating metrics dataframe
2025-06-08 18:13:17,411:INFO:Initializing Dummy Classifier
2025-06-08 18:13:17,411:INFO:Total runtime is 1.0757302045822144 minutes
2025-06-08 18:13:17,422:INFO:SubProcess create_model() called ==================================
2025-06-08 18:13:17,423:INFO:Initializing create_model()
2025-06-08 18:13:17,423:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A6EBD22F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-08 18:13:17,423:INFO:Checking exceptions
2025-06-08 18:13:17,423:INFO:Importing libraries
2025-06-08 18:13:17,423:INFO:Copying training dataset
2025-06-08 18:13:17,452:INFO:Defining folds
2025-06-08 18:13:17,453:INFO:Declaring metric variables
2025-06-08 18:13:17,462:INFO:Importing untrained model
2025-06-08 18:13:17,462:INFO:Dummy Classifier Imported successfully
2025-06-08 18:13:17,486:INFO:Starting cross validation
2025-06-08 18:13:17,487:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-08 18:13:17,550:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:13:17,586:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:13:17,590:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:13:17,601:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:13:17,601:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:13:17,601:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:13:17,607:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:13:17,607:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:13:17,614:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:13:17,618:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-08 18:13:17,643:INFO:Calculating mean and std
2025-06-08 18:13:17,647:INFO:Creating metrics dataframe
2025-06-08 18:13:17,651:INFO:Uploading results into container
2025-06-08 18:13:17,652:INFO:Uploading model into container now
2025-06-08 18:13:17,652:INFO:_master_model_container: 15
2025-06-08 18:13:17,652:INFO:_display_container: 2
2025-06-08 18:13:17,653:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-06-08 18:13:17,653:INFO:create_model() successfully completed......................................
2025-06-08 18:13:17,843:INFO:SubProcess create_model() end ==================================
2025-06-08 18:13:17,843:INFO:Creating metrics dataframe
2025-06-08 18:13:17,871:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-06-08 18:13:17,890:INFO:Initializing create_model()
2025-06-08 18:13:17,890:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-08 18:13:17,890:INFO:Checking exceptions
2025-06-08 18:13:17,894:INFO:Importing libraries
2025-06-08 18:13:17,894:INFO:Copying training dataset
2025-06-08 18:13:17,919:INFO:Defining folds
2025-06-08 18:13:17,919:INFO:Declaring metric variables
2025-06-08 18:13:17,919:INFO:Importing untrained model
2025-06-08 18:13:17,919:INFO:Declaring custom model
2025-06-08 18:13:17,921:INFO:Ridge Classifier Imported successfully
2025-06-08 18:13:17,922:INFO:Cross validation set to False
2025-06-08 18:13:17,922:INFO:Fitting Model
2025-06-08 18:13:17,948:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-06-08 18:13:17,948:INFO:create_model() successfully completed......................................
2025-06-08 18:13:18,235:INFO:_master_model_container: 15
2025-06-08 18:13:18,235:INFO:_display_container: 2
2025-06-08 18:13:18,236:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-06-08 18:13:18,236:INFO:compare_models() successfully completed......................................
2025-06-08 18:13:46,814:INFO:Initializing create_model()
2025-06-08 18:13:46,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced'})
2025-06-08 18:13:46,814:INFO:Checking exceptions
2025-06-08 18:13:46,837:INFO:Importing libraries
2025-06-08 18:13:46,840:INFO:Copying training dataset
2025-06-08 18:13:46,860:INFO:Defining folds
2025-06-08 18:13:46,860:INFO:Declaring metric variables
2025-06-08 18:13:46,860:INFO:Importing untrained model
2025-06-08 18:13:46,877:INFO:Extreme Gradient Boosting Imported successfully
2025-06-08 18:13:46,896:INFO:Starting cross validation
2025-06-08 18:13:46,896:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-08 18:13:49,393:INFO:Calculating mean and std
2025-06-08 18:13:49,393:INFO:Creating metrics dataframe
2025-06-08 18:13:49,393:INFO:Finalizing model
2025-06-08 18:13:50,304:INFO:Uploading results into container
2025-06-08 18:13:50,306:INFO:Uploading model into container now
2025-06-08 18:13:50,321:INFO:_master_model_container: 16
2025-06-08 18:13:50,323:INFO:_display_container: 3
2025-06-08 18:13:50,323:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1, ...)
2025-06-08 18:13:50,323:INFO:create_model() successfully completed......................................
2025-06-08 18:13:59,888:INFO:Initializing tune_model()
2025-06-08 18:13:59,888:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1, ...), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>)
2025-06-08 18:13:59,888:INFO:Checking exceptions
2025-06-08 18:13:59,914:INFO:Copying training dataset
2025-06-08 18:13:59,929:INFO:Checking base model
2025-06-08 18:13:59,930:INFO:Base model : Extreme Gradient Boosting
2025-06-08 18:13:59,930:INFO:Declaring metric variables
2025-06-08 18:13:59,943:INFO:Defining Hyperparameters
2025-06-08 18:14:00,125:INFO:Tuning with n_jobs=-1
2025-06-08 18:14:00,131:INFO:Initializing RandomizedSearchCV
2025-06-08 18:14:20,243:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__scale_pos_weight': 38.0, 'actual_estimator__reg_lambda': 0.7, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__n_estimators': 60, 'actual_estimator__min_child_weight': 1, 'actual_estimator__max_depth': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__colsample_bytree': 0.7}
2025-06-08 18:14:20,245:INFO:Hyperparameter search completed
2025-06-08 18:14:20,245:INFO:SubProcess create_model() called ==================================
2025-06-08 18:14:20,245:INFO:Initializing create_model()
2025-06-08 18:14:20,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A6D075060>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'scale_pos_weight': 38.0, 'reg_lambda': 0.7, 'reg_alpha': 0.001, 'n_estimators': 60, 'min_child_weight': 1, 'max_depth': 6, 'learning_rate': 0.4, 'colsample_bytree': 0.7})
2025-06-08 18:14:20,245:INFO:Checking exceptions
2025-06-08 18:14:20,245:INFO:Importing libraries
2025-06-08 18:14:20,245:INFO:Copying training dataset
2025-06-08 18:14:20,279:INFO:Defining folds
2025-06-08 18:14:20,279:INFO:Declaring metric variables
2025-06-08 18:14:20,287:INFO:Importing untrained model
2025-06-08 18:14:20,287:INFO:Declaring custom model
2025-06-08 18:14:20,296:INFO:Extreme Gradient Boosting Imported successfully
2025-06-08 18:14:20,309:INFO:Starting cross validation
2025-06-08 18:14:20,312:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-08 18:14:21,842:INFO:Calculating mean and std
2025-06-08 18:14:21,845:INFO:Creating metrics dataframe
2025-06-08 18:14:21,857:INFO:Finalizing model
2025-06-08 18:14:22,393:INFO:Uploading results into container
2025-06-08 18:14:22,395:INFO:Uploading model into container now
2025-06-08 18:14:22,396:INFO:_master_model_container: 17
2025-06-08 18:14:22,396:INFO:_display_container: 4
2025-06-08 18:14:22,396:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=0.7, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=-1, ...)
2025-06-08 18:14:22,396:INFO:create_model() successfully completed......................................
2025-06-08 18:14:22,557:INFO:SubProcess create_model() end ==================================
2025-06-08 18:14:22,557:INFO:choose_better activated
2025-06-08 18:14:22,573:INFO:SubProcess create_model() called ==================================
2025-06-08 18:14:22,573:INFO:Initializing create_model()
2025-06-08 18:14:22,573:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-08 18:14:22,573:INFO:Checking exceptions
2025-06-08 18:14:22,573:INFO:Importing libraries
2025-06-08 18:14:22,573:INFO:Copying training dataset
2025-06-08 18:14:22,594:INFO:Defining folds
2025-06-08 18:14:22,594:INFO:Declaring metric variables
2025-06-08 18:14:22,594:INFO:Importing untrained model
2025-06-08 18:14:22,594:INFO:Declaring custom model
2025-06-08 18:14:22,594:INFO:Extreme Gradient Boosting Imported successfully
2025-06-08 18:14:22,610:INFO:Starting cross validation
2025-06-08 18:14:22,611:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-08 18:14:26,759:INFO:Calculating mean and std
2025-06-08 18:14:26,760:INFO:Creating metrics dataframe
2025-06-08 18:14:26,760:INFO:Finalizing model
2025-06-08 18:14:27,830:INFO:Uploading results into container
2025-06-08 18:14:27,835:INFO:Uploading model into container now
2025-06-08 18:14:27,835:INFO:_master_model_container: 18
2025-06-08 18:14:27,837:INFO:_display_container: 5
2025-06-08 18:14:27,837:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1, ...)
2025-06-08 18:14:27,837:INFO:create_model() successfully completed......................................
2025-06-08 18:14:27,993:INFO:SubProcess create_model() end ==================================
2025-06-08 18:14:27,993:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1, ...) result for F1 is 0.7584
2025-06-08 18:14:27,993:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=0.7, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=-1, ...) result for F1 is 0.7624
2025-06-08 18:14:27,993:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=0.7, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=-1, ...) is best model
2025-06-08 18:14:27,993:INFO:choose_better completed
2025-06-08 18:14:28,026:INFO:_master_model_container: 18
2025-06-08 18:14:28,026:INFO:_display_container: 4
2025-06-08 18:14:28,033:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=0.7, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=-1, ...)
2025-06-08 18:14:28,033:INFO:tune_model() successfully completed......................................
2025-06-08 18:14:59,280:INFO:Initializing finalize_model()
2025-06-08 18:14:59,281:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=0.7, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=-1, ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-08 18:14:59,282:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=0.7, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=-1, ...)
2025-06-08 18:14:59,290:INFO:Initializing create_model()
2025-06-08 18:14:59,290:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=0.7, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=-1, ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-08 18:14:59,290:INFO:Checking exceptions
2025-06-08 18:14:59,292:INFO:Importing libraries
2025-06-08 18:14:59,292:INFO:Copying training dataset
2025-06-08 18:14:59,293:INFO:Defining folds
2025-06-08 18:14:59,293:INFO:Declaring metric variables
2025-06-08 18:14:59,293:INFO:Importing untrained model
2025-06-08 18:14:59,293:INFO:Declaring custom model
2025-06-08 18:14:59,294:INFO:Extreme Gradient Boosting Imported successfully
2025-06-08 18:14:59,295:INFO:Cross validation set to False
2025-06-08 18:14:59,295:INFO:Fitting Model
2025-06-08 18:15:00,023:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['isSchool', 'rental_count',
                                             'return_count', 'apart',
                                             'closest_hospital_dist',
                                             'closest_convenience_dist',
                                             'closest_culture_dist', 'age_20s',
                                             'age_30s', 'age_40s',
                                             'crosswalk_count',
                                             'closest_cross_dist', 'bus_count',
                                             'closest_bus_dist', 'subway_count',
                                             'clos...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=-1, ...))],
         verbose=False)
2025-06-08 18:15:00,023:INFO:create_model() successfully completed......................................
2025-06-08 18:15:00,207:INFO:_master_model_container: 18
2025-06-08 18:15:00,208:INFO:_display_container: 4
2025-06-08 18:15:00,223:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['isSchool', 'rental_count',
                                             'return_count', 'apart',
                                             'closest_hospital_dist',
                                             'closest_convenience_dist',
                                             'closest_culture_dist', 'age_20s',
                                             'age_30s', 'age_40s',
                                             'crosswalk_count',
                                             'closest_cross_dist', 'bus_count',
                                             'closest_bus_dist', 'subway_count',
                                             'clos...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=-1, ...))],
         verbose=False)
2025-06-08 18:15:00,223:INFO:finalize_model() successfully completed......................................
2025-06-08 18:15:00,404:INFO:Initializing predict_model()
2025-06-08 18:15:00,404:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['isSchool', 'rental_count',
                                             'return_count', 'apart',
                                             'closest_hospital_dist',
                                             'closest_convenience_dist',
                                             'closest_culture_dist', 'age_20s',
                                             'age_30s', 'age_40s',
                                             'crosswalk_count',
                                             'closest_cross_dist', 'bus_count',
                                             'closest_bus_dist', 'subway_count',
                                             'clos...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=-1, ...))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025A6EB3BD00>)
2025-06-08 18:15:00,404:INFO:Checking exceptions
2025-06-08 18:15:00,404:INFO:Preloading libraries
2025-06-08 18:15:00,408:INFO:Set up data.
2025-06-08 18:15:00,429:INFO:Set up index.
2025-06-08 18:15:35,099:INFO:Initializing get_config()
2025-06-08 18:15:35,101:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A6EABE230>, variable=X_train)
2025-06-08 18:15:35,102:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2025-06-08 18:15:35,104:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py:321: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2025-06-08 18:15:35,118:INFO:Variable:  returned as        isSchool  rental_count  return_count     apart  closest_hospital_dist  \
1526          0      0.000000      0.000000  0.000000               6.753224   
1813          1      4.577036      4.658558  0.000000               4.484650   
19279         0      0.000000      0.000000  0.000000               5.147014   
2599          1      4.934242      4.984048  6.028278               3.300803   
1936          0      0.000000      0.000000  0.000000               5.682774   
...         ...           ...           ...       ...                    ...   
32376         0      0.000000      0.000000  0.000000               4.301848   
28123         0      1.758970      1.678001  0.000000               4.374832   
31758         0      0.000000      0.000000  0.000000               5.541237   
1211          0      4.366176      4.369448  7.085901               5.738585   
20449         0      3.146173      3.154399  4.927254               4.933111   

       closest_convenience_dist  closest_culture_dist    age_20s    age_30s  \
1526                   6.397195              7.051930   9.029681   9.354688   
1813                   3.827818              6.605085   8.250020   8.318323   
19279                  4.320978              5.812755   7.517683   7.548420   
2599                   3.336692              6.248655   8.546797   8.831818   
1936                   4.713324              6.472786   9.029681   9.354688   
...                         ...                   ...        ...        ...   
32376                  3.340475              6.535544   7.419641   7.571612   
28123                  4.616723              5.404635  10.063892  10.244259   
31758                  5.374055              5.460620   7.862272   7.596469   
1211                   4.332340              6.986263   8.438911   8.746964   
20449                  3.861991              5.212646   8.476239   8.843242   

        age_40s  ...  bus_avg_alight  subway_avg_board  subway_avg_alight  \
1526   9.071215  ...        0.000000               0.0                0.0   
1813   8.673134  ...        0.000000               0.0                0.0   
19279  7.875865  ...        0.000000               0.0                0.0   
2599   8.748407  ...        7.465909               0.0                0.0   
1936   9.071215  ...        0.000000               0.0                0.0   
...         ...  ...             ...               ...                ...   
32376  7.758269  ...        0.000000               0.0                0.0   
28123  9.943179  ...        0.000000               0.0                0.0   
31758  7.718918  ...        0.000000               0.0                0.0   
1211   8.809739  ...        0.000000               0.0                0.0   
20449  8.811502  ...        0.000000               0.0                0.0   

          area20     area30     area40  wp_area20  wp_area30  wp_area40  \
1526    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   
1813   11.845654  11.870794  12.259103   3.332205   4.471639   5.096813   
19279   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   
2599    8.865947   9.152208   8.874273   3.917011   4.442651   4.491441   
1936   10.282943  10.599394  10.276731   3.663562   4.314149   4.442651   
...          ...        ...        ...        ...        ...        ...   
32376   8.422223   8.491619   8.631816   0.000000   1.098612   1.791759   
28123  12.798146  13.151178  13.023378   8.119249   8.578476   8.351434   
31758  10.203527   9.996284   9.987645   0.810930   0.916291   1.558145   
1211   10.836955  11.220720  11.535294   4.997212   5.669881   5.476463   
20449  10.955628  11.470751  11.502522   7.669145   7.822044   7.524696   

       isCommercial  
1526              0  
1813              1  
19279             1  
2599              1  
1936              1  
...             ...  
32376             1  
28123             1  
31758             1  
1211              1  
20449             0  

[5464 rows x 27 columns]
2025-06-08 18:15:35,118:INFO:get_config() successfully completed......................................
2025-06-08 18:15:39,951:WARNING:C:\Users\omslu\AppData\Local\Temp\ipykernel_996\544866967.py:5: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap.summary_plot(shap_values.values[:, :, class_idx], X_test)

2025-06-08 18:15:43,740:WARNING:C:\Users\omslu\AppData\Local\Temp\ipykernel_996\544866967.py:5: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap.summary_plot(shap_values.values[:, :, class_idx], X_test)

2025-06-08 18:15:47,703:WARNING:C:\Users\omslu\AppData\Local\Temp\ipykernel_996\544866967.py:5: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.
  shap.summary_plot(shap_values.values[:, :, class_idx], X_test)

2025-06-14 16:11:38,299:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-14 16:11:38,301:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-14 16:11:38,301:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-14 16:11:38,301:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-14 16:11:41,627:INFO:PyCaret ClassificationExperiment
2025-06-14 16:11:41,627:INFO:Logging name: clf-default-name
2025-06-14 16:11:41,627:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-14 16:11:41,627:INFO:version 3.3.2
2025-06-14 16:11:41,628:INFO:Initializing setup()
2025-06-14 16:11:41,628:INFO:self.USI: 2964
2025-06-14 16:11:41,628:INFO:self._variable_keys: {'target_param', 'logging_param', 'y_test', 'y_train', 'gpu_n_jobs_param', 'X_test', 'X', 'exp_id', 'data', 'X_train', 'log_plots_param', 'USI', 'n_jobs_param', '_available_plots', 'fix_imbalance', 'memory', 'seed', 'fold_groups_param', 'y', '_ml_usecase', 'exp_name_log', 'gpu_param', 'fold_shuffle_param', 'is_multiclass', 'fold_generator', 'idx', 'html_param', 'pipeline'}
2025-06-14 16:11:41,628:INFO:Checking environment
2025-06-14 16:11:41,628:INFO:python_version: 3.10.16
2025-06-14 16:11:41,628:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-14 16:11:41,628:INFO:machine: AMD64
2025-06-14 16:11:41,628:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-14 16:11:41,639:INFO:Memory: svmem(total=33885192192, available=14617870336, percent=56.9, used=19267321856, free=14617870336)
2025-06-14 16:11:41,641:INFO:Physical Core: 14
2025-06-14 16:11:41,641:INFO:Logical Core: 18
2025-06-14 16:11:41,641:INFO:Checking libraries
2025-06-14 16:11:41,641:INFO:System:
2025-06-14 16:11:41,642:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-14 16:11:41,642:INFO:executable: C:\Users\omslu\anaconda3\envs\pycaret_env\python.exe
2025-06-14 16:11:41,642:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-14 16:11:41,642:INFO:PyCaret required dependencies:
2025-06-14 16:11:41,711:INFO:                 pip: 25.1
2025-06-14 16:11:41,711:INFO:          setuptools: 78.1.1
2025-06-14 16:11:41,711:INFO:             pycaret: 3.3.2
2025-06-14 16:11:41,711:INFO:             IPython: 8.37.0
2025-06-14 16:11:41,711:INFO:          ipywidgets: 8.1.7
2025-06-14 16:11:41,711:INFO:                tqdm: 4.67.1
2025-06-14 16:11:41,711:INFO:               numpy: 1.26.4
2025-06-14 16:11:41,711:INFO:              pandas: 2.1.4
2025-06-14 16:11:41,712:INFO:              jinja2: 3.1.6
2025-06-14 16:11:41,712:INFO:               scipy: 1.11.4
2025-06-14 16:11:41,712:INFO:              joblib: 1.3.2
2025-06-14 16:11:41,712:INFO:             sklearn: 1.4.2
2025-06-14 16:11:41,712:INFO:                pyod: 2.0.5
2025-06-14 16:11:41,712:INFO:            imblearn: 0.13.0
2025-06-14 16:11:41,712:INFO:   category_encoders: 2.7.0
2025-06-14 16:11:41,712:INFO:            lightgbm: 4.6.0
2025-06-14 16:11:41,712:INFO:               numba: 0.61.2
2025-06-14 16:11:41,713:INFO:            requests: 2.32.3
2025-06-14 16:11:41,713:INFO:          matplotlib: 3.7.5
2025-06-14 16:11:41,713:INFO:          scikitplot: 0.3.7
2025-06-14 16:11:41,713:INFO:         yellowbrick: 1.5
2025-06-14 16:11:41,713:INFO:              plotly: 5.24.1
2025-06-14 16:11:41,713:INFO:    plotly-resampler: Not installed
2025-06-14 16:11:41,713:INFO:             kaleido: 0.2.1
2025-06-14 16:11:41,713:INFO:           schemdraw: 0.15
2025-06-14 16:11:41,713:INFO:         statsmodels: 0.14.4
2025-06-14 16:11:41,713:INFO:              sktime: 0.26.0
2025-06-14 16:11:41,714:INFO:               tbats: 1.1.3
2025-06-14 16:11:41,714:INFO:            pmdarima: 2.0.4
2025-06-14 16:11:41,714:INFO:              psutil: 7.0.0
2025-06-14 16:11:41,714:INFO:          markupsafe: 3.0.2
2025-06-14 16:11:41,714:INFO:             pickle5: Not installed
2025-06-14 16:11:41,714:INFO:         cloudpickle: 3.1.1
2025-06-14 16:11:41,714:INFO:         deprecation: 2.1.0
2025-06-14 16:11:41,714:INFO:              xxhash: 3.5.0
2025-06-14 16:11:41,714:INFO:           wurlitzer: Not installed
2025-06-14 16:11:41,715:INFO:PyCaret optional dependencies:
2025-06-14 16:11:41,849:INFO:                shap: 0.47.2
2025-06-14 16:11:41,849:INFO:           interpret: Not installed
2025-06-14 16:11:41,849:INFO:                umap: Not installed
2025-06-14 16:11:41,849:INFO:     ydata_profiling: Not installed
2025-06-14 16:11:41,849:INFO:  explainerdashboard: Not installed
2025-06-14 16:11:41,849:INFO:             autoviz: Not installed
2025-06-14 16:11:41,849:INFO:           fairlearn: Not installed
2025-06-14 16:11:41,849:INFO:          deepchecks: Not installed
2025-06-14 16:11:41,849:INFO:             xgboost: 3.0.2
2025-06-14 16:11:41,849:INFO:            catboost: Not installed
2025-06-14 16:11:41,849:INFO:              kmodes: Not installed
2025-06-14 16:11:41,849:INFO:             mlxtend: Not installed
2025-06-14 16:11:41,849:INFO:       statsforecast: Not installed
2025-06-14 16:11:41,849:INFO:        tune_sklearn: Not installed
2025-06-14 16:11:41,849:INFO:                 ray: Not installed
2025-06-14 16:11:41,849:INFO:            hyperopt: Not installed
2025-06-14 16:11:41,849:INFO:              optuna: Not installed
2025-06-14 16:11:41,849:INFO:               skopt: Not installed
2025-06-14 16:11:41,849:INFO:              mlflow: Not installed
2025-06-14 16:11:41,849:INFO:              gradio: Not installed
2025-06-14 16:11:41,849:INFO:             fastapi: Not installed
2025-06-14 16:11:41,849:INFO:             uvicorn: Not installed
2025-06-14 16:11:41,849:INFO:              m2cgen: Not installed
2025-06-14 16:11:41,849:INFO:           evidently: Not installed
2025-06-14 16:11:41,849:INFO:               fugue: Not installed
2025-06-14 16:11:41,849:INFO:           streamlit: Not installed
2025-06-14 16:11:41,849:INFO:             prophet: Not installed
2025-06-14 16:11:41,849:INFO:None
2025-06-14 16:11:41,849:INFO:Set up data.
2025-06-14 16:11:41,895:INFO:Set up folding strategy.
2025-06-14 16:11:41,895:INFO:Set up train/test split.
2025-06-14 16:11:41,920:INFO:Set up index.
2025-06-14 16:11:41,921:INFO:Assigning column types.
2025-06-14 16:11:41,937:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-14 16:11:42,140:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-14 16:11:42,161:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-14 16:11:42,265:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:11:42,265:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:11:42,441:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-14 16:11:42,441:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-14 16:11:42,542:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:11:42,551:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:11:42,552:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-14 16:11:42,686:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-14 16:11:42,772:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:11:42,779:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:11:42,920:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-14 16:11:43,036:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:11:43,046:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:11:43,046:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-06-14 16:11:43,284:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:11:43,299:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:11:43,585:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:11:43,601:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:11:43,622:INFO:Preparing preprocessing pipeline...
2025-06-14 16:11:43,626:INFO:Set up simple imputation.
2025-06-14 16:11:43,715:INFO:Finished creating preprocessing pipeline.
2025-06-14 16:11:43,727:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\omslu\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['isSchool', 'rental_count',
                                             'return_count', 'apart',
                                             'closest_hospital_dist',
                                             'closest_convenience_dist',
                                             'closest_culture_dist', 'age_20s',
                                             'age_30s', 'age_40s',
                                             'crosswalk_count',
                                             'closest_cross_dist', 'bus_count'...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-06-14 16:11:43,727:INFO:Creating final display dataframe.
2025-06-14 16:11:43,985:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target        risk_level
2                   Target type        Multiclass
3           Original data shape        (8029, 28)
4        Transformed data shape        (8029, 28)
5   Transformed train set shape        (5620, 28)
6    Transformed test set shape        (2409, 28)
7              Numeric features                27
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              2964
2025-06-14 16:11:44,318:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:11:44,327:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:11:44,581:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:11:44,591:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:11:44,603:INFO:setup() successfully completed in 2.99s...............
2025-06-14 16:11:44,612:INFO:Initializing compare_models()
2025-06-14 16:11:44,613:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013CBD0A62C0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000013CBD0A62C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-06-14 16:11:44,613:INFO:Checking exceptions
2025-06-14 16:11:44,624:INFO:Preparing display monitor
2025-06-14 16:11:44,676:INFO:Initializing Logistic Regression
2025-06-14 16:11:44,676:INFO:Total runtime is 0.0 minutes
2025-06-14 16:11:44,676:INFO:SubProcess create_model() called ==================================
2025-06-14 16:11:44,676:INFO:Initializing create_model()
2025-06-14 16:11:44,676:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013CBD0A62C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013CBD0A7160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:11:44,676:INFO:Checking exceptions
2025-06-14 16:11:44,676:INFO:Importing libraries
2025-06-14 16:11:44,676:INFO:Copying training dataset
2025-06-14 16:11:44,709:INFO:Defining folds
2025-06-14 16:11:44,709:INFO:Declaring metric variables
2025-06-14 16:11:44,716:INFO:Importing untrained model
2025-06-14 16:11:44,723:INFO:Logistic Regression Imported successfully
2025-06-14 16:11:44,727:INFO:Starting cross validation
2025-06-14 16:11:44,727:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:11:53,539:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:11:53,561:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:11:53,577:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:11:53,618:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:11:53,636:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:11:53,736:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:11:53,789:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:11:53,795:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:11:53,962:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:11:54,222:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:11:54,254:INFO:Calculating mean and std
2025-06-14 16:11:54,256:INFO:Creating metrics dataframe
2025-06-14 16:11:54,263:INFO:Uploading results into container
2025-06-14 16:11:54,263:INFO:Uploading model into container now
2025-06-14 16:11:54,265:INFO:_master_model_container: 1
2025-06-14 16:11:54,265:INFO:_display_container: 2
2025-06-14 16:11:54,265:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-14 16:11:54,267:INFO:create_model() successfully completed......................................
2025-06-14 16:11:54,415:INFO:SubProcess create_model() end ==================================
2025-06-14 16:11:54,416:INFO:Creating metrics dataframe
2025-06-14 16:11:54,429:INFO:Initializing K Neighbors Classifier
2025-06-14 16:11:54,430:INFO:Total runtime is 0.16256995598475138 minutes
2025-06-14 16:11:54,438:INFO:SubProcess create_model() called ==================================
2025-06-14 16:11:54,440:INFO:Initializing create_model()
2025-06-14 16:11:54,440:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013CBD0A62C0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013CBD0A7160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:11:54,440:INFO:Checking exceptions
2025-06-14 16:11:54,440:INFO:Importing libraries
2025-06-14 16:11:54,441:INFO:Copying training dataset
2025-06-14 16:11:54,461:INFO:Defining folds
2025-06-14 16:11:54,461:INFO:Declaring metric variables
2025-06-14 16:11:54,471:INFO:Importing untrained model
2025-06-14 16:11:54,475:INFO:K Neighbors Classifier Imported successfully
2025-06-14 16:11:54,488:INFO:Starting cross validation
2025-06-14 16:11:54,489:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:12:00,488:INFO:Calculating mean and std
2025-06-14 16:12:00,493:INFO:Creating metrics dataframe
2025-06-14 16:12:00,495:INFO:Uploading results into container
2025-06-14 16:12:00,495:INFO:Uploading model into container now
2025-06-14 16:12:00,495:INFO:_master_model_container: 2
2025-06-14 16:12:00,495:INFO:_display_container: 2
2025-06-14 16:12:00,495:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-14 16:12:00,495:INFO:create_model() successfully completed......................................
2025-06-14 16:12:00,660:INFO:SubProcess create_model() end ==================================
2025-06-14 16:12:00,661:INFO:Creating metrics dataframe
2025-06-14 16:12:00,681:INFO:Initializing Naive Bayes
2025-06-14 16:12:00,681:INFO:Total runtime is 0.26675804853439333 minutes
2025-06-14 16:12:00,689:INFO:SubProcess create_model() called ==================================
2025-06-14 16:12:00,689:INFO:Initializing create_model()
2025-06-14 16:12:00,690:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013CBD0A62C0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013CBD0A7160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:12:00,691:INFO:Checking exceptions
2025-06-14 16:12:00,691:INFO:Importing libraries
2025-06-14 16:12:00,691:INFO:Copying training dataset
2025-06-14 16:12:00,724:INFO:Defining folds
2025-06-14 16:12:00,725:INFO:Declaring metric variables
2025-06-14 16:12:00,732:INFO:Importing untrained model
2025-06-14 16:12:00,742:INFO:Naive Bayes Imported successfully
2025-06-14 16:12:00,761:INFO:Starting cross validation
2025-06-14 16:12:00,764:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:12:00,937:INFO:Calculating mean and std
2025-06-14 16:12:00,937:INFO:Creating metrics dataframe
2025-06-14 16:12:00,937:INFO:Uploading results into container
2025-06-14 16:12:00,937:INFO:Uploading model into container now
2025-06-14 16:12:00,937:INFO:_master_model_container: 3
2025-06-14 16:12:00,937:INFO:_display_container: 2
2025-06-14 16:12:00,937:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-06-14 16:12:00,937:INFO:create_model() successfully completed......................................
2025-06-14 16:12:01,100:INFO:SubProcess create_model() end ==================================
2025-06-14 16:12:01,100:INFO:Creating metrics dataframe
2025-06-14 16:12:01,130:INFO:Initializing Decision Tree Classifier
2025-06-14 16:12:01,130:INFO:Total runtime is 0.2742331385612488 minutes
2025-06-14 16:12:01,140:INFO:SubProcess create_model() called ==================================
2025-06-14 16:12:01,143:INFO:Initializing create_model()
2025-06-14 16:12:01,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013CBD0A62C0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013CBD0A7160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:12:01,144:INFO:Checking exceptions
2025-06-14 16:12:01,144:INFO:Importing libraries
2025-06-14 16:12:01,144:INFO:Copying training dataset
2025-06-14 16:12:01,181:INFO:Defining folds
2025-06-14 16:12:01,182:INFO:Declaring metric variables
2025-06-14 16:12:01,188:INFO:Importing untrained model
2025-06-14 16:12:01,195:INFO:Decision Tree Classifier Imported successfully
2025-06-14 16:12:01,213:INFO:Starting cross validation
2025-06-14 16:12:01,216:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:12:01,615:INFO:Calculating mean and std
2025-06-14 16:12:01,618:INFO:Creating metrics dataframe
2025-06-14 16:12:01,622:INFO:Uploading results into container
2025-06-14 16:12:01,624:INFO:Uploading model into container now
2025-06-14 16:12:01,625:INFO:_master_model_container: 4
2025-06-14 16:12:01,625:INFO:_display_container: 2
2025-06-14 16:12:01,626:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-06-14 16:12:01,626:INFO:create_model() successfully completed......................................
2025-06-14 16:12:01,783:INFO:SubProcess create_model() end ==================================
2025-06-14 16:12:01,783:INFO:Creating metrics dataframe
2025-06-14 16:12:01,809:INFO:Initializing SVM - Linear Kernel
2025-06-14 16:12:01,809:INFO:Total runtime is 0.28555010954538984 minutes
2025-06-14 16:12:01,821:INFO:SubProcess create_model() called ==================================
2025-06-14 16:12:01,822:INFO:Initializing create_model()
2025-06-14 16:12:01,823:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013CBD0A62C0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013CBD0A7160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:12:01,823:INFO:Checking exceptions
2025-06-14 16:12:01,824:INFO:Importing libraries
2025-06-14 16:12:01,824:INFO:Copying training dataset
2025-06-14 16:12:01,854:INFO:Defining folds
2025-06-14 16:12:01,855:INFO:Declaring metric variables
2025-06-14 16:12:01,864:INFO:Importing untrained model
2025-06-14 16:12:01,872:INFO:SVM - Linear Kernel Imported successfully
2025-06-14 16:12:01,881:INFO:Starting cross validation
2025-06-14 16:12:01,887:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:12:02,374:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:02,412:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:12:02,438:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:02,445:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:02,485:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:02,496:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:02,501:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:12:02,509:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:02,509:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:02,514:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:02,522:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:12:02,522:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:12:02,538:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:02,538:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:02,558:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:12:02,589:INFO:Calculating mean and std
2025-06-14 16:12:02,591:INFO:Creating metrics dataframe
2025-06-14 16:12:02,595:INFO:Uploading results into container
2025-06-14 16:12:02,596:INFO:Uploading model into container now
2025-06-14 16:12:02,597:INFO:_master_model_container: 5
2025-06-14 16:12:02,597:INFO:_display_container: 2
2025-06-14 16:12:02,599:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-06-14 16:12:02,599:INFO:create_model() successfully completed......................................
2025-06-14 16:12:02,736:INFO:SubProcess create_model() end ==================================
2025-06-14 16:12:02,736:INFO:Creating metrics dataframe
2025-06-14 16:12:02,751:INFO:Initializing Ridge Classifier
2025-06-14 16:12:02,751:INFO:Total runtime is 0.3012567400932312 minutes
2025-06-14 16:12:02,777:INFO:SubProcess create_model() called ==================================
2025-06-14 16:12:02,779:INFO:Initializing create_model()
2025-06-14 16:12:02,779:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013CBD0A62C0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013CBD0A7160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:12:02,779:INFO:Checking exceptions
2025-06-14 16:12:02,780:INFO:Importing libraries
2025-06-14 16:12:02,780:INFO:Copying training dataset
2025-06-14 16:12:02,810:INFO:Defining folds
2025-06-14 16:12:02,810:INFO:Declaring metric variables
2025-06-14 16:12:02,819:INFO:Importing untrained model
2025-06-14 16:12:02,830:INFO:Ridge Classifier Imported successfully
2025-06-14 16:12:02,845:INFO:Starting cross validation
2025-06-14 16:12:02,847:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:12:02,932:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:02,939:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:12:02,961:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:02,963:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:02,966:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:02,967:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:02,967:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:02,975:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:02,975:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:02,977:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:12:02,978:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:02,980:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:12:02,980:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:02,980:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:12:02,981:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:12:02,984:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:12:02,986:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:12:02,989:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:12:02,992:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:12:02,993:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:12:03,020:INFO:Calculating mean and std
2025-06-14 16:12:03,022:INFO:Creating metrics dataframe
2025-06-14 16:12:03,022:INFO:Uploading results into container
2025-06-14 16:12:03,022:INFO:Uploading model into container now
2025-06-14 16:12:03,022:INFO:_master_model_container: 6
2025-06-14 16:12:03,022:INFO:_display_container: 2
2025-06-14 16:12:03,022:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-06-14 16:12:03,022:INFO:create_model() successfully completed......................................
2025-06-14 16:12:03,182:INFO:SubProcess create_model() end ==================================
2025-06-14 16:12:03,182:INFO:Creating metrics dataframe
2025-06-14 16:12:03,210:INFO:Initializing Random Forest Classifier
2025-06-14 16:12:03,210:INFO:Total runtime is 0.3089068412780762 minutes
2025-06-14 16:12:03,227:INFO:SubProcess create_model() called ==================================
2025-06-14 16:12:03,227:INFO:Initializing create_model()
2025-06-14 16:12:03,227:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013CBD0A62C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013CBD0A7160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:12:03,228:INFO:Checking exceptions
2025-06-14 16:12:03,228:INFO:Importing libraries
2025-06-14 16:12:03,228:INFO:Copying training dataset
2025-06-14 16:12:03,255:INFO:Defining folds
2025-06-14 16:12:03,255:INFO:Declaring metric variables
2025-06-14 16:12:03,271:INFO:Importing untrained model
2025-06-14 16:12:03,281:INFO:Random Forest Classifier Imported successfully
2025-06-14 16:12:03,297:INFO:Starting cross validation
2025-06-14 16:12:03,298:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:12:07,138:INFO:Calculating mean and std
2025-06-14 16:12:07,138:INFO:Creating metrics dataframe
2025-06-14 16:12:07,138:INFO:Uploading results into container
2025-06-14 16:12:07,138:INFO:Uploading model into container now
2025-06-14 16:12:07,138:INFO:_master_model_container: 7
2025-06-14 16:12:07,138:INFO:_display_container: 2
2025-06-14 16:12:07,138:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-06-14 16:12:07,138:INFO:create_model() successfully completed......................................
2025-06-14 16:12:07,288:INFO:SubProcess create_model() end ==================================
2025-06-14 16:12:07,288:INFO:Creating metrics dataframe
2025-06-14 16:12:07,319:INFO:Initializing Quadratic Discriminant Analysis
2025-06-14 16:12:07,319:INFO:Total runtime is 0.3773760318756104 minutes
2025-06-14 16:12:07,326:INFO:SubProcess create_model() called ==================================
2025-06-14 16:12:07,327:INFO:Initializing create_model()
2025-06-14 16:12:07,327:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013CBD0A62C0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013CBD0A7160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:12:07,327:INFO:Checking exceptions
2025-06-14 16:12:07,328:INFO:Importing libraries
2025-06-14 16:12:07,328:INFO:Copying training dataset
2025-06-14 16:12:07,353:INFO:Defining folds
2025-06-14 16:12:07,353:INFO:Declaring metric variables
2025-06-14 16:12:07,362:INFO:Importing untrained model
2025-06-14 16:12:07,362:INFO:Quadratic Discriminant Analysis Imported successfully
2025-06-14 16:12:07,379:INFO:Starting cross validation
2025-06-14 16:12:07,379:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:12:07,452:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:07,506:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:07,506:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:07,510:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:07,511:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:07,512:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:07,514:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:07,521:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:07,523:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:07,532:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:07,556:INFO:Calculating mean and std
2025-06-14 16:12:07,559:INFO:Creating metrics dataframe
2025-06-14 16:12:07,563:INFO:Uploading results into container
2025-06-14 16:12:07,564:INFO:Uploading model into container now
2025-06-14 16:12:07,565:INFO:_master_model_container: 8
2025-06-14 16:12:07,565:INFO:_display_container: 2
2025-06-14 16:12:07,566:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-06-14 16:12:07,566:INFO:create_model() successfully completed......................................
2025-06-14 16:12:07,705:INFO:SubProcess create_model() end ==================================
2025-06-14 16:12:07,705:INFO:Creating metrics dataframe
2025-06-14 16:12:07,724:INFO:Initializing Ada Boost Classifier
2025-06-14 16:12:07,724:INFO:Total runtime is 0.38413693904876717 minutes
2025-06-14 16:12:07,731:INFO:SubProcess create_model() called ==================================
2025-06-14 16:12:07,732:INFO:Initializing create_model()
2025-06-14 16:12:07,732:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013CBD0A62C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013CBD0A7160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:12:07,733:INFO:Checking exceptions
2025-06-14 16:12:07,733:INFO:Importing libraries
2025-06-14 16:12:07,733:INFO:Copying training dataset
2025-06-14 16:12:07,759:INFO:Defining folds
2025-06-14 16:12:07,759:INFO:Declaring metric variables
2025-06-14 16:12:07,759:INFO:Importing untrained model
2025-06-14 16:12:07,776:INFO:Ada Boost Classifier Imported successfully
2025-06-14 16:12:07,791:INFO:Starting cross validation
2025-06-14 16:12:07,791:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:12:07,846:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:12:07,852:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:12:07,861:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:12:07,862:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:12:07,868:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:12:07,869:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:12:07,872:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:12:07,877:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:12:07,880:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:12:07,893:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:12:09,192:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:09,202:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:09,228:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:09,244:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:09,268:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:09,268:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:09,268:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:09,314:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:09,328:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:09,328:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:09,375:INFO:Calculating mean and std
2025-06-14 16:12:09,375:INFO:Creating metrics dataframe
2025-06-14 16:12:09,375:INFO:Uploading results into container
2025-06-14 16:12:09,375:INFO:Uploading model into container now
2025-06-14 16:12:09,375:INFO:_master_model_container: 9
2025-06-14 16:12:09,375:INFO:_display_container: 2
2025-06-14 16:12:09,375:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-06-14 16:12:09,375:INFO:create_model() successfully completed......................................
2025-06-14 16:12:09,548:INFO:SubProcess create_model() end ==================================
2025-06-14 16:12:09,548:INFO:Creating metrics dataframe
2025-06-14 16:12:09,569:INFO:Initializing Gradient Boosting Classifier
2025-06-14 16:12:09,569:INFO:Total runtime is 0.41488179763158173 minutes
2025-06-14 16:12:09,577:INFO:SubProcess create_model() called ==================================
2025-06-14 16:12:09,577:INFO:Initializing create_model()
2025-06-14 16:12:09,577:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013CBD0A62C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013CBD0A7160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:12:09,577:INFO:Checking exceptions
2025-06-14 16:12:09,577:INFO:Importing libraries
2025-06-14 16:12:09,577:INFO:Copying training dataset
2025-06-14 16:12:09,611:INFO:Defining folds
2025-06-14 16:12:09,612:INFO:Declaring metric variables
2025-06-14 16:12:09,620:INFO:Importing untrained model
2025-06-14 16:12:09,626:INFO:Gradient Boosting Classifier Imported successfully
2025-06-14 16:12:09,640:INFO:Starting cross validation
2025-06-14 16:12:09,640:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:12:26,711:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:26,720:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:26,782:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:26,935:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:26,969:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:27,011:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:27,011:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:27,112:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:27,112:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:27,122:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:27,156:INFO:Calculating mean and std
2025-06-14 16:12:27,156:INFO:Creating metrics dataframe
2025-06-14 16:12:27,156:INFO:Uploading results into container
2025-06-14 16:12:27,156:INFO:Uploading model into container now
2025-06-14 16:12:27,156:INFO:_master_model_container: 10
2025-06-14 16:12:27,156:INFO:_display_container: 2
2025-06-14 16:12:27,156:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-14 16:12:27,156:INFO:create_model() successfully completed......................................
2025-06-14 16:12:27,306:INFO:SubProcess create_model() end ==================================
2025-06-14 16:12:27,306:INFO:Creating metrics dataframe
2025-06-14 16:12:27,328:INFO:Initializing Linear Discriminant Analysis
2025-06-14 16:12:27,328:INFO:Total runtime is 0.7108605662981671 minutes
2025-06-14 16:12:27,333:INFO:SubProcess create_model() called ==================================
2025-06-14 16:12:27,338:INFO:Initializing create_model()
2025-06-14 16:12:27,338:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013CBD0A62C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013CBD0A7160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:12:27,338:INFO:Checking exceptions
2025-06-14 16:12:27,338:INFO:Importing libraries
2025-06-14 16:12:27,338:INFO:Copying training dataset
2025-06-14 16:12:27,359:INFO:Defining folds
2025-06-14 16:12:27,359:INFO:Declaring metric variables
2025-06-14 16:12:27,362:INFO:Importing untrained model
2025-06-14 16:12:27,362:INFO:Linear Discriminant Analysis Imported successfully
2025-06-14 16:12:27,375:INFO:Starting cross validation
2025-06-14 16:12:27,375:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:12:27,440:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:27,474:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:27,479:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:27,479:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:27,481:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:27,483:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:27,490:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:27,494:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:27,496:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:27,500:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:12:27,538:INFO:Calculating mean and std
2025-06-14 16:12:27,539:INFO:Creating metrics dataframe
2025-06-14 16:12:27,539:INFO:Uploading results into container
2025-06-14 16:12:27,539:INFO:Uploading model into container now
2025-06-14 16:12:27,539:INFO:_master_model_container: 11
2025-06-14 16:12:27,539:INFO:_display_container: 2
2025-06-14 16:12:27,539:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-06-14 16:12:27,539:INFO:create_model() successfully completed......................................
2025-06-14 16:12:27,688:INFO:SubProcess create_model() end ==================================
2025-06-14 16:12:27,688:INFO:Creating metrics dataframe
2025-06-14 16:12:27,726:INFO:Initializing Extra Trees Classifier
2025-06-14 16:12:27,726:INFO:Total runtime is 0.7175035079320273 minutes
2025-06-14 16:12:27,730:INFO:SubProcess create_model() called ==================================
2025-06-14 16:12:27,730:INFO:Initializing create_model()
2025-06-14 16:12:27,730:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013CBD0A62C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013CBD0A7160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:12:27,730:INFO:Checking exceptions
2025-06-14 16:12:27,730:INFO:Importing libraries
2025-06-14 16:12:27,730:INFO:Copying training dataset
2025-06-14 16:12:27,757:INFO:Defining folds
2025-06-14 16:12:27,757:INFO:Declaring metric variables
2025-06-14 16:12:27,760:INFO:Importing untrained model
2025-06-14 16:12:27,771:INFO:Extra Trees Classifier Imported successfully
2025-06-14 16:12:27,774:INFO:Starting cross validation
2025-06-14 16:12:27,774:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:12:29,854:INFO:Calculating mean and std
2025-06-14 16:12:29,856:INFO:Creating metrics dataframe
2025-06-14 16:12:29,858:INFO:Uploading results into container
2025-06-14 16:12:29,858:INFO:Uploading model into container now
2025-06-14 16:12:29,858:INFO:_master_model_container: 12
2025-06-14 16:12:29,858:INFO:_display_container: 2
2025-06-14 16:12:29,858:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-06-14 16:12:29,858:INFO:create_model() successfully completed......................................
2025-06-14 16:12:30,012:INFO:SubProcess create_model() end ==================================
2025-06-14 16:12:30,012:INFO:Creating metrics dataframe
2025-06-14 16:12:30,022:INFO:Initializing Extreme Gradient Boosting
2025-06-14 16:12:30,022:INFO:Total runtime is 0.7557717283566794 minutes
2025-06-14 16:12:30,041:INFO:SubProcess create_model() called ==================================
2025-06-14 16:12:30,042:INFO:Initializing create_model()
2025-06-14 16:12:30,042:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013CBD0A62C0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013CBD0A7160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:12:30,042:INFO:Checking exceptions
2025-06-14 16:12:30,042:INFO:Importing libraries
2025-06-14 16:12:30,043:INFO:Copying training dataset
2025-06-14 16:12:30,056:INFO:Defining folds
2025-06-14 16:12:30,056:INFO:Declaring metric variables
2025-06-14 16:12:30,072:INFO:Importing untrained model
2025-06-14 16:12:30,082:INFO:Extreme Gradient Boosting Imported successfully
2025-06-14 16:12:30,089:INFO:Starting cross validation
2025-06-14 16:12:30,089:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:12:32,608:INFO:Calculating mean and std
2025-06-14 16:12:32,608:INFO:Creating metrics dataframe
2025-06-14 16:12:32,608:INFO:Uploading results into container
2025-06-14 16:12:32,608:INFO:Uploading model into container now
2025-06-14 16:12:32,616:INFO:_master_model_container: 13
2025-06-14 16:12:32,616:INFO:_display_container: 2
2025-06-14 16:12:32,616:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-06-14 16:12:32,616:INFO:create_model() successfully completed......................................
2025-06-14 16:12:32,765:INFO:SubProcess create_model() end ==================================
2025-06-14 16:12:32,765:INFO:Creating metrics dataframe
2025-06-14 16:12:32,790:INFO:Initializing Light Gradient Boosting Machine
2025-06-14 16:12:32,790:INFO:Total runtime is 0.8018919984499614 minutes
2025-06-14 16:12:32,805:INFO:SubProcess create_model() called ==================================
2025-06-14 16:12:32,805:INFO:Initializing create_model()
2025-06-14 16:12:32,805:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013CBD0A62C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013CBD0A7160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:12:32,806:INFO:Checking exceptions
2025-06-14 16:12:32,806:INFO:Importing libraries
2025-06-14 16:12:32,806:INFO:Copying training dataset
2025-06-14 16:12:32,841:INFO:Defining folds
2025-06-14 16:12:32,842:INFO:Declaring metric variables
2025-06-14 16:12:32,844:INFO:Importing untrained model
2025-06-14 16:12:32,864:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-14 16:12:32,884:INFO:Starting cross validation
2025-06-14 16:12:32,887:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:12:45,406:INFO:Calculating mean and std
2025-06-14 16:12:45,410:INFO:Creating metrics dataframe
2025-06-14 16:12:45,414:INFO:Uploading results into container
2025-06-14 16:12:45,415:INFO:Uploading model into container now
2025-06-14 16:12:45,416:INFO:_master_model_container: 14
2025-06-14 16:12:45,416:INFO:_display_container: 2
2025-06-14 16:12:45,417:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-06-14 16:12:45,417:INFO:create_model() successfully completed......................................
2025-06-14 16:12:45,553:INFO:SubProcess create_model() end ==================================
2025-06-14 16:12:45,553:INFO:Creating metrics dataframe
2025-06-14 16:12:45,576:INFO:Initializing Dummy Classifier
2025-06-14 16:12:45,576:INFO:Total runtime is 1.0149996399879455 minutes
2025-06-14 16:12:45,584:INFO:SubProcess create_model() called ==================================
2025-06-14 16:12:45,584:INFO:Initializing create_model()
2025-06-14 16:12:45,584:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013CBD0A62C0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013CBD0A7160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:12:45,585:INFO:Checking exceptions
2025-06-14 16:12:45,585:INFO:Importing libraries
2025-06-14 16:12:45,585:INFO:Copying training dataset
2025-06-14 16:12:45,612:INFO:Defining folds
2025-06-14 16:12:45,612:INFO:Declaring metric variables
2025-06-14 16:12:45,621:INFO:Importing untrained model
2025-06-14 16:12:45,628:INFO:Dummy Classifier Imported successfully
2025-06-14 16:12:45,642:INFO:Starting cross validation
2025-06-14 16:12:45,642:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:12:45,697:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:12:45,729:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:12:45,735:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:12:45,745:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:12:45,745:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:12:45,747:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:12:45,751:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:12:45,755:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:12:45,762:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:12:45,762:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:12:45,791:INFO:Calculating mean and std
2025-06-14 16:12:45,794:INFO:Creating metrics dataframe
2025-06-14 16:12:45,797:INFO:Uploading results into container
2025-06-14 16:12:45,798:INFO:Uploading model into container now
2025-06-14 16:12:45,799:INFO:_master_model_container: 15
2025-06-14 16:12:45,799:INFO:_display_container: 2
2025-06-14 16:12:45,799:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-06-14 16:12:45,800:INFO:create_model() successfully completed......................................
2025-06-14 16:12:45,940:INFO:SubProcess create_model() end ==================================
2025-06-14 16:12:45,940:INFO:Creating metrics dataframe
2025-06-14 16:12:45,979:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-06-14 16:12:45,996:INFO:Initializing create_model()
2025-06-14 16:12:45,996:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013CBD0A62C0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:12:45,997:INFO:Checking exceptions
2025-06-14 16:12:46,000:INFO:Importing libraries
2025-06-14 16:12:46,000:INFO:Copying training dataset
2025-06-14 16:12:46,007:INFO:Defining folds
2025-06-14 16:12:46,007:INFO:Declaring metric variables
2025-06-14 16:12:46,007:INFO:Importing untrained model
2025-06-14 16:12:46,007:INFO:Declaring custom model
2025-06-14 16:12:46,022:INFO:Gradient Boosting Classifier Imported successfully
2025-06-14 16:12:46,023:INFO:Cross validation set to False
2025-06-14 16:12:46,023:INFO:Fitting Model
2025-06-14 16:13:02,993:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-14 16:13:02,993:INFO:create_model() successfully completed......................................
2025-06-14 16:13:03,195:INFO:_master_model_container: 15
2025-06-14 16:13:03,195:INFO:_display_container: 2
2025-06-14 16:13:03,195:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-14 16:13:03,195:INFO:compare_models() successfully completed......................................
2025-06-14 16:13:03,426:INFO:Initializing create_model()
2025-06-14 16:13:03,426:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013CBD0A62C0>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced'})
2025-06-14 16:13:03,426:INFO:Checking exceptions
2025-06-14 16:13:03,459:INFO:Importing libraries
2025-06-14 16:13:03,459:INFO:Copying training dataset
2025-06-14 16:13:03,484:INFO:Defining folds
2025-06-14 16:13:03,484:INFO:Declaring metric variables
2025-06-14 16:13:03,491:INFO:Importing untrained model
2025-06-14 16:13:03,499:INFO:Extreme Gradient Boosting Imported successfully
2025-06-14 16:13:03,506:INFO:Starting cross validation
2025-06-14 16:13:03,506:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:13:06,043:INFO:Calculating mean and std
2025-06-14 16:13:06,046:INFO:Creating metrics dataframe
2025-06-14 16:13:06,057:INFO:Finalizing model
2025-06-14 16:13:07,066:INFO:Uploading results into container
2025-06-14 16:13:07,067:INFO:Uploading model into container now
2025-06-14 16:13:07,084:INFO:_master_model_container: 16
2025-06-14 16:13:07,084:INFO:_display_container: 3
2025-06-14 16:13:07,085:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1, ...)
2025-06-14 16:13:07,087:INFO:create_model() successfully completed......................................
2025-06-14 16:13:07,444:INFO:Initializing tune_model()
2025-06-14 16:13:07,444:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1, ...), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013CBD0A62C0>)
2025-06-14 16:13:07,445:INFO:Checking exceptions
2025-06-14 16:13:07,476:INFO:Copying training dataset
2025-06-14 16:13:07,492:INFO:Checking base model
2025-06-14 16:13:07,492:INFO:Base model : Extreme Gradient Boosting
2025-06-14 16:13:07,492:INFO:Declaring metric variables
2025-06-14 16:13:07,508:INFO:Defining Hyperparameters
2025-06-14 16:13:07,650:INFO:Tuning with n_jobs=-1
2025-06-14 16:13:07,650:INFO:Initializing RandomizedSearchCV
2025-06-14 16:13:27,389:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__scale_pos_weight': 38.0, 'actual_estimator__reg_lambda': 0.7, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__n_estimators': 60, 'actual_estimator__min_child_weight': 1, 'actual_estimator__max_depth': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__colsample_bytree': 0.7}
2025-06-14 16:13:27,391:INFO:Hyperparameter search completed
2025-06-14 16:13:27,391:INFO:SubProcess create_model() called ==================================
2025-06-14 16:13:27,393:INFO:Initializing create_model()
2025-06-14 16:13:27,393:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013CBD0A62C0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000013CC062B3A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'scale_pos_weight': 38.0, 'reg_lambda': 0.7, 'reg_alpha': 0.001, 'n_estimators': 60, 'min_child_weight': 1, 'max_depth': 6, 'learning_rate': 0.4, 'colsample_bytree': 0.7})
2025-06-14 16:13:27,393:INFO:Checking exceptions
2025-06-14 16:13:27,393:INFO:Importing libraries
2025-06-14 16:13:27,393:INFO:Copying training dataset
2025-06-14 16:13:27,415:INFO:Defining folds
2025-06-14 16:13:27,415:INFO:Declaring metric variables
2025-06-14 16:13:27,423:INFO:Importing untrained model
2025-06-14 16:13:27,424:INFO:Declaring custom model
2025-06-14 16:13:27,433:INFO:Extreme Gradient Boosting Imported successfully
2025-06-14 16:13:27,441:INFO:Starting cross validation
2025-06-14 16:13:27,447:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:13:28,951:INFO:Calculating mean and std
2025-06-14 16:13:28,951:INFO:Creating metrics dataframe
2025-06-14 16:13:28,958:INFO:Finalizing model
2025-06-14 16:13:29,639:INFO:Uploading results into container
2025-06-14 16:13:29,640:INFO:Uploading model into container now
2025-06-14 16:13:29,640:INFO:_master_model_container: 17
2025-06-14 16:13:29,642:INFO:_display_container: 4
2025-06-14 16:13:29,642:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=0.7, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=-1, ...)
2025-06-14 16:13:29,644:INFO:create_model() successfully completed......................................
2025-06-14 16:13:29,801:INFO:SubProcess create_model() end ==================================
2025-06-14 16:13:29,801:INFO:choose_better activated
2025-06-14 16:13:29,816:INFO:SubProcess create_model() called ==================================
2025-06-14 16:13:29,816:INFO:Initializing create_model()
2025-06-14 16:13:29,816:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013CBD0A62C0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:13:29,816:INFO:Checking exceptions
2025-06-14 16:13:29,816:INFO:Importing libraries
2025-06-14 16:13:29,816:INFO:Copying training dataset
2025-06-14 16:13:29,863:INFO:Defining folds
2025-06-14 16:13:29,863:INFO:Declaring metric variables
2025-06-14 16:13:29,863:INFO:Importing untrained model
2025-06-14 16:13:29,864:INFO:Declaring custom model
2025-06-14 16:13:29,867:INFO:Extreme Gradient Boosting Imported successfully
2025-06-14 16:13:29,867:INFO:Starting cross validation
2025-06-14 16:13:29,869:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:13:32,289:INFO:Calculating mean and std
2025-06-14 16:13:32,289:INFO:Creating metrics dataframe
2025-06-14 16:13:32,289:INFO:Finalizing model
2025-06-14 16:13:33,333:INFO:Uploading results into container
2025-06-14 16:13:33,334:INFO:Uploading model into container now
2025-06-14 16:13:33,334:INFO:_master_model_container: 18
2025-06-14 16:13:33,334:INFO:_display_container: 5
2025-06-14 16:13:33,336:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1, ...)
2025-06-14 16:13:33,336:INFO:create_model() successfully completed......................................
2025-06-14 16:13:33,478:INFO:SubProcess create_model() end ==================================
2025-06-14 16:13:33,480:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1, ...) result for F1 is 0.7442
2025-06-14 16:13:33,482:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=0.7, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=-1, ...) result for F1 is 0.7498
2025-06-14 16:13:33,483:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=0.7, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=-1, ...) is best model
2025-06-14 16:13:33,484:INFO:choose_better completed
2025-06-14 16:13:33,502:INFO:_master_model_container: 18
2025-06-14 16:13:33,502:INFO:_display_container: 4
2025-06-14 16:13:33,504:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=0.7, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=-1, ...)
2025-06-14 16:13:33,505:INFO:tune_model() successfully completed......................................
2025-06-14 16:13:33,680:INFO:Initializing finalize_model()
2025-06-14 16:13:33,680:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013CBD0A62C0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=0.7, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=-1, ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-14 16:13:33,680:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=0.7, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=-1, ...)
2025-06-14 16:13:33,709:INFO:Initializing create_model()
2025-06-14 16:13:33,709:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013CBD0A62C0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=0.7, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=-1, ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:13:33,709:INFO:Checking exceptions
2025-06-14 16:13:33,714:INFO:Importing libraries
2025-06-14 16:13:33,714:INFO:Copying training dataset
2025-06-14 16:13:33,717:INFO:Defining folds
2025-06-14 16:13:33,717:INFO:Declaring metric variables
2025-06-14 16:13:33,718:INFO:Importing untrained model
2025-06-14 16:13:33,718:INFO:Declaring custom model
2025-06-14 16:13:33,722:INFO:Extreme Gradient Boosting Imported successfully
2025-06-14 16:13:33,723:INFO:Cross validation set to False
2025-06-14 16:13:33,723:INFO:Fitting Model
2025-06-14 16:13:34,435:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['isSchool', 'rental_count',
                                             'return_count', 'apart',
                                             'closest_hospital_dist',
                                             'closest_convenience_dist',
                                             'closest_culture_dist', 'age_20s',
                                             'age_30s', 'age_40s',
                                             'crosswalk_count',
                                             'closest_cross_dist', 'bus_count',
                                             'closest_bus_dist', 'subway_count',
                                             'clos...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=-1, ...))],
         verbose=False)
2025-06-14 16:13:34,437:INFO:create_model() successfully completed......................................
2025-06-14 16:13:34,595:INFO:_master_model_container: 18
2025-06-14 16:13:34,595:INFO:_display_container: 4
2025-06-14 16:13:34,610:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['isSchool', 'rental_count',
                                             'return_count', 'apart',
                                             'closest_hospital_dist',
                                             'closest_convenience_dist',
                                             'closest_culture_dist', 'age_20s',
                                             'age_30s', 'age_40s',
                                             'crosswalk_count',
                                             'closest_cross_dist', 'bus_count',
                                             'closest_bus_dist', 'subway_count',
                                             'clos...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=-1, ...))],
         verbose=False)
2025-06-14 16:13:34,610:INFO:finalize_model() successfully completed......................................
2025-06-14 16:13:34,778:INFO:Initializing predict_model()
2025-06-14 16:13:34,778:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000013CBD0A62C0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['isSchool', 'rental_count',
                                             'return_count', 'apart',
                                             'closest_hospital_dist',
                                             'closest_convenience_dist',
                                             'closest_culture_dist', 'age_20s',
                                             'age_30s', 'age_40s',
                                             'crosswalk_count',
                                             'closest_cross_dist', 'bus_count',
                                             'closest_bus_dist', 'subway_count',
                                             'clos...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=-1, ...))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000013CC05CBB50>)
2025-06-14 16:13:34,778:INFO:Checking exceptions
2025-06-14 16:13:34,778:INFO:Preloading libraries
2025-06-14 16:13:34,778:INFO:Set up data.
2025-06-14 16:13:34,806:INFO:Set up index.
2025-06-14 16:31:28,904:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-14 16:31:28,905:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-14 16:31:28,905:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-14 16:31:28,905:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-14 16:31:31,507:INFO:PyCaret ClassificationExperiment
2025-06-14 16:31:31,507:INFO:Logging name: clf-default-name
2025-06-14 16:31:31,507:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-14 16:31:31,507:INFO:version 3.3.2
2025-06-14 16:31:31,507:INFO:Initializing setup()
2025-06-14 16:31:31,507:INFO:self.USI: 45fc
2025-06-14 16:31:31,507:INFO:self._variable_keys: {'X_train', 'gpu_param', 'n_jobs_param', 'memory', 'fix_imbalance', 'USI', 'pipeline', 'y', 'gpu_n_jobs_param', 'logging_param', 'log_plots_param', 'y_test', 'html_param', 'is_multiclass', 'fold_shuffle_param', 'X', 'fold_groups_param', 'exp_id', 'idx', '_ml_usecase', 'target_param', 'exp_name_log', 'y_train', '_available_plots', 'data', 'X_test', 'fold_generator', 'seed'}
2025-06-14 16:31:31,507:INFO:Checking environment
2025-06-14 16:31:31,507:INFO:python_version: 3.10.16
2025-06-14 16:31:31,507:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-14 16:31:31,507:INFO:machine: AMD64
2025-06-14 16:31:31,507:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-14 16:31:31,507:INFO:Memory: svmem(total=33885192192, available=17754169344, percent=47.6, used=16131022848, free=17754169344)
2025-06-14 16:31:31,507:INFO:Physical Core: 14
2025-06-14 16:31:31,507:INFO:Logical Core: 18
2025-06-14 16:31:31,521:INFO:Checking libraries
2025-06-14 16:31:31,521:INFO:System:
2025-06-14 16:31:31,521:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-14 16:31:31,521:INFO:executable: C:\Users\omslu\anaconda3\envs\pycaret_env\python.exe
2025-06-14 16:31:31,521:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-14 16:31:31,521:INFO:PyCaret required dependencies:
2025-06-14 16:31:31,581:INFO:                 pip: 25.1
2025-06-14 16:31:31,581:INFO:          setuptools: 78.1.1
2025-06-14 16:31:31,581:INFO:             pycaret: 3.3.2
2025-06-14 16:31:31,582:INFO:             IPython: 8.37.0
2025-06-14 16:31:31,582:INFO:          ipywidgets: 8.1.7
2025-06-14 16:31:31,582:INFO:                tqdm: 4.67.1
2025-06-14 16:31:31,582:INFO:               numpy: 1.26.4
2025-06-14 16:31:31,582:INFO:              pandas: 2.1.4
2025-06-14 16:31:31,582:INFO:              jinja2: 3.1.6
2025-06-14 16:31:31,582:INFO:               scipy: 1.11.4
2025-06-14 16:31:31,582:INFO:              joblib: 1.3.2
2025-06-14 16:31:31,582:INFO:             sklearn: 1.4.2
2025-06-14 16:31:31,583:INFO:                pyod: 2.0.5
2025-06-14 16:31:31,583:INFO:            imblearn: 0.13.0
2025-06-14 16:31:31,583:INFO:   category_encoders: 2.7.0
2025-06-14 16:31:31,583:INFO:            lightgbm: 4.6.0
2025-06-14 16:31:31,583:INFO:               numba: 0.61.2
2025-06-14 16:31:31,583:INFO:            requests: 2.32.3
2025-06-14 16:31:31,583:INFO:          matplotlib: 3.7.5
2025-06-14 16:31:31,583:INFO:          scikitplot: 0.3.7
2025-06-14 16:31:31,583:INFO:         yellowbrick: 1.5
2025-06-14 16:31:31,583:INFO:              plotly: 5.24.1
2025-06-14 16:31:31,584:INFO:    plotly-resampler: Not installed
2025-06-14 16:31:31,584:INFO:             kaleido: 0.2.1
2025-06-14 16:31:31,584:INFO:           schemdraw: 0.15
2025-06-14 16:31:31,584:INFO:         statsmodels: 0.14.4
2025-06-14 16:31:31,584:INFO:              sktime: 0.26.0
2025-06-14 16:31:31,584:INFO:               tbats: 1.1.3
2025-06-14 16:31:31,584:INFO:            pmdarima: 2.0.4
2025-06-14 16:31:31,584:INFO:              psutil: 7.0.0
2025-06-14 16:31:31,584:INFO:          markupsafe: 3.0.2
2025-06-14 16:31:31,584:INFO:             pickle5: Not installed
2025-06-14 16:31:31,585:INFO:         cloudpickle: 3.1.1
2025-06-14 16:31:31,585:INFO:         deprecation: 2.1.0
2025-06-14 16:31:31,585:INFO:              xxhash: 3.5.0
2025-06-14 16:31:31,585:INFO:           wurlitzer: Not installed
2025-06-14 16:31:31,585:INFO:PyCaret optional dependencies:
2025-06-14 16:31:31,685:INFO:                shap: 0.47.2
2025-06-14 16:31:31,685:INFO:           interpret: Not installed
2025-06-14 16:31:31,685:INFO:                umap: Not installed
2025-06-14 16:31:31,685:INFO:     ydata_profiling: Not installed
2025-06-14 16:31:31,685:INFO:  explainerdashboard: Not installed
2025-06-14 16:31:31,685:INFO:             autoviz: Not installed
2025-06-14 16:31:31,685:INFO:           fairlearn: Not installed
2025-06-14 16:31:31,685:INFO:          deepchecks: Not installed
2025-06-14 16:31:31,685:INFO:             xgboost: 3.0.2
2025-06-14 16:31:31,685:INFO:            catboost: Not installed
2025-06-14 16:31:31,685:INFO:              kmodes: Not installed
2025-06-14 16:31:31,685:INFO:             mlxtend: Not installed
2025-06-14 16:31:31,685:INFO:       statsforecast: Not installed
2025-06-14 16:31:31,685:INFO:        tune_sklearn: Not installed
2025-06-14 16:31:31,685:INFO:                 ray: Not installed
2025-06-14 16:31:31,685:INFO:            hyperopt: Not installed
2025-06-14 16:31:31,685:INFO:              optuna: Not installed
2025-06-14 16:31:31,685:INFO:               skopt: Not installed
2025-06-14 16:31:31,685:INFO:              mlflow: Not installed
2025-06-14 16:31:31,685:INFO:              gradio: Not installed
2025-06-14 16:31:31,685:INFO:             fastapi: Not installed
2025-06-14 16:31:31,685:INFO:             uvicorn: Not installed
2025-06-14 16:31:31,685:INFO:              m2cgen: Not installed
2025-06-14 16:31:31,685:INFO:           evidently: Not installed
2025-06-14 16:31:31,685:INFO:               fugue: Not installed
2025-06-14 16:31:31,685:INFO:           streamlit: Not installed
2025-06-14 16:31:31,685:INFO:             prophet: Not installed
2025-06-14 16:31:31,685:INFO:None
2025-06-14 16:31:31,685:INFO:Set up data.
2025-06-14 16:31:31,726:INFO:Set up folding strategy.
2025-06-14 16:31:31,726:INFO:Set up train/test split.
2025-06-14 16:31:31,748:INFO:Set up index.
2025-06-14 16:31:31,748:INFO:Assigning column types.
2025-06-14 16:31:31,779:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-14 16:31:31,926:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-14 16:31:31,945:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-14 16:31:32,063:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:31:32,067:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:31:32,257:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-14 16:31:32,257:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-14 16:31:32,352:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:31:32,368:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:31:32,368:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-14 16:31:32,514:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-14 16:31:32,618:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:31:32,627:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:31:32,768:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-14 16:31:32,863:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:31:32,878:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:31:32,878:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-06-14 16:31:33,131:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:31:33,131:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:31:33,382:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:31:33,382:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:31:33,398:INFO:Preparing preprocessing pipeline...
2025-06-14 16:31:33,398:INFO:Set up simple imputation.
2025-06-14 16:31:33,492:INFO:Finished creating preprocessing pipeline.
2025-06-14 16:31:33,508:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\omslu\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['isSchool', 'rental_count',
                                             'return_count', 'apart',
                                             'closest_hospital_dist',
                                             'closest_convenience_dist',
                                             'closest_culture_dist', 'age_20s',
                                             'age_30s', 'age_40s',
                                             'crosswalk_count',
                                             'closest_cross_dist', 'bus_count'...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-06-14 16:31:33,508:INFO:Creating final display dataframe.
2025-06-14 16:31:33,828:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target        risk_level
2                   Target type        Multiclass
3           Original data shape        (7680, 28)
4        Transformed data shape        (7680, 28)
5   Transformed train set shape        (5376, 28)
6    Transformed test set shape        (2304, 28)
7              Numeric features                27
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              45fc
2025-06-14 16:31:34,093:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:31:34,108:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:31:34,428:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:31:34,439:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:31:34,439:INFO:setup() successfully completed in 2.94s...............
2025-06-14 16:31:34,466:INFO:Initializing compare_models()
2025-06-14 16:31:34,466:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BDBC5ED40>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000021BDBC5ED40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-06-14 16:31:34,467:INFO:Checking exceptions
2025-06-14 16:31:34,499:INFO:Preparing display monitor
2025-06-14 16:31:34,561:INFO:Initializing Logistic Regression
2025-06-14 16:31:34,561:INFO:Total runtime is 0.0 minutes
2025-06-14 16:31:34,570:INFO:SubProcess create_model() called ==================================
2025-06-14 16:31:34,570:INFO:Initializing create_model()
2025-06-14 16:31:34,571:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BDBC5ED40>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BDF481CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:31:34,571:INFO:Checking exceptions
2025-06-14 16:31:34,571:INFO:Importing libraries
2025-06-14 16:31:34,571:INFO:Copying training dataset
2025-06-14 16:31:34,594:INFO:Defining folds
2025-06-14 16:31:34,594:INFO:Declaring metric variables
2025-06-14 16:31:34,602:INFO:Importing untrained model
2025-06-14 16:31:34,608:INFO:Logistic Regression Imported successfully
2025-06-14 16:31:34,622:INFO:Starting cross validation
2025-06-14 16:31:34,624:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:31:43,639:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:43,753:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:43,800:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:43,851:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:43,968:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:44,102:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:44,276:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:44,323:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:44,425:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:44,507:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-14 16:31:44,535:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:44,567:INFO:Calculating mean and std
2025-06-14 16:31:44,567:INFO:Creating metrics dataframe
2025-06-14 16:31:44,576:INFO:Uploading results into container
2025-06-14 16:31:44,576:INFO:Uploading model into container now
2025-06-14 16:31:44,578:INFO:_master_model_container: 1
2025-06-14 16:31:44,578:INFO:_display_container: 2
2025-06-14 16:31:44,578:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-14 16:31:44,578:INFO:create_model() successfully completed......................................
2025-06-14 16:31:44,753:INFO:SubProcess create_model() end ==================================
2025-06-14 16:31:44,753:INFO:Creating metrics dataframe
2025-06-14 16:31:44,756:INFO:Initializing K Neighbors Classifier
2025-06-14 16:31:44,756:INFO:Total runtime is 0.16991669336954754 minutes
2025-06-14 16:31:44,772:INFO:SubProcess create_model() called ==================================
2025-06-14 16:31:44,772:INFO:Initializing create_model()
2025-06-14 16:31:44,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BDBC5ED40>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BDF481CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:31:44,772:INFO:Checking exceptions
2025-06-14 16:31:44,772:INFO:Importing libraries
2025-06-14 16:31:44,772:INFO:Copying training dataset
2025-06-14 16:31:44,806:INFO:Defining folds
2025-06-14 16:31:44,806:INFO:Declaring metric variables
2025-06-14 16:31:44,813:INFO:Importing untrained model
2025-06-14 16:31:44,819:INFO:K Neighbors Classifier Imported successfully
2025-06-14 16:31:44,835:INFO:Starting cross validation
2025-06-14 16:31:44,837:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:31:47,393:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-14 16:31:47,393:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-14 16:31:47,393:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-14 16:31:47,393:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-14 16:31:50,509:INFO:PyCaret ClassificationExperiment
2025-06-14 16:31:50,509:INFO:Logging name: clf-default-name
2025-06-14 16:31:50,510:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-14 16:31:50,510:INFO:version 3.3.2
2025-06-14 16:31:50,510:INFO:Initializing setup()
2025-06-14 16:31:50,510:INFO:self.USI: d46f
2025-06-14 16:31:50,510:INFO:self._variable_keys: {'n_jobs_param', 'log_plots_param', 'gpu_n_jobs_param', 'gpu_param', 'fold_groups_param', 'exp_id', 'y', 'X', 'target_param', 'is_multiclass', 'pipeline', 'seed', 'data', '_ml_usecase', 'y_test', 'y_train', '_available_plots', 'fold_generator', 'fold_shuffle_param', 'X_train', 'exp_name_log', 'html_param', 'idx', 'USI', 'fix_imbalance', 'logging_param', 'X_test', 'memory'}
2025-06-14 16:31:50,510:INFO:Checking environment
2025-06-14 16:31:50,510:INFO:python_version: 3.10.16
2025-06-14 16:31:50,510:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-14 16:31:50,510:INFO:machine: AMD64
2025-06-14 16:31:50,510:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-14 16:31:50,520:INFO:Memory: svmem(total=33885192192, available=15315136512, percent=54.8, used=18570055680, free=15315136512)
2025-06-14 16:31:50,521:INFO:Physical Core: 14
2025-06-14 16:31:50,521:INFO:Logical Core: 18
2025-06-14 16:31:50,521:INFO:Checking libraries
2025-06-14 16:31:50,521:INFO:System:
2025-06-14 16:31:50,522:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-14 16:31:50,522:INFO:executable: C:\Users\omslu\anaconda3\envs\pycaret_env\python.exe
2025-06-14 16:31:50,522:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-14 16:31:50,522:INFO:PyCaret required dependencies:
2025-06-14 16:31:50,581:INFO:                 pip: 25.1
2025-06-14 16:31:50,581:INFO:          setuptools: 78.1.1
2025-06-14 16:31:50,581:INFO:             pycaret: 3.3.2
2025-06-14 16:31:50,581:INFO:             IPython: 8.37.0
2025-06-14 16:31:50,581:INFO:          ipywidgets: 8.1.7
2025-06-14 16:31:50,581:INFO:                tqdm: 4.67.1
2025-06-14 16:31:50,581:INFO:               numpy: 1.26.4
2025-06-14 16:31:50,581:INFO:              pandas: 2.1.4
2025-06-14 16:31:50,581:INFO:              jinja2: 3.1.6
2025-06-14 16:31:50,582:INFO:               scipy: 1.11.4
2025-06-14 16:31:50,582:INFO:              joblib: 1.3.2
2025-06-14 16:31:50,582:INFO:             sklearn: 1.4.2
2025-06-14 16:31:50,582:INFO:                pyod: 2.0.5
2025-06-14 16:31:50,582:INFO:            imblearn: 0.13.0
2025-06-14 16:31:50,582:INFO:   category_encoders: 2.7.0
2025-06-14 16:31:50,582:INFO:            lightgbm: 4.6.0
2025-06-14 16:31:50,583:INFO:               numba: 0.61.2
2025-06-14 16:31:50,583:INFO:            requests: 2.32.3
2025-06-14 16:31:50,583:INFO:          matplotlib: 3.7.5
2025-06-14 16:31:50,583:INFO:          scikitplot: 0.3.7
2025-06-14 16:31:50,583:INFO:         yellowbrick: 1.5
2025-06-14 16:31:50,583:INFO:              plotly: 5.24.1
2025-06-14 16:31:50,584:INFO:    plotly-resampler: Not installed
2025-06-14 16:31:50,584:INFO:             kaleido: 0.2.1
2025-06-14 16:31:50,584:INFO:           schemdraw: 0.15
2025-06-14 16:31:50,584:INFO:         statsmodels: 0.14.4
2025-06-14 16:31:50,584:INFO:              sktime: 0.26.0
2025-06-14 16:31:50,584:INFO:               tbats: 1.1.3
2025-06-14 16:31:50,584:INFO:            pmdarima: 2.0.4
2025-06-14 16:31:50,584:INFO:              psutil: 7.0.0
2025-06-14 16:31:50,584:INFO:          markupsafe: 3.0.2
2025-06-14 16:31:50,584:INFO:             pickle5: Not installed
2025-06-14 16:31:50,584:INFO:         cloudpickle: 3.1.1
2025-06-14 16:31:50,585:INFO:         deprecation: 2.1.0
2025-06-14 16:31:50,585:INFO:              xxhash: 3.5.0
2025-06-14 16:31:50,585:INFO:           wurlitzer: Not installed
2025-06-14 16:31:50,585:INFO:PyCaret optional dependencies:
2025-06-14 16:31:50,680:INFO:                shap: 0.47.2
2025-06-14 16:31:50,680:INFO:           interpret: Not installed
2025-06-14 16:31:50,680:INFO:                umap: Not installed
2025-06-14 16:31:50,680:INFO:     ydata_profiling: Not installed
2025-06-14 16:31:50,680:INFO:  explainerdashboard: Not installed
2025-06-14 16:31:50,680:INFO:             autoviz: Not installed
2025-06-14 16:31:50,680:INFO:           fairlearn: Not installed
2025-06-14 16:31:50,680:INFO:          deepchecks: Not installed
2025-06-14 16:31:50,680:INFO:             xgboost: 3.0.2
2025-06-14 16:31:50,680:INFO:            catboost: Not installed
2025-06-14 16:31:50,680:INFO:              kmodes: Not installed
2025-06-14 16:31:50,680:INFO:             mlxtend: Not installed
2025-06-14 16:31:50,680:INFO:       statsforecast: Not installed
2025-06-14 16:31:50,680:INFO:        tune_sklearn: Not installed
2025-06-14 16:31:50,683:INFO:                 ray: Not installed
2025-06-14 16:31:50,683:INFO:            hyperopt: Not installed
2025-06-14 16:31:50,683:INFO:              optuna: Not installed
2025-06-14 16:31:50,683:INFO:               skopt: Not installed
2025-06-14 16:31:50,683:INFO:              mlflow: Not installed
2025-06-14 16:31:50,683:INFO:              gradio: Not installed
2025-06-14 16:31:50,683:INFO:             fastapi: Not installed
2025-06-14 16:31:50,683:INFO:             uvicorn: Not installed
2025-06-14 16:31:50,683:INFO:              m2cgen: Not installed
2025-06-14 16:31:50,683:INFO:           evidently: Not installed
2025-06-14 16:31:50,683:INFO:               fugue: Not installed
2025-06-14 16:31:50,683:INFO:           streamlit: Not installed
2025-06-14 16:31:50,683:INFO:             prophet: Not installed
2025-06-14 16:31:50,683:INFO:None
2025-06-14 16:31:50,683:INFO:Set up data.
2025-06-14 16:31:50,726:INFO:Set up folding strategy.
2025-06-14 16:31:50,726:INFO:Set up train/test split.
2025-06-14 16:31:50,752:INFO:Set up index.
2025-06-14 16:31:50,754:INFO:Assigning column types.
2025-06-14 16:31:50,779:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-14 16:31:50,975:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-14 16:31:50,986:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-14 16:31:51,106:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:31:51,111:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:31:51,309:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-14 16:31:51,313:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-14 16:31:51,401:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:31:51,416:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:31:51,417:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-14 16:31:51,578:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-14 16:31:51,636:INFO:Calculating mean and std
2025-06-14 16:31:51,641:INFO:Creating metrics dataframe
2025-06-14 16:31:51,645:INFO:Uploading results into container
2025-06-14 16:31:51,646:INFO:Uploading model into container now
2025-06-14 16:31:51,647:INFO:_master_model_container: 2
2025-06-14 16:31:51,649:INFO:_display_container: 2
2025-06-14 16:31:51,649:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-14 16:31:51,650:INFO:create_model() successfully completed......................................
2025-06-14 16:31:51,675:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:31:51,684:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:31:51,805:INFO:SubProcess create_model() end ==================================
2025-06-14 16:31:51,805:INFO:Creating metrics dataframe
2025-06-14 16:31:51,806:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-14 16:31:51,806:INFO:Initializing Naive Bayes
2025-06-14 16:31:51,806:INFO:Total runtime is 0.2874164899190267 minutes
2025-06-14 16:31:51,826:INFO:SubProcess create_model() called ==================================
2025-06-14 16:31:51,828:INFO:Initializing create_model()
2025-06-14 16:31:51,828:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BDBC5ED40>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BDF481CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:31:51,828:INFO:Checking exceptions
2025-06-14 16:31:51,828:INFO:Importing libraries
2025-06-14 16:31:51,829:INFO:Copying training dataset
2025-06-14 16:31:51,847:INFO:Defining folds
2025-06-14 16:31:51,847:INFO:Declaring metric variables
2025-06-14 16:31:51,857:INFO:Importing untrained model
2025-06-14 16:31:51,860:INFO:Naive Bayes Imported successfully
2025-06-14 16:31:51,876:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:31:51,878:INFO:Starting cross validation
2025-06-14 16:31:51,879:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:31:51,883:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:31:51,884:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-06-14 16:31:52,058:INFO:Calculating mean and std
2025-06-14 16:31:52,060:INFO:Creating metrics dataframe
2025-06-14 16:31:52,064:INFO:Uploading results into container
2025-06-14 16:31:52,066:INFO:Uploading model into container now
2025-06-14 16:31:52,067:INFO:_master_model_container: 3
2025-06-14 16:31:52,067:INFO:_display_container: 2
2025-06-14 16:31:52,067:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-06-14 16:31:52,067:INFO:create_model() successfully completed......................................
2025-06-14 16:31:52,128:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:31:52,137:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:31:52,222:INFO:SubProcess create_model() end ==================================
2025-06-14 16:31:52,222:INFO:Creating metrics dataframe
2025-06-14 16:31:52,239:INFO:Initializing Decision Tree Classifier
2025-06-14 16:31:52,241:INFO:Total runtime is 0.29466996987660726 minutes
2025-06-14 16:31:52,241:INFO:SubProcess create_model() called ==================================
2025-06-14 16:31:52,241:INFO:Initializing create_model()
2025-06-14 16:31:52,241:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BDBC5ED40>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BDF481CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:31:52,241:INFO:Checking exceptions
2025-06-14 16:31:52,241:INFO:Importing libraries
2025-06-14 16:31:52,241:INFO:Copying training dataset
2025-06-14 16:31:52,279:INFO:Defining folds
2025-06-14 16:31:52,279:INFO:Declaring metric variables
2025-06-14 16:31:52,287:INFO:Importing untrained model
2025-06-14 16:31:52,294:INFO:Decision Tree Classifier Imported successfully
2025-06-14 16:31:52,304:INFO:Starting cross validation
2025-06-14 16:31:52,304:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:31:52,345:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:31:52,355:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:31:52,360:INFO:Preparing preprocessing pipeline...
2025-06-14 16:31:52,365:INFO:Set up simple imputation.
2025-06-14 16:31:52,464:INFO:Finished creating preprocessing pipeline.
2025-06-14 16:31:52,488:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\omslu\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['isSchool', 'rental_count',
                                             'return_count', 'apart',
                                             'closest_hospital_dist',
                                             'closest_convenience_dist',
                                             'closest_culture_dist', 'age_20s',
                                             'age_30s', 'age_40s',
                                             'crosswalk_count',
                                             'closest_cross_dist', 'bus_count'...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-06-14 16:31:52,488:INFO:Creating final display dataframe.
2025-06-14 16:31:52,807:INFO:Calculating mean and std
2025-06-14 16:31:52,809:INFO:Creating metrics dataframe
2025-06-14 16:31:52,809:INFO:Uploading results into container
2025-06-14 16:31:52,809:INFO:Uploading model into container now
2025-06-14 16:31:52,809:INFO:_master_model_container: 4
2025-06-14 16:31:52,809:INFO:_display_container: 2
2025-06-14 16:31:52,809:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-06-14 16:31:52,809:INFO:create_model() successfully completed......................................
2025-06-14 16:31:52,823:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target        risk_level
2                   Target type        Multiclass
3           Original data shape         (773, 28)
4        Transformed data shape         (773, 28)
5   Transformed train set shape         (541, 28)
6    Transformed test set shape         (232, 28)
7              Numeric features                27
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              d46f
2025-06-14 16:31:52,987:INFO:SubProcess create_model() end ==================================
2025-06-14 16:31:52,987:INFO:Creating metrics dataframe
2025-06-14 16:31:52,997:INFO:Initializing SVM - Linear Kernel
2025-06-14 16:31:52,997:INFO:Total runtime is 0.3072648008664449 minutes
2025-06-14 16:31:53,014:INFO:SubProcess create_model() called ==================================
2025-06-14 16:31:53,014:INFO:Initializing create_model()
2025-06-14 16:31:53,014:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BDBC5ED40>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BDF481CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:31:53,014:INFO:Checking exceptions
2025-06-14 16:31:53,014:INFO:Importing libraries
2025-06-14 16:31:53,014:INFO:Copying training dataset
2025-06-14 16:31:53,031:INFO:Defining folds
2025-06-14 16:31:53,031:INFO:Declaring metric variables
2025-06-14 16:31:53,045:INFO:Importing untrained model
2025-06-14 16:31:53,045:INFO:SVM - Linear Kernel Imported successfully
2025-06-14 16:31:53,061:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:31:53,061:INFO:Starting cross validation
2025-06-14 16:31:53,061:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:31:53,061:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:31:53,576:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:31:53,589:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:31:53,591:INFO:setup() successfully completed in 3.09s...............
2025-06-14 16:31:53,610:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:53,619:INFO:Initializing compare_models()
2025-06-14 16:31:53,619:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A27382E290>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001A27382E290>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-06-14 16:31:53,621:INFO:Checking exceptions
2025-06-14 16:31:53,625:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:53,633:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:53,633:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:31:53,651:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:31:53,651:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:53,656:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:53,656:INFO:Preparing display monitor
2025-06-14 16:31:53,668:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:53,668:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:53,677:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:31:53,690:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:53,698:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:53,721:INFO:Initializing Logistic Regression
2025-06-14 16:31:53,721:INFO:Total runtime is 0.0 minutes
2025-06-14 16:31:53,724:INFO:SubProcess create_model() called ==================================
2025-06-14 16:31:53,724:INFO:Initializing create_model()
2025-06-14 16:31:53,724:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A27382E290>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A276004940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:31:53,724:INFO:Checking exceptions
2025-06-14 16:31:53,724:INFO:Importing libraries
2025-06-14 16:31:53,724:INFO:Copying training dataset
2025-06-14 16:31:53,743:INFO:Defining folds
2025-06-14 16:31:53,743:INFO:Declaring metric variables
2025-06-14 16:31:53,743:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:53,743:INFO:Importing untrained model
2025-06-14 16:31:53,757:INFO:Logistic Regression Imported successfully
2025-06-14 16:31:53,772:INFO:Starting cross validation
2025-06-14 16:31:53,772:INFO:Calculating mean and std
2025-06-14 16:31:53,773:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:31:53,773:INFO:Creating metrics dataframe
2025-06-14 16:31:53,773:INFO:Uploading results into container
2025-06-14 16:31:53,773:INFO:Uploading model into container now
2025-06-14 16:31:53,773:INFO:_master_model_container: 5
2025-06-14 16:31:53,773:INFO:_display_container: 2
2025-06-14 16:31:53,773:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-06-14 16:31:53,773:INFO:create_model() successfully completed......................................
2025-06-14 16:31:54,225:INFO:SubProcess create_model() end ==================================
2025-06-14 16:31:54,229:INFO:Creating metrics dataframe
2025-06-14 16:31:54,531:INFO:Initializing Ridge Classifier
2025-06-14 16:31:54,531:INFO:Total runtime is 0.3328344225883484 minutes
2025-06-14 16:31:54,608:INFO:SubProcess create_model() called ==================================
2025-06-14 16:31:54,612:INFO:Initializing create_model()
2025-06-14 16:31:54,615:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BDBC5ED40>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BDF481CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:31:54,617:INFO:Checking exceptions
2025-06-14 16:31:54,624:INFO:Importing libraries
2025-06-14 16:31:54,626:INFO:Copying training dataset
2025-06-14 16:31:55,023:INFO:Defining folds
2025-06-14 16:31:55,029:INFO:Declaring metric variables
2025-06-14 16:31:55,068:INFO:Importing untrained model
2025-06-14 16:31:55,075:INFO:Ridge Classifier Imported successfully
2025-06-14 16:31:55,087:INFO:Starting cross validation
2025-06-14 16:31:55,089:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:31:55,145:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:55,511:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:55,528:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:55,532:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:55,532:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:55,568:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:55,576:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:55,576:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:55,582:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:55,598:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:31:55,602:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:31:55,608:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:31:55,677:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:31:55,744:INFO:Calculating mean and std
2025-06-14 16:31:55,751:INFO:Creating metrics dataframe
2025-06-14 16:31:55,755:INFO:Uploading results into container
2025-06-14 16:31:55,761:INFO:Uploading model into container now
2025-06-14 16:31:55,764:INFO:_master_model_container: 6
2025-06-14 16:31:55,767:INFO:_display_container: 2
2025-06-14 16:31:55,768:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-06-14 16:31:55,769:INFO:create_model() successfully completed......................................
2025-06-14 16:31:56,172:INFO:SubProcess create_model() end ==================================
2025-06-14 16:31:56,174:INFO:Creating metrics dataframe
2025-06-14 16:31:56,187:INFO:Initializing Random Forest Classifier
2025-06-14 16:31:56,187:INFO:Total runtime is 0.36043705940246584 minutes
2025-06-14 16:31:56,193:INFO:SubProcess create_model() called ==================================
2025-06-14 16:31:56,193:INFO:Initializing create_model()
2025-06-14 16:31:56,195:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BDBC5ED40>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BDF481CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:31:56,195:INFO:Checking exceptions
2025-06-14 16:31:56,195:INFO:Importing libraries
2025-06-14 16:31:56,195:INFO:Copying training dataset
2025-06-14 16:31:56,242:INFO:Defining folds
2025-06-14 16:31:56,242:INFO:Declaring metric variables
2025-06-14 16:31:56,265:INFO:Importing untrained model
2025-06-14 16:31:56,284:INFO:Random Forest Classifier Imported successfully
2025-06-14 16:31:56,318:INFO:Starting cross validation
2025-06-14 16:31:56,319:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:32:01,992:INFO:Calculating mean and std
2025-06-14 16:32:02,000:INFO:Creating metrics dataframe
2025-06-14 16:32:02,006:INFO:Uploading results into container
2025-06-14 16:32:02,008:INFO:Uploading model into container now
2025-06-14 16:32:02,016:INFO:_master_model_container: 7
2025-06-14 16:32:02,016:INFO:_display_container: 2
2025-06-14 16:32:02,022:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-06-14 16:32:02,022:INFO:create_model() successfully completed......................................
2025-06-14 16:32:02,483:INFO:SubProcess create_model() end ==================================
2025-06-14 16:32:02,483:INFO:Creating metrics dataframe
2025-06-14 16:32:02,531:INFO:Initializing Quadratic Discriminant Analysis
2025-06-14 16:32:02,531:INFO:Total runtime is 0.4661589622497559 minutes
2025-06-14 16:32:02,545:INFO:SubProcess create_model() called ==================================
2025-06-14 16:32:02,546:INFO:Initializing create_model()
2025-06-14 16:32:02,547:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BDBC5ED40>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BDF481CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:32:02,547:INFO:Checking exceptions
2025-06-14 16:32:02,547:INFO:Importing libraries
2025-06-14 16:32:02,547:INFO:Copying training dataset
2025-06-14 16:32:02,618:INFO:Defining folds
2025-06-14 16:32:02,620:INFO:Declaring metric variables
2025-06-14 16:32:02,630:INFO:Importing untrained model
2025-06-14 16:32:02,644:INFO:Quadratic Discriminant Analysis Imported successfully
2025-06-14 16:32:02,695:INFO:Starting cross validation
2025-06-14 16:32:02,703:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:32:02,796:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:02,891:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:02,951:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:02,973:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:02,987:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:02,981:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:02,997:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:03,008:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:03,015:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:03,044:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:03,100:INFO:Calculating mean and std
2025-06-14 16:32:03,109:INFO:Creating metrics dataframe
2025-06-14 16:32:03,121:INFO:Uploading results into container
2025-06-14 16:32:03,122:INFO:Uploading model into container now
2025-06-14 16:32:03,125:INFO:_master_model_container: 8
2025-06-14 16:32:03,125:INFO:_display_container: 2
2025-06-14 16:32:03,126:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-06-14 16:32:03,129:INFO:create_model() successfully completed......................................
2025-06-14 16:32:03,459:INFO:SubProcess create_model() end ==================================
2025-06-14 16:32:03,459:INFO:Creating metrics dataframe
2025-06-14 16:32:03,489:INFO:Initializing Ada Boost Classifier
2025-06-14 16:32:03,489:INFO:Total runtime is 0.4821235815684001 minutes
2025-06-14 16:32:03,500:INFO:SubProcess create_model() called ==================================
2025-06-14 16:32:03,500:INFO:Initializing create_model()
2025-06-14 16:32:03,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BDBC5ED40>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BDF481CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:32:03,502:INFO:Checking exceptions
2025-06-14 16:32:03,502:INFO:Importing libraries
2025-06-14 16:32:03,502:INFO:Copying training dataset
2025-06-14 16:32:03,547:INFO:Defining folds
2025-06-14 16:32:03,549:INFO:Declaring metric variables
2025-06-14 16:32:03,560:INFO:Importing untrained model
2025-06-14 16:32:03,575:INFO:Ada Boost Classifier Imported successfully
2025-06-14 16:32:03,610:INFO:Starting cross validation
2025-06-14 16:32:03,612:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:32:03,678:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:32:03,758:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:32:03,769:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:32:03,771:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:32:03,783:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:32:03,791:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:32:03,799:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:32:03,807:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:32:03,822:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:32:03,822:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:32:06,308:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:06,331:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:06,427:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:06,430:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:06,434:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:06,435:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:06,443:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:06,457:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:06,475:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:06,475:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:06,489:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:06,523:INFO:Calculating mean and std
2025-06-14 16:32:06,531:INFO:Creating metrics dataframe
2025-06-14 16:32:06,534:INFO:Uploading results into container
2025-06-14 16:32:06,536:INFO:Uploading model into container now
2025-06-14 16:32:06,536:INFO:_master_model_container: 9
2025-06-14 16:32:06,538:INFO:_display_container: 2
2025-06-14 16:32:06,541:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-06-14 16:32:06,541:INFO:create_model() successfully completed......................................
2025-06-14 16:32:06,578:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-14 16:32:06,578:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-14 16:32:06,578:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-14 16:32:06,578:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-14 16:32:07,063:INFO:SubProcess create_model() end ==================================
2025-06-14 16:32:07,064:INFO:Creating metrics dataframe
2025-06-14 16:32:07,152:INFO:Initializing Gradient Boosting Classifier
2025-06-14 16:32:07,152:INFO:Total runtime is 0.5431728442509969 minutes
2025-06-14 16:32:07,166:INFO:SubProcess create_model() called ==================================
2025-06-14 16:32:07,168:INFO:Initializing create_model()
2025-06-14 16:32:07,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BDBC5ED40>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BDF481CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:32:07,168:INFO:Checking exceptions
2025-06-14 16:32:07,168:INFO:Importing libraries
2025-06-14 16:32:07,168:INFO:Copying training dataset
2025-06-14 16:32:07,257:INFO:Defining folds
2025-06-14 16:32:07,258:INFO:Declaring metric variables
2025-06-14 16:32:07,270:INFO:Importing untrained model
2025-06-14 16:32:07,282:INFO:Gradient Boosting Classifier Imported successfully
2025-06-14 16:32:07,326:INFO:Starting cross validation
2025-06-14 16:32:07,328:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:32:08,402:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:08,440:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:08,468:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:08,474:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:08,484:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-14 16:32:08,527:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-14 16:32:08,556:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:08,595:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:08,617:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:08,641:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:08,644:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:08,688:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:08,780:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-14 16:32:08,794:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-14 16:32:08,877:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:08,891:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:08,903:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-14 16:32:08,927:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:08,975:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:09,014:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:09,018:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:09,045:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:09,248:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-14 16:32:09,303:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:09,327:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:09,353:INFO:Calculating mean and std
2025-06-14 16:32:09,358:INFO:Creating metrics dataframe
2025-06-14 16:32:09,366:INFO:Uploading results into container
2025-06-14 16:32:09,369:INFO:Uploading model into container now
2025-06-14 16:32:09,370:INFO:_master_model_container: 1
2025-06-14 16:32:09,374:INFO:_display_container: 2
2025-06-14 16:32:09,374:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-14 16:32:09,374:INFO:create_model() successfully completed......................................
2025-06-14 16:32:09,715:INFO:SubProcess create_model() end ==================================
2025-06-14 16:32:09,719:INFO:Creating metrics dataframe
2025-06-14 16:32:09,753:INFO:Initializing K Neighbors Classifier
2025-06-14 16:32:09,753:INFO:Total runtime is 0.2671934167544047 minutes
2025-06-14 16:32:09,763:INFO:SubProcess create_model() called ==================================
2025-06-14 16:32:09,763:INFO:Initializing create_model()
2025-06-14 16:32:09,763:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A27382E290>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A276004940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:32:09,766:INFO:Checking exceptions
2025-06-14 16:32:09,766:INFO:Importing libraries
2025-06-14 16:32:09,766:INFO:Copying training dataset
2025-06-14 16:32:09,806:INFO:Defining folds
2025-06-14 16:32:09,806:INFO:Declaring metric variables
2025-06-14 16:32:09,820:INFO:Importing untrained model
2025-06-14 16:32:09,837:INFO:K Neighbors Classifier Imported successfully
2025-06-14 16:32:09,865:INFO:Starting cross validation
2025-06-14 16:32:09,868:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:32:10,385:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:10,400:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:13,919:INFO:PyCaret ClassificationExperiment
2025-06-14 16:32:13,919:INFO:Logging name: clf-default-name
2025-06-14 16:32:13,919:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-14 16:32:13,919:INFO:version 3.3.2
2025-06-14 16:32:13,919:INFO:Initializing setup()
2025-06-14 16:32:13,919:INFO:self.USI: 3cd6
2025-06-14 16:32:13,921:INFO:self._variable_keys: {'fold_generator', 'fix_imbalance', 'target_param', 'X_test', 'gpu_n_jobs_param', 'html_param', 'X_train', 'USI', 'X', 'y', 'idx', 'gpu_param', 'n_jobs_param', 'exp_id', 'data', 'y_train', 'fold_shuffle_param', 'is_multiclass', 'exp_name_log', 'seed', 'memory', '_available_plots', 'logging_param', 'pipeline', 'y_test', 'log_plots_param', 'fold_groups_param', '_ml_usecase'}
2025-06-14 16:32:13,921:INFO:Checking environment
2025-06-14 16:32:13,921:INFO:python_version: 3.10.16
2025-06-14 16:32:13,921:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-14 16:32:13,926:INFO:machine: AMD64
2025-06-14 16:32:13,927:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-14 16:32:13,965:INFO:Memory: svmem(total=33885192192, available=13154365440, percent=61.2, used=20730826752, free=13154365440)
2025-06-14 16:32:13,967:INFO:Physical Core: 14
2025-06-14 16:32:13,967:INFO:Logical Core: 18
2025-06-14 16:32:13,967:INFO:Checking libraries
2025-06-14 16:32:13,968:INFO:System:
2025-06-14 16:32:13,968:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-14 16:32:13,968:INFO:executable: C:\Users\omslu\anaconda3\envs\pycaret_env\python.exe
2025-06-14 16:32:13,968:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-14 16:32:13,968:INFO:PyCaret required dependencies:
2025-06-14 16:32:14,092:INFO:                 pip: 25.1
2025-06-14 16:32:14,092:INFO:          setuptools: 78.1.1
2025-06-14 16:32:14,092:INFO:             pycaret: 3.3.2
2025-06-14 16:32:14,092:INFO:             IPython: 8.37.0
2025-06-14 16:32:14,094:INFO:          ipywidgets: 8.1.7
2025-06-14 16:32:14,094:INFO:                tqdm: 4.67.1
2025-06-14 16:32:14,094:INFO:               numpy: 1.26.4
2025-06-14 16:32:14,094:INFO:              pandas: 2.1.4
2025-06-14 16:32:14,094:INFO:              jinja2: 3.1.6
2025-06-14 16:32:14,096:INFO:               scipy: 1.11.4
2025-06-14 16:32:14,096:INFO:              joblib: 1.3.2
2025-06-14 16:32:14,096:INFO:             sklearn: 1.4.2
2025-06-14 16:32:14,096:INFO:                pyod: 2.0.5
2025-06-14 16:32:14,098:INFO:            imblearn: 0.13.0
2025-06-14 16:32:14,098:INFO:   category_encoders: 2.7.0
2025-06-14 16:32:14,098:INFO:            lightgbm: 4.6.0
2025-06-14 16:32:14,098:INFO:               numba: 0.61.2
2025-06-14 16:32:14,098:INFO:            requests: 2.32.3
2025-06-14 16:32:14,098:INFO:          matplotlib: 3.7.5
2025-06-14 16:32:14,098:INFO:          scikitplot: 0.3.7
2025-06-14 16:32:14,098:INFO:         yellowbrick: 1.5
2025-06-14 16:32:14,098:INFO:              plotly: 5.24.1
2025-06-14 16:32:14,100:INFO:    plotly-resampler: Not installed
2025-06-14 16:32:14,100:INFO:             kaleido: 0.2.1
2025-06-14 16:32:14,100:INFO:           schemdraw: 0.15
2025-06-14 16:32:14,100:INFO:         statsmodels: 0.14.4
2025-06-14 16:32:14,100:INFO:              sktime: 0.26.0
2025-06-14 16:32:14,100:INFO:               tbats: 1.1.3
2025-06-14 16:32:14,100:INFO:            pmdarima: 2.0.4
2025-06-14 16:32:14,100:INFO:              psutil: 7.0.0
2025-06-14 16:32:14,100:INFO:          markupsafe: 3.0.2
2025-06-14 16:32:14,100:INFO:             pickle5: Not installed
2025-06-14 16:32:14,100:INFO:         cloudpickle: 3.1.1
2025-06-14 16:32:14,100:INFO:         deprecation: 2.1.0
2025-06-14 16:32:14,100:INFO:              xxhash: 3.5.0
2025-06-14 16:32:14,105:INFO:           wurlitzer: Not installed
2025-06-14 16:32:14,105:INFO:PyCaret optional dependencies:
2025-06-14 16:32:14,269:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-14 16:32:14,269:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-14 16:32:14,269:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-14 16:32:14,271:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-14 16:32:14,278:INFO:                shap: 0.47.2
2025-06-14 16:32:14,278:INFO:           interpret: Not installed
2025-06-14 16:32:14,278:INFO:                umap: Not installed
2025-06-14 16:32:14,278:INFO:     ydata_profiling: Not installed
2025-06-14 16:32:14,278:INFO:  explainerdashboard: Not installed
2025-06-14 16:32:14,278:INFO:             autoviz: Not installed
2025-06-14 16:32:14,278:INFO:           fairlearn: Not installed
2025-06-14 16:32:14,278:INFO:          deepchecks: Not installed
2025-06-14 16:32:14,278:INFO:             xgboost: 3.0.2
2025-06-14 16:32:14,278:INFO:            catboost: Not installed
2025-06-14 16:32:14,280:INFO:              kmodes: Not installed
2025-06-14 16:32:14,280:INFO:             mlxtend: Not installed
2025-06-14 16:32:14,280:INFO:       statsforecast: Not installed
2025-06-14 16:32:14,280:INFO:        tune_sklearn: Not installed
2025-06-14 16:32:14,280:INFO:                 ray: Not installed
2025-06-14 16:32:14,280:INFO:            hyperopt: Not installed
2025-06-14 16:32:14,280:INFO:              optuna: Not installed
2025-06-14 16:32:14,280:INFO:               skopt: Not installed
2025-06-14 16:32:14,280:INFO:              mlflow: Not installed
2025-06-14 16:32:14,280:INFO:              gradio: Not installed
2025-06-14 16:32:14,280:INFO:             fastapi: Not installed
2025-06-14 16:32:14,280:INFO:             uvicorn: Not installed
2025-06-14 16:32:14,280:INFO:              m2cgen: Not installed
2025-06-14 16:32:14,280:INFO:           evidently: Not installed
2025-06-14 16:32:14,282:INFO:               fugue: Not installed
2025-06-14 16:32:14,282:INFO:           streamlit: Not installed
2025-06-14 16:32:14,282:INFO:             prophet: Not installed
2025-06-14 16:32:14,282:INFO:None
2025-06-14 16:32:14,282:INFO:Set up data.
2025-06-14 16:32:14,328:INFO:Set up folding strategy.
2025-06-14 16:32:14,330:INFO:Set up train/test split.
2025-06-14 16:32:14,417:INFO:Set up index.
2025-06-14 16:32:14,421:INFO:Assigning column types.
2025-06-14 16:32:14,497:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-14 16:32:14,867:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-14 16:32:14,891:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-14 16:32:15,384:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:32:15,412:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:32:15,858:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-14 16:32:15,871:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-14 16:32:16,123:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:32:16,149:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:32:16,157:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-14 16:32:16,582:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-14 16:32:16,776:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:32:16,794:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:32:17,131:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-14 16:32:17,360:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:32:17,381:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:32:17,383:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-06-14 16:32:17,874:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:32:17,894:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:32:18,364:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:32:18,390:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:32:18,403:INFO:Preparing preprocessing pipeline...
2025-06-14 16:32:18,410:INFO:Set up simple imputation.
2025-06-14 16:32:18,620:INFO:Finished creating preprocessing pipeline.
2025-06-14 16:32:18,653:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\omslu\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['isSchool', 'rental_count',
                                             'return_count', 'apart',
                                             'closest_hospital_dist',
                                             'closest_convenience_dist',
                                             'closest_culture_dist', 'age_20s',
                                             'age_30s', 'age_40s',
                                             'crosswalk_count',
                                             'closest_cross_dist', 'bus_count'...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-06-14 16:32:18,655:INFO:Creating final display dataframe.
2025-06-14 16:32:19,654:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target        risk_level
2                   Target type        Multiclass
3           Original data shape       (14978, 28)
4        Transformed data shape       (14978, 28)
5   Transformed train set shape       (10484, 28)
6    Transformed test set shape        (4494, 28)
7              Numeric features                27
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              3cd6
2025-06-14 16:32:20,174:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:32:20,197:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:32:20,725:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:32:20,755:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:32:20,789:INFO:setup() successfully completed in 6.88s...............
2025-06-14 16:32:20,823:INFO:Initializing compare_models()
2025-06-14 16:32:20,829:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001590BC53BE0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001590BC53BE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-06-14 16:32:20,829:INFO:Checking exceptions
2025-06-14 16:32:20,882:INFO:Preparing display monitor
2025-06-14 16:32:21,048:INFO:Initializing Logistic Regression
2025-06-14 16:32:21,054:INFO:Total runtime is 9.482701619466146e-05 minutes
2025-06-14 16:32:21,083:INFO:SubProcess create_model() called ==================================
2025-06-14 16:32:21,083:INFO:Initializing create_model()
2025-06-14 16:32:21,088:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001590BC53BE0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001590BC53190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:32:21,090:INFO:Checking exceptions
2025-06-14 16:32:21,090:INFO:Importing libraries
2025-06-14 16:32:21,090:INFO:Copying training dataset
2025-06-14 16:32:21,177:INFO:Defining folds
2025-06-14 16:32:21,179:INFO:Declaring metric variables
2025-06-14 16:32:21,190:INFO:Importing untrained model
2025-06-14 16:32:21,214:INFO:Logistic Regression Imported successfully
2025-06-14 16:32:21,255:INFO:Starting cross validation
2025-06-14 16:32:21,263:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:32:21,399:INFO:PyCaret ClassificationExperiment
2025-06-14 16:32:21,399:INFO:Logging name: clf-default-name
2025-06-14 16:32:21,403:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-14 16:32:21,403:INFO:version 3.3.2
2025-06-14 16:32:21,404:INFO:Initializing setup()
2025-06-14 16:32:21,404:INFO:self.USI: 4dd5
2025-06-14 16:32:21,405:INFO:self._variable_keys: {'is_multiclass', 'n_jobs_param', 'y', '_available_plots', 'X_test', 'fix_imbalance', 'X', 'y_test', 'memory', '_ml_usecase', 'X_train', 'log_plots_param', 'fold_groups_param', 'y_train', 'fold_shuffle_param', 'gpu_n_jobs_param', 'exp_name_log', 'data', 'idx', 'gpu_param', 'pipeline', 'html_param', 'USI', 'target_param', 'fold_generator', 'exp_id', 'seed', 'logging_param'}
2025-06-14 16:32:21,405:INFO:Checking environment
2025-06-14 16:32:21,405:INFO:python_version: 3.10.16
2025-06-14 16:32:21,405:INFO:python_build: ('main', 'Dec 11 2024 16:19:12')
2025-06-14 16:32:21,405:INFO:machine: AMD64
2025-06-14 16:32:21,406:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-14 16:32:21,720:INFO:Memory: svmem(total=33885192192, available=12647915520, percent=62.7, used=21237276672, free=12647915520)
2025-06-14 16:32:21,720:INFO:Physical Core: 14
2025-06-14 16:32:21,720:INFO:Logical Core: 18
2025-06-14 16:32:21,720:INFO:Checking libraries
2025-06-14 16:32:21,721:INFO:System:
2025-06-14 16:32:21,721:INFO:    python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
2025-06-14 16:32:21,723:INFO:executable: C:\Users\omslu\anaconda3\envs\pycaret_env\python.exe
2025-06-14 16:32:21,723:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-14 16:32:21,723:INFO:PyCaret required dependencies:
2025-06-14 16:32:22,484:INFO:                 pip: 25.1
2025-06-14 16:32:22,484:INFO:          setuptools: 78.1.1
2025-06-14 16:32:22,484:INFO:             pycaret: 3.3.2
2025-06-14 16:32:22,485:INFO:             IPython: 8.37.0
2025-06-14 16:32:22,486:INFO:          ipywidgets: 8.1.7
2025-06-14 16:32:22,486:INFO:                tqdm: 4.67.1
2025-06-14 16:32:22,486:INFO:               numpy: 1.26.4
2025-06-14 16:32:22,487:INFO:              pandas: 2.1.4
2025-06-14 16:32:22,488:INFO:              jinja2: 3.1.6
2025-06-14 16:32:22,488:INFO:               scipy: 1.11.4
2025-06-14 16:32:22,488:INFO:              joblib: 1.3.2
2025-06-14 16:32:22,488:INFO:             sklearn: 1.4.2
2025-06-14 16:32:22,488:INFO:                pyod: 2.0.5
2025-06-14 16:32:22,490:INFO:            imblearn: 0.13.0
2025-06-14 16:32:22,490:INFO:   category_encoders: 2.7.0
2025-06-14 16:32:22,490:INFO:            lightgbm: 4.6.0
2025-06-14 16:32:22,492:INFO:               numba: 0.61.2
2025-06-14 16:32:22,492:INFO:            requests: 2.32.3
2025-06-14 16:32:22,492:INFO:          matplotlib: 3.7.5
2025-06-14 16:32:22,492:INFO:          scikitplot: 0.3.7
2025-06-14 16:32:22,492:INFO:         yellowbrick: 1.5
2025-06-14 16:32:22,492:INFO:              plotly: 5.24.1
2025-06-14 16:32:22,492:INFO:    plotly-resampler: Not installed
2025-06-14 16:32:22,492:INFO:             kaleido: 0.2.1
2025-06-14 16:32:22,492:INFO:           schemdraw: 0.15
2025-06-14 16:32:22,494:INFO:         statsmodels: 0.14.4
2025-06-14 16:32:22,494:INFO:              sktime: 0.26.0
2025-06-14 16:32:22,494:INFO:               tbats: 1.1.3
2025-06-14 16:32:22,496:INFO:            pmdarima: 2.0.4
2025-06-14 16:32:22,496:INFO:              psutil: 7.0.0
2025-06-14 16:32:22,497:INFO:          markupsafe: 3.0.2
2025-06-14 16:32:22,497:INFO:             pickle5: Not installed
2025-06-14 16:32:22,497:INFO:         cloudpickle: 3.1.1
2025-06-14 16:32:22,499:INFO:         deprecation: 2.1.0
2025-06-14 16:32:22,499:INFO:              xxhash: 3.5.0
2025-06-14 16:32:22,500:INFO:           wurlitzer: Not installed
2025-06-14 16:32:22,500:INFO:PyCaret optional dependencies:
2025-06-14 16:32:22,644:INFO:                shap: 0.47.2
2025-06-14 16:32:22,644:INFO:           interpret: Not installed
2025-06-14 16:32:22,645:INFO:                umap: Not installed
2025-06-14 16:32:22,645:INFO:     ydata_profiling: Not installed
2025-06-14 16:32:22,645:INFO:  explainerdashboard: Not installed
2025-06-14 16:32:22,645:INFO:             autoviz: Not installed
2025-06-14 16:32:22,645:INFO:           fairlearn: Not installed
2025-06-14 16:32:22,645:INFO:          deepchecks: Not installed
2025-06-14 16:32:22,645:INFO:             xgboost: 3.0.2
2025-06-14 16:32:22,646:INFO:            catboost: Not installed
2025-06-14 16:32:22,646:INFO:              kmodes: Not installed
2025-06-14 16:32:22,646:INFO:             mlxtend: Not installed
2025-06-14 16:32:22,646:INFO:       statsforecast: Not installed
2025-06-14 16:32:22,646:INFO:        tune_sklearn: Not installed
2025-06-14 16:32:22,646:INFO:                 ray: Not installed
2025-06-14 16:32:22,646:INFO:            hyperopt: Not installed
2025-06-14 16:32:22,646:INFO:              optuna: Not installed
2025-06-14 16:32:22,646:INFO:               skopt: Not installed
2025-06-14 16:32:22,646:INFO:              mlflow: Not installed
2025-06-14 16:32:22,646:INFO:              gradio: Not installed
2025-06-14 16:32:22,646:INFO:             fastapi: Not installed
2025-06-14 16:32:22,648:INFO:             uvicorn: Not installed
2025-06-14 16:32:22,648:INFO:              m2cgen: Not installed
2025-06-14 16:32:22,648:INFO:           evidently: Not installed
2025-06-14 16:32:22,648:INFO:               fugue: Not installed
2025-06-14 16:32:22,648:INFO:           streamlit: Not installed
2025-06-14 16:32:22,648:INFO:             prophet: Not installed
2025-06-14 16:32:22,648:INFO:None
2025-06-14 16:32:22,648:INFO:Set up data.
2025-06-14 16:32:23,079:INFO:Set up folding strategy.
2025-06-14 16:32:23,079:INFO:Set up train/test split.
2025-06-14 16:32:23,229:INFO:Set up index.
2025-06-14 16:32:23,250:INFO:Assigning column types.
2025-06-14 16:32:23,549:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-14 16:32:24,623:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-14 16:32:24,644:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-14 16:32:25,081:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:32:25,088:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:32:25,644:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-14 16:32:25,651:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-14 16:32:25,909:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:32:25,943:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:32:25,949:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-14 16:32:26,338:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-14 16:32:26,574:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:32:26,595:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:32:26,992:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-14 16:32:27,150:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:32:27,172:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:32:27,172:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-06-14 16:32:27,839:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:27,845:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:32:27,870:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:32:28,398:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:32:28,420:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:32:28,436:INFO:Preparing preprocessing pipeline...
2025-06-14 16:32:28,440:INFO:Set up simple imputation.
2025-06-14 16:32:28,594:INFO:Finished creating preprocessing pipeline.
2025-06-14 16:32:28,610:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\omslu\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['isSchool', 'rental_count',
                                             'return_count', 'apart',
                                             'closest_hospital_dist',
                                             'closest_convenience_dist',
                                             'closest_culture_dist', 'age_20s',
                                             'age_30s', 'age_40s',
                                             'crosswalk_count',
                                             'closest_cross_dist', 'bus_count'...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-06-14 16:32:28,611:INFO:Creating final display dataframe.
2025-06-14 16:32:29,407:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target        risk_level
2                   Target type        Multiclass
3           Original data shape        (2406, 28)
4        Transformed data shape        (2406, 28)
5   Transformed train set shape        (1684, 28)
6    Transformed test set shape         (722, 28)
7              Numeric features                27
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              4dd5
2025-06-14 16:32:30,014:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:32:30,042:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:32:30,707:INFO:Soft dependency imported: xgboost: 3.0.2
2025-06-14 16:32:30,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-14 16:32:30,757:INFO:setup() successfully completed in 9.41s...............
2025-06-14 16:32:30,789:INFO:Initializing compare_models()
2025-06-14 16:32:30,790:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002027E6FEEF0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002027E6FEEF0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-06-14 16:32:30,790:INFO:Checking exceptions
2025-06-14 16:32:30,802:INFO:Preparing display monitor
2025-06-14 16:32:30,936:INFO:Initializing Logistic Regression
2025-06-14 16:32:30,936:INFO:Total runtime is 0.0 minutes
2025-06-14 16:32:30,990:INFO:SubProcess create_model() called ==================================
2025-06-14 16:32:30,992:INFO:Initializing create_model()
2025-06-14 16:32:30,992:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002027E6FEEF0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202025D5AB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:32:30,992:INFO:Checking exceptions
2025-06-14 16:32:30,992:INFO:Importing libraries
2025-06-14 16:32:30,992:INFO:Copying training dataset
2025-06-14 16:32:31,071:INFO:Defining folds
2025-06-14 16:32:31,071:INFO:Declaring metric variables
2025-06-14 16:32:31,113:INFO:Importing untrained model
2025-06-14 16:32:31,126:INFO:Logistic Regression Imported successfully
2025-06-14 16:32:31,157:INFO:Starting cross validation
2025-06-14 16:32:31,164:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:32:33,117:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:34,016:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:34,399:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:34,482:INFO:Calculating mean and std
2025-06-14 16:32:34,515:INFO:Creating metrics dataframe
2025-06-14 16:32:34,519:INFO:Uploading results into container
2025-06-14 16:32:34,532:INFO:Uploading model into container now
2025-06-14 16:32:34,545:INFO:_master_model_container: 2
2025-06-14 16:32:34,547:INFO:_display_container: 2
2025-06-14 16:32:34,547:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-14 16:32:34,547:INFO:create_model() successfully completed......................................
2025-06-14 16:32:35,448:INFO:SubProcess create_model() end ==================================
2025-06-14 16:32:35,448:INFO:Creating metrics dataframe
2025-06-14 16:32:35,562:INFO:Initializing Naive Bayes
2025-06-14 16:32:35,562:INFO:Total runtime is 0.6973503867785136 minutes
2025-06-14 16:32:35,589:INFO:SubProcess create_model() called ==================================
2025-06-14 16:32:35,590:INFO:Initializing create_model()
2025-06-14 16:32:35,599:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A27382E290>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A276004940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:32:35,599:INFO:Checking exceptions
2025-06-14 16:32:35,599:INFO:Importing libraries
2025-06-14 16:32:35,599:INFO:Copying training dataset
2025-06-14 16:32:35,700:INFO:Defining folds
2025-06-14 16:32:35,700:INFO:Declaring metric variables
2025-06-14 16:32:35,723:INFO:Importing untrained model
2025-06-14 16:32:35,751:INFO:Naive Bayes Imported successfully
2025-06-14 16:32:35,821:INFO:Starting cross validation
2025-06-14 16:32:35,830:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:32:36,050:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:36,163:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:36,172:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:36,173:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:36,221:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:36,274:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:36,294:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:36,295:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:36,400:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:36,505:INFO:Calculating mean and std
2025-06-14 16:32:36,515:INFO:Creating metrics dataframe
2025-06-14 16:32:36,541:INFO:Uploading results into container
2025-06-14 16:32:36,552:INFO:Uploading model into container now
2025-06-14 16:32:36,555:INFO:_master_model_container: 3
2025-06-14 16:32:36,555:INFO:_display_container: 2
2025-06-14 16:32:36,567:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-06-14 16:32:36,568:INFO:create_model() successfully completed......................................
2025-06-14 16:32:37,118:INFO:SubProcess create_model() end ==================================
2025-06-14 16:32:37,122:INFO:Creating metrics dataframe
2025-06-14 16:32:37,214:INFO:Initializing Decision Tree Classifier
2025-06-14 16:32:37,214:INFO:Total runtime is 0.7248813986778259 minutes
2025-06-14 16:32:37,245:INFO:SubProcess create_model() called ==================================
2025-06-14 16:32:37,247:INFO:Initializing create_model()
2025-06-14 16:32:37,247:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A27382E290>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A276004940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:32:37,257:INFO:Checking exceptions
2025-06-14 16:32:37,258:INFO:Importing libraries
2025-06-14 16:32:37,258:INFO:Copying training dataset
2025-06-14 16:32:37,331:INFO:Defining folds
2025-06-14 16:32:37,331:INFO:Declaring metric variables
2025-06-14 16:32:37,379:INFO:Importing untrained model
2025-06-14 16:32:37,416:INFO:Decision Tree Classifier Imported successfully
2025-06-14 16:32:37,508:INFO:Starting cross validation
2025-06-14 16:32:37,510:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:32:38,079:INFO:Calculating mean and std
2025-06-14 16:32:38,093:INFO:Creating metrics dataframe
2025-06-14 16:32:38,111:INFO:Uploading results into container
2025-06-14 16:32:38,115:INFO:Uploading model into container now
2025-06-14 16:32:38,128:INFO:_master_model_container: 4
2025-06-14 16:32:38,128:INFO:_display_container: 2
2025-06-14 16:32:38,139:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-06-14 16:32:38,139:INFO:create_model() successfully completed......................................
2025-06-14 16:32:38,797:INFO:SubProcess create_model() end ==================================
2025-06-14 16:32:38,797:INFO:Creating metrics dataframe
2025-06-14 16:32:38,902:INFO:Initializing SVM - Linear Kernel
2025-06-14 16:32:38,902:INFO:Total runtime is 0.7530081152915954 minutes
2025-06-14 16:32:38,958:INFO:SubProcess create_model() called ==================================
2025-06-14 16:32:38,966:INFO:Initializing create_model()
2025-06-14 16:32:38,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A27382E290>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A276004940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:32:38,973:INFO:Checking exceptions
2025-06-14 16:32:38,973:INFO:Importing libraries
2025-06-14 16:32:38,974:INFO:Copying training dataset
2025-06-14 16:32:39,001:INFO:Defining folds
2025-06-14 16:32:39,001:INFO:Declaring metric variables
2025-06-14 16:32:39,049:INFO:Importing untrained model
2025-06-14 16:32:39,095:INFO:SVM - Linear Kernel Imported successfully
2025-06-14 16:32:39,218:INFO:Starting cross validation
2025-06-14 16:32:39,230:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:32:40,113:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:40,120:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:40,169:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:40,230:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:40,293:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:40,303:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:40,306:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:40,316:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:40,317:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:40,341:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:40,345:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:40,359:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:40,384:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:40,384:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:40,401:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:40,438:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:40,444:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:40,563:INFO:Calculating mean and std
2025-06-14 16:32:40,580:INFO:Creating metrics dataframe
2025-06-14 16:32:40,617:INFO:Uploading results into container
2025-06-14 16:32:40,630:INFO:Uploading model into container now
2025-06-14 16:32:40,632:INFO:_master_model_container: 5
2025-06-14 16:32:40,632:INFO:_display_container: 2
2025-06-14 16:32:40,634:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-06-14 16:32:40,634:INFO:create_model() successfully completed......................................
2025-06-14 16:32:41,224:INFO:SubProcess create_model() end ==================================
2025-06-14 16:32:41,225:INFO:Creating metrics dataframe
2025-06-14 16:32:41,280:INFO:Initializing Ridge Classifier
2025-06-14 16:32:41,282:INFO:Total runtime is 0.7926802198092142 minutes
2025-06-14 16:32:41,323:INFO:SubProcess create_model() called ==================================
2025-06-14 16:32:41,324:INFO:Initializing create_model()
2025-06-14 16:32:41,325:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A27382E290>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A276004940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:32:41,325:INFO:Checking exceptions
2025-06-14 16:32:41,325:INFO:Importing libraries
2025-06-14 16:32:41,325:INFO:Copying training dataset
2025-06-14 16:32:41,380:INFO:Defining folds
2025-06-14 16:32:41,390:INFO:Declaring metric variables
2025-06-14 16:32:41,432:INFO:Importing untrained model
2025-06-14 16:32:41,475:INFO:Ridge Classifier Imported successfully
2025-06-14 16:32:41,558:INFO:Starting cross validation
2025-06-14 16:32:41,567:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:32:41,713:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:41,717:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:41,773:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:41,774:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:41,774:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:41,777:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:41,830:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:41,865:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:41,883:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:41,891:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:41,899:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:41,932:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:41,944:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:41,968:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:42,003:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:42,021:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:42,061:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:42,085:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:42,103:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:42,138:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:42,241:INFO:Calculating mean and std
2025-06-14 16:32:42,261:INFO:Creating metrics dataframe
2025-06-14 16:32:42,274:INFO:Uploading results into container
2025-06-14 16:32:42,283:INFO:Uploading model into container now
2025-06-14 16:32:42,283:INFO:_master_model_container: 6
2025-06-14 16:32:42,293:INFO:_display_container: 2
2025-06-14 16:32:42,293:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-06-14 16:32:42,293:INFO:create_model() successfully completed......................................
2025-06-14 16:32:42,727:INFO:SubProcess create_model() end ==================================
2025-06-14 16:32:42,728:INFO:Creating metrics dataframe
2025-06-14 16:32:42,852:INFO:Initializing Random Forest Classifier
2025-06-14 16:32:42,853:INFO:Total runtime is 0.818860618273417 minutes
2025-06-14 16:32:42,899:INFO:SubProcess create_model() called ==================================
2025-06-14 16:32:42,899:INFO:Initializing create_model()
2025-06-14 16:32:42,901:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A27382E290>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A276004940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:32:42,908:INFO:Checking exceptions
2025-06-14 16:32:42,908:INFO:Importing libraries
2025-06-14 16:32:42,908:INFO:Copying training dataset
2025-06-14 16:32:43,035:INFO:Defining folds
2025-06-14 16:32:43,037:INFO:Declaring metric variables
2025-06-14 16:32:43,068:INFO:Importing untrained model
2025-06-14 16:32:43,126:INFO:Random Forest Classifier Imported successfully
2025-06-14 16:32:43,228:INFO:Starting cross validation
2025-06-14 16:32:43,240:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:32:46,532:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:46,565:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:46,705:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:46,765:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:46,896:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:46,962:INFO:Calculating mean and std
2025-06-14 16:32:46,986:INFO:Creating metrics dataframe
2025-06-14 16:32:47,012:INFO:Uploading results into container
2025-06-14 16:32:47,022:INFO:Uploading model into container now
2025-06-14 16:32:47,033:INFO:_master_model_container: 7
2025-06-14 16:32:47,040:INFO:_display_container: 2
2025-06-14 16:32:47,042:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-06-14 16:32:47,042:INFO:create_model() successfully completed......................................
2025-06-14 16:32:47,600:INFO:SubProcess create_model() end ==================================
2025-06-14 16:32:47,600:INFO:Creating metrics dataframe
2025-06-14 16:32:47,660:INFO:Initializing Quadratic Discriminant Analysis
2025-06-14 16:32:47,660:INFO:Total runtime is 0.8989801843961078 minutes
2025-06-14 16:32:47,693:INFO:SubProcess create_model() called ==================================
2025-06-14 16:32:47,701:INFO:Initializing create_model()
2025-06-14 16:32:47,703:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A27382E290>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A276004940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:32:47,703:INFO:Checking exceptions
2025-06-14 16:32:47,703:INFO:Importing libraries
2025-06-14 16:32:47,703:INFO:Copying training dataset
2025-06-14 16:32:47,752:INFO:Defining folds
2025-06-14 16:32:47,755:INFO:Declaring metric variables
2025-06-14 16:32:47,800:INFO:Importing untrained model
2025-06-14 16:32:47,858:INFO:Quadratic Discriminant Analysis Imported successfully
2025-06-14 16:32:47,951:INFO:Starting cross validation
2025-06-14 16:32:47,960:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:32:48,090:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-14 16:32:48,099:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:48,143:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:48,145:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-14 16:32:48,214:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-14 16:32:48,237:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-14 16:32:48,257:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:48,269:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-14 16:32:48,269:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-14 16:32:48,288:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:48,293:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-14 16:32:48,311:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-14 16:32:48,313:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:48,329:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:48,331:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-14 16:32:48,351:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:48,362:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-14 16:32:48,366:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:48,358:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:48,360:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:48,386:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:48,399:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:48,402:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:48,409:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:48,443:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:48,489:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:48,533:INFO:Calculating mean and std
2025-06-14 16:32:48,553:INFO:Creating metrics dataframe
2025-06-14 16:32:48,575:INFO:Uploading results into container
2025-06-14 16:32:48,577:INFO:Uploading model into container now
2025-06-14 16:32:48,587:INFO:_master_model_container: 8
2025-06-14 16:32:48,588:INFO:_display_container: 2
2025-06-14 16:32:48,597:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-06-14 16:32:48,597:INFO:create_model() successfully completed......................................
2025-06-14 16:32:49,346:INFO:SubProcess create_model() end ==================================
2025-06-14 16:32:49,348:INFO:Creating metrics dataframe
2025-06-14 16:32:49,473:INFO:Initializing Ada Boost Classifier
2025-06-14 16:32:49,474:INFO:Total runtime is 0.9292157570521035 minutes
2025-06-14 16:32:49,508:INFO:SubProcess create_model() called ==================================
2025-06-14 16:32:49,508:INFO:Initializing create_model()
2025-06-14 16:32:49,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A27382E290>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A276004940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:32:49,517:INFO:Checking exceptions
2025-06-14 16:32:49,517:INFO:Importing libraries
2025-06-14 16:32:49,517:INFO:Copying training dataset
2025-06-14 16:32:49,582:INFO:Defining folds
2025-06-14 16:32:49,589:INFO:Declaring metric variables
2025-06-14 16:32:49,621:INFO:Importing untrained model
2025-06-14 16:32:49,661:INFO:Ada Boost Classifier Imported successfully
2025-06-14 16:32:49,737:INFO:Starting cross validation
2025-06-14 16:32:49,743:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:32:49,864:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:32:49,895:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:32:49,906:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:32:49,957:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:32:50,025:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:32:50,049:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:32:50,081:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:32:50,088:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-14 16:32:50,093:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:32:50,114:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:32:50,226:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-14 16:32:50,226:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:50,294:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:51,040:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:51,181:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-14 16:32:51,271:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:51,276:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:51,298:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:51,344:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:51,344:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:51,441:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:51,476:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:51,580:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:51,703:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-14 16:32:51,722:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:51,746:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:51,811:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:51,846:INFO:Calculating mean and std
2025-06-14 16:32:51,850:INFO:Creating metrics dataframe
2025-06-14 16:32:51,864:INFO:Uploading results into container
2025-06-14 16:32:51,866:INFO:Uploading model into container now
2025-06-14 16:32:51,866:INFO:_master_model_container: 9
2025-06-14 16:32:51,873:INFO:_display_container: 2
2025-06-14 16:32:51,880:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-06-14 16:32:51,881:INFO:create_model() successfully completed......................................
2025-06-14 16:32:52,302:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:52,311:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-14 16:32:52,378:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:52,380:INFO:SubProcess create_model() end ==================================
2025-06-14 16:32:52,382:INFO:Creating metrics dataframe
2025-06-14 16:32:52,408:INFO:Initializing Gradient Boosting Classifier
2025-06-14 16:32:52,410:INFO:Total runtime is 0.9781519492467242 minutes
2025-06-14 16:32:52,423:INFO:SubProcess create_model() called ==================================
2025-06-14 16:32:52,423:INFO:Initializing create_model()
2025-06-14 16:32:52,425:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A27382E290>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A276004940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:32:52,425:INFO:Checking exceptions
2025-06-14 16:32:52,425:INFO:Importing libraries
2025-06-14 16:32:52,425:INFO:Copying training dataset
2025-06-14 16:32:52,494:INFO:Defining folds
2025-06-14 16:32:52,494:INFO:Declaring metric variables
2025-06-14 16:32:52,524:INFO:Importing untrained model
2025-06-14 16:32:52,547:INFO:Gradient Boosting Classifier Imported successfully
2025-06-14 16:32:52,583:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:52,607:INFO:Starting cross validation
2025-06-14 16:32:52,614:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:32:52,629:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-14 16:32:52,693:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:52,868:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:53,049:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:53,447:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:53,562:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:53,683:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:53,738:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:53,878:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:54,314:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-14 16:32:54,402:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:54,460:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:54,470:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:54,621:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:54,691:INFO:Calculating mean and std
2025-06-14 16:32:54,695:INFO:Creating metrics dataframe
2025-06-14 16:32:54,699:INFO:Uploading results into container
2025-06-14 16:32:54,704:INFO:Uploading model into container now
2025-06-14 16:32:54,707:INFO:_master_model_container: 10
2025-06-14 16:32:54,707:INFO:_display_container: 2
2025-06-14 16:32:54,707:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-14 16:32:54,707:INFO:create_model() successfully completed......................................
2025-06-14 16:32:54,954:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-14 16:32:55,024:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:55,098:INFO:SubProcess create_model() end ==================================
2025-06-14 16:32:55,099:INFO:Creating metrics dataframe
2025-06-14 16:32:55,127:INFO:Initializing Linear Discriminant Analysis
2025-06-14 16:32:55,127:INFO:Total runtime is 1.3427652438481648 minutes
2025-06-14 16:32:55,141:INFO:SubProcess create_model() called ==================================
2025-06-14 16:32:55,141:INFO:Initializing create_model()
2025-06-14 16:32:55,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BDBC5ED40>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BDF481CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:32:55,151:INFO:Checking exceptions
2025-06-14 16:32:55,151:INFO:Importing libraries
2025-06-14 16:32:55,151:INFO:Copying training dataset
2025-06-14 16:32:55,153:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:55,266:INFO:Defining folds
2025-06-14 16:32:55,274:INFO:Declaring metric variables
2025-06-14 16:32:55,303:INFO:Importing untrained model
2025-06-14 16:32:55,310:INFO:Linear Discriminant Analysis Imported successfully
2025-06-14 16:32:55,348:INFO:Starting cross validation
2025-06-14 16:32:55,350:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:32:55,429:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:55,489:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:55,544:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:55,592:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:55,615:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:55,671:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:55,674:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:55,688:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:55,702:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:55,805:INFO:Calculating mean and std
2025-06-14 16:32:55,812:INFO:Creating metrics dataframe
2025-06-14 16:32:55,817:INFO:Uploading results into container
2025-06-14 16:32:55,817:INFO:Uploading model into container now
2025-06-14 16:32:55,826:INFO:_master_model_container: 11
2025-06-14 16:32:55,826:INFO:_display_container: 2
2025-06-14 16:32:55,827:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-06-14 16:32:55,827:INFO:create_model() successfully completed......................................
2025-06-14 16:32:56,236:INFO:SubProcess create_model() end ==================================
2025-06-14 16:32:56,240:INFO:Creating metrics dataframe
2025-06-14 16:32:56,314:INFO:Initializing Extra Trees Classifier
2025-06-14 16:32:56,315:INFO:Total runtime is 1.3625587145487466 minutes
2025-06-14 16:32:56,335:INFO:SubProcess create_model() called ==================================
2025-06-14 16:32:56,335:INFO:Initializing create_model()
2025-06-14 16:32:56,337:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BDBC5ED40>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BDF481CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:32:56,337:INFO:Checking exceptions
2025-06-14 16:32:56,337:INFO:Importing libraries
2025-06-14 16:32:56,337:INFO:Copying training dataset
2025-06-14 16:32:56,423:INFO:Defining folds
2025-06-14 16:32:56,424:INFO:Declaring metric variables
2025-06-14 16:32:56,435:INFO:Importing untrained model
2025-06-14 16:32:56,444:INFO:Extra Trees Classifier Imported successfully
2025-06-14 16:32:56,476:INFO:Starting cross validation
2025-06-14 16:32:56,482:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:32:56,544:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:56,714:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-14 16:32:56,866:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:56,993:INFO:Calculating mean and std
2025-06-14 16:32:57,001:INFO:Creating metrics dataframe
2025-06-14 16:32:57,020:INFO:Uploading results into container
2025-06-14 16:32:57,021:INFO:Uploading model into container now
2025-06-14 16:32:57,028:INFO:_master_model_container: 1
2025-06-14 16:32:57,028:INFO:_display_container: 2
2025-06-14 16:32:57,029:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-14 16:32:57,029:INFO:create_model() successfully completed......................................
2025-06-14 16:32:57,047:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:57,165:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:57,830:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:58,087:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:58,798:INFO:SubProcess create_model() end ==================================
2025-06-14 16:32:58,798:INFO:Creating metrics dataframe
2025-06-14 16:32:58,899:INFO:Initializing K Neighbors Classifier
2025-06-14 16:32:58,901:INFO:Total runtime is 0.6308836976687113 minutes
2025-06-14 16:32:58,989:INFO:SubProcess create_model() called ==================================
2025-06-14 16:32:58,990:INFO:Initializing create_model()
2025-06-14 16:32:58,990:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001590BC53BE0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001590BC53190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:32:58,990:INFO:Checking exceptions
2025-06-14 16:32:58,990:INFO:Importing libraries
2025-06-14 16:32:58,990:INFO:Copying training dataset
2025-06-14 16:32:59,053:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:59,078:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:59,094:INFO:Defining folds
2025-06-14 16:32:59,094:INFO:Declaring metric variables
2025-06-14 16:32:59,115:INFO:Importing untrained model
2025-06-14 16:32:59,139:INFO:K Neighbors Classifier Imported successfully
2025-06-14 16:32:59,140:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:59,145:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:59,147:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:59,155:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:59,177:INFO:Starting cross validation
2025-06-14 16:32:59,182:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:32:59,313:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:59,341:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:59,550:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:32:59,595:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:32:59,687:INFO:Calculating mean and std
2025-06-14 16:32:59,697:INFO:Creating metrics dataframe
2025-06-14 16:32:59,734:INFO:Uploading results into container
2025-06-14 16:32:59,753:INFO:Uploading model into container now
2025-06-14 16:32:59,755:INFO:_master_model_container: 10
2025-06-14 16:32:59,756:INFO:_display_container: 2
2025-06-14 16:32:59,762:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-14 16:32:59,762:INFO:create_model() successfully completed......................................
2025-06-14 16:33:00,032:INFO:Calculating mean and std
2025-06-14 16:33:00,047:INFO:Creating metrics dataframe
2025-06-14 16:33:00,055:INFO:Uploading results into container
2025-06-14 16:33:00,057:INFO:Uploading model into container now
2025-06-14 16:33:00,057:INFO:_master_model_container: 12
2025-06-14 16:33:00,058:INFO:_display_container: 2
2025-06-14 16:33:00,059:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-06-14 16:33:00,059:INFO:create_model() successfully completed......................................
2025-06-14 16:33:00,271:INFO:SubProcess create_model() end ==================================
2025-06-14 16:33:00,272:INFO:Creating metrics dataframe
2025-06-14 16:33:00,344:INFO:Initializing Linear Discriminant Analysis
2025-06-14 16:33:00,344:INFO:Total runtime is 1.1103728413581846 minutes
2025-06-14 16:33:00,371:INFO:SubProcess create_model() called ==================================
2025-06-14 16:33:00,372:INFO:Initializing create_model()
2025-06-14 16:33:00,375:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A27382E290>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A276004940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:33:00,376:INFO:Checking exceptions
2025-06-14 16:33:00,376:INFO:Importing libraries
2025-06-14 16:33:00,376:INFO:Copying training dataset
2025-06-14 16:33:00,402:INFO:SubProcess create_model() end ==================================
2025-06-14 16:33:00,402:INFO:Creating metrics dataframe
2025-06-14 16:33:00,428:INFO:Defining folds
2025-06-14 16:33:00,428:INFO:Declaring metric variables
2025-06-14 16:33:00,443:INFO:Importing untrained model
2025-06-14 16:33:00,451:INFO:Initializing Extreme Gradient Boosting
2025-06-14 16:33:00,451:INFO:Total runtime is 1.431493298212687 minutes
2025-06-14 16:33:00,461:INFO:SubProcess create_model() called ==================================
2025-06-14 16:33:00,461:INFO:Initializing create_model()
2025-06-14 16:33:00,461:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BDBC5ED40>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BDF481CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:33:00,461:INFO:Checking exceptions
2025-06-14 16:33:00,463:INFO:Importing libraries
2025-06-14 16:33:00,463:INFO:Copying training dataset
2025-06-14 16:33:00,465:INFO:Linear Discriminant Analysis Imported successfully
2025-06-14 16:33:00,521:INFO:Starting cross validation
2025-06-14 16:33:00,523:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:33:00,525:INFO:Defining folds
2025-06-14 16:33:00,526:INFO:Declaring metric variables
2025-06-14 16:33:00,538:INFO:Importing untrained model
2025-06-14 16:33:00,553:INFO:Extreme Gradient Boosting Imported successfully
2025-06-14 16:33:00,595:INFO:Starting cross validation
2025-06-14 16:33:00,597:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:33:00,604:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:00,698:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:00,700:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:00,744:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:00,750:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:00,752:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:00,774:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:00,797:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:00,831:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:00,857:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:00,859:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:00,870:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:00,873:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:00,906:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:00,931:INFO:Calculating mean and std
2025-06-14 16:33:00,953:INFO:Creating metrics dataframe
2025-06-14 16:33:00,978:INFO:Uploading results into container
2025-06-14 16:33:00,985:INFO:Uploading model into container now
2025-06-14 16:33:00,986:INFO:_master_model_container: 11
2025-06-14 16:33:00,986:INFO:_display_container: 2
2025-06-14 16:33:00,987:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-06-14 16:33:00,987:INFO:create_model() successfully completed......................................
2025-06-14 16:33:01,362:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:01,587:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-14 16:33:01,721:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:01,726:INFO:SubProcess create_model() end ==================================
2025-06-14 16:33:01,727:INFO:Creating metrics dataframe
2025-06-14 16:33:01,830:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:01,845:INFO:Initializing Extra Trees Classifier
2025-06-14 16:33:01,845:INFO:Total runtime is 1.135393182436625 minutes
2025-06-14 16:33:01,886:INFO:SubProcess create_model() called ==================================
2025-06-14 16:33:01,887:INFO:Initializing create_model()
2025-06-14 16:33:01,893:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A27382E290>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A276004940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:33:01,895:INFO:Checking exceptions
2025-06-14 16:33:01,895:INFO:Importing libraries
2025-06-14 16:33:01,895:INFO:Copying training dataset
2025-06-14 16:33:01,959:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-14 16:33:01,992:INFO:Defining folds
2025-06-14 16:33:01,993:INFO:Declaring metric variables
2025-06-14 16:33:02,038:INFO:Importing untrained model
2025-06-14 16:33:02,066:INFO:Extra Trees Classifier Imported successfully
2025-06-14 16:33:02,071:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:02,084:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:02,115:INFO:Starting cross validation
2025-06-14 16:33:02,117:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:33:02,992:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:03,581:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:03,693:INFO:Calculating mean and std
2025-06-14 16:33:03,701:INFO:Creating metrics dataframe
2025-06-14 16:33:03,714:INFO:Uploading results into container
2025-06-14 16:33:03,721:INFO:Uploading model into container now
2025-06-14 16:33:03,722:INFO:_master_model_container: 1
2025-06-14 16:33:03,723:INFO:_display_container: 2
2025-06-14 16:33:03,729:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-14 16:33:03,731:INFO:create_model() successfully completed......................................
2025-06-14 16:33:04,217:INFO:SubProcess create_model() end ==================================
2025-06-14 16:33:04,217:INFO:Creating metrics dataframe
2025-06-14 16:33:04,275:INFO:Initializing K Neighbors Classifier
2025-06-14 16:33:04,275:INFO:Total runtime is 0.5556536714235941 minutes
2025-06-14 16:33:04,287:INFO:SubProcess create_model() called ==================================
2025-06-14 16:33:04,287:INFO:Initializing create_model()
2025-06-14 16:33:04,288:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002027E6FEEF0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202025D5AB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:33:04,288:INFO:Checking exceptions
2025-06-14 16:33:04,288:INFO:Importing libraries
2025-06-14 16:33:04,288:INFO:Copying training dataset
2025-06-14 16:33:04,321:INFO:Defining folds
2025-06-14 16:33:04,326:INFO:Declaring metric variables
2025-06-14 16:33:04,353:INFO:Importing untrained model
2025-06-14 16:33:04,361:INFO:K Neighbors Classifier Imported successfully
2025-06-14 16:33:04,415:INFO:Starting cross validation
2025-06-14 16:33:04,417:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:33:04,600:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:04,640:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:04,703:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:04,830:INFO:Calculating mean and std
2025-06-14 16:33:04,844:INFO:Creating metrics dataframe
2025-06-14 16:33:04,882:INFO:Uploading results into container
2025-06-14 16:33:04,884:INFO:Uploading model into container now
2025-06-14 16:33:04,886:INFO:_master_model_container: 12
2025-06-14 16:33:04,886:INFO:_display_container: 2
2025-06-14 16:33:04,886:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-06-14 16:33:04,886:INFO:create_model() successfully completed......................................
2025-06-14 16:33:06,074:INFO:SubProcess create_model() end ==================================
2025-06-14 16:33:06,075:INFO:Creating metrics dataframe
2025-06-14 16:33:06,225:INFO:Initializing Extreme Gradient Boosting
2025-06-14 16:33:06,225:INFO:Total runtime is 1.2084026813507078 minutes
2025-06-14 16:33:06,271:INFO:SubProcess create_model() called ==================================
2025-06-14 16:33:06,272:INFO:Initializing create_model()
2025-06-14 16:33:06,272:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A27382E290>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A276004940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:33:06,272:INFO:Checking exceptions
2025-06-14 16:33:06,272:INFO:Importing libraries
2025-06-14 16:33:06,272:INFO:Copying training dataset
2025-06-14 16:33:06,401:INFO:Defining folds
2025-06-14 16:33:06,401:INFO:Declaring metric variables
2025-06-14 16:33:06,452:INFO:Importing untrained model
2025-06-14 16:33:06,507:INFO:Extreme Gradient Boosting Imported successfully
2025-06-14 16:33:06,605:INFO:Starting cross validation
2025-06-14 16:33:06,607:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:33:10,960:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:11,094:INFO:Calculating mean and std
2025-06-14 16:33:11,105:INFO:Creating metrics dataframe
2025-06-14 16:33:11,110:INFO:Uploading results into container
2025-06-14 16:33:11,110:INFO:Uploading model into container now
2025-06-14 16:33:11,112:INFO:_master_model_container: 13
2025-06-14 16:33:11,112:INFO:_display_container: 2
2025-06-14 16:33:11,114:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-06-14 16:33:11,114:INFO:create_model() successfully completed......................................
2025-06-14 16:33:11,753:INFO:SubProcess create_model() end ==================================
2025-06-14 16:33:11,753:INFO:Creating metrics dataframe
2025-06-14 16:33:11,832:INFO:Initializing Light Gradient Boosting Machine
2025-06-14 16:33:11,832:INFO:Total runtime is 1.3018523494402565 minutes
2025-06-14 16:33:11,862:INFO:SubProcess create_model() called ==================================
2025-06-14 16:33:11,864:INFO:Initializing create_model()
2025-06-14 16:33:11,866:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A27382E290>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A276004940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:33:11,866:INFO:Checking exceptions
2025-06-14 16:33:11,866:INFO:Importing libraries
2025-06-14 16:33:11,866:INFO:Copying training dataset
2025-06-14 16:33:11,894:INFO:Calculating mean and std
2025-06-14 16:33:11,902:INFO:Creating metrics dataframe
2025-06-14 16:33:11,924:INFO:Uploading results into container
2025-06-14 16:33:11,926:INFO:Uploading model into container now
2025-06-14 16:33:11,926:INFO:_master_model_container: 13
2025-06-14 16:33:11,926:INFO:_display_container: 2
2025-06-14 16:33:11,930:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-06-14 16:33:11,934:INFO:create_model() successfully completed......................................
2025-06-14 16:33:11,937:INFO:Defining folds
2025-06-14 16:33:11,937:INFO:Declaring metric variables
2025-06-14 16:33:11,960:INFO:Importing untrained model
2025-06-14 16:33:11,986:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-14 16:33:12,036:INFO:Starting cross validation
2025-06-14 16:33:12,047:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:33:12,451:INFO:SubProcess create_model() end ==================================
2025-06-14 16:33:12,454:INFO:Creating metrics dataframe
2025-06-14 16:33:12,528:INFO:Initializing Light Gradient Boosting Machine
2025-06-14 16:33:12,529:INFO:Total runtime is 1.632788292566935 minutes
2025-06-14 16:33:12,567:INFO:SubProcess create_model() called ==================================
2025-06-14 16:33:12,569:INFO:Initializing create_model()
2025-06-14 16:33:12,572:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BDBC5ED40>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BDF481CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:33:12,572:INFO:Checking exceptions
2025-06-14 16:33:12,572:INFO:Importing libraries
2025-06-14 16:33:12,572:INFO:Copying training dataset
2025-06-14 16:33:12,639:INFO:Defining folds
2025-06-14 16:33:12,642:INFO:Declaring metric variables
2025-06-14 16:33:12,664:INFO:Importing untrained model
2025-06-14 16:33:12,692:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-14 16:33:12,741:INFO:Starting cross validation
2025-06-14 16:33:12,743:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:33:19,567:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:19,923:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:20,355:INFO:Calculating mean and std
2025-06-14 16:33:20,361:INFO:Creating metrics dataframe
2025-06-14 16:33:20,368:INFO:Uploading results into container
2025-06-14 16:33:20,368:INFO:Uploading model into container now
2025-06-14 16:33:20,370:INFO:_master_model_container: 2
2025-06-14 16:33:20,370:INFO:_display_container: 2
2025-06-14 16:33:20,373:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-14 16:33:20,373:INFO:create_model() successfully completed......................................
2025-06-14 16:33:20,606:INFO:SubProcess create_model() end ==================================
2025-06-14 16:33:20,606:INFO:Creating metrics dataframe
2025-06-14 16:33:20,630:INFO:Initializing Naive Bayes
2025-06-14 16:33:20,630:INFO:Total runtime is 0.8282420674959818 minutes
2025-06-14 16:33:20,642:INFO:SubProcess create_model() called ==================================
2025-06-14 16:33:20,642:INFO:Initializing create_model()
2025-06-14 16:33:20,644:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002027E6FEEF0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202025D5AB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:33:20,644:INFO:Checking exceptions
2025-06-14 16:33:20,644:INFO:Importing libraries
2025-06-14 16:33:20,644:INFO:Copying training dataset
2025-06-14 16:33:20,677:INFO:Defining folds
2025-06-14 16:33:20,677:INFO:Declaring metric variables
2025-06-14 16:33:20,691:INFO:Importing untrained model
2025-06-14 16:33:20,699:INFO:Naive Bayes Imported successfully
2025-06-14 16:33:20,723:INFO:Starting cross validation
2025-06-14 16:33:20,723:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:33:20,792:INFO:Calculating mean and std
2025-06-14 16:33:20,798:INFO:Creating metrics dataframe
2025-06-14 16:33:20,819:INFO:Uploading results into container
2025-06-14 16:33:20,820:INFO:Uploading model into container now
2025-06-14 16:33:20,822:INFO:_master_model_container: 2
2025-06-14 16:33:20,822:INFO:_display_container: 2
2025-06-14 16:33:20,829:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-14 16:33:20,829:INFO:create_model() successfully completed......................................
2025-06-14 16:33:21,021:INFO:Calculating mean and std
2025-06-14 16:33:21,025:INFO:Creating metrics dataframe
2025-06-14 16:33:21,030:INFO:Uploading results into container
2025-06-14 16:33:21,032:INFO:Uploading model into container now
2025-06-14 16:33:21,033:INFO:_master_model_container: 3
2025-06-14 16:33:21,033:INFO:_display_container: 2
2025-06-14 16:33:21,034:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-06-14 16:33:21,034:INFO:create_model() successfully completed......................................
2025-06-14 16:33:21,120:INFO:SubProcess create_model() end ==================================
2025-06-14 16:33:21,121:INFO:Creating metrics dataframe
2025-06-14 16:33:21,141:INFO:Initializing Naive Bayes
2025-06-14 16:33:21,143:INFO:Total runtime is 1.0015780488650003 minutes
2025-06-14 16:33:21,153:INFO:SubProcess create_model() called ==================================
2025-06-14 16:33:21,154:INFO:Initializing create_model()
2025-06-14 16:33:21,154:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001590BC53BE0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001590BC53190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:33:21,155:INFO:Checking exceptions
2025-06-14 16:33:21,155:INFO:Importing libraries
2025-06-14 16:33:21,155:INFO:Copying training dataset
2025-06-14 16:33:21,198:INFO:Defining folds
2025-06-14 16:33:21,199:INFO:Declaring metric variables
2025-06-14 16:33:21,208:INFO:Importing untrained model
2025-06-14 16:33:21,218:INFO:Naive Bayes Imported successfully
2025-06-14 16:33:21,221:INFO:SubProcess create_model() end ==================================
2025-06-14 16:33:21,221:INFO:Creating metrics dataframe
2025-06-14 16:33:21,234:INFO:Starting cross validation
2025-06-14 16:33:21,237:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:33:21,239:INFO:Initializing Decision Tree Classifier
2025-06-14 16:33:21,241:INFO:Total runtime is 0.8384210546811421 minutes
2025-06-14 16:33:21,250:INFO:SubProcess create_model() called ==================================
2025-06-14 16:33:21,250:INFO:Initializing create_model()
2025-06-14 16:33:21,250:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002027E6FEEF0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202025D5AB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:33:21,250:INFO:Checking exceptions
2025-06-14 16:33:21,250:INFO:Importing libraries
2025-06-14 16:33:21,250:INFO:Copying training dataset
2025-06-14 16:33:21,276:INFO:Defining folds
2025-06-14 16:33:21,276:INFO:Declaring metric variables
2025-06-14 16:33:21,289:INFO:Importing untrained model
2025-06-14 16:33:21,300:INFO:Decision Tree Classifier Imported successfully
2025-06-14 16:33:21,331:INFO:Starting cross validation
2025-06-14 16:33:21,334:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:33:21,765:INFO:Calculating mean and std
2025-06-14 16:33:21,771:INFO:Creating metrics dataframe
2025-06-14 16:33:21,781:INFO:Uploading results into container
2025-06-14 16:33:21,783:INFO:Uploading model into container now
2025-06-14 16:33:21,785:INFO:_master_model_container: 3
2025-06-14 16:33:21,785:INFO:_display_container: 2
2025-06-14 16:33:21,785:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-06-14 16:33:21,785:INFO:create_model() successfully completed......................................
2025-06-14 16:33:21,794:INFO:Calculating mean and std
2025-06-14 16:33:21,799:INFO:Creating metrics dataframe
2025-06-14 16:33:21,803:INFO:Uploading results into container
2025-06-14 16:33:21,805:INFO:Uploading model into container now
2025-06-14 16:33:21,807:INFO:_master_model_container: 4
2025-06-14 16:33:21,807:INFO:_display_container: 2
2025-06-14 16:33:21,809:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-06-14 16:33:21,809:INFO:create_model() successfully completed......................................
2025-06-14 16:33:21,969:INFO:SubProcess create_model() end ==================================
2025-06-14 16:33:21,969:INFO:Creating metrics dataframe
2025-06-14 16:33:22,000:INFO:Initializing Decision Tree Classifier
2025-06-14 16:33:22,000:INFO:Total runtime is 1.0158620436986288 minutes
2025-06-14 16:33:22,000:INFO:SubProcess create_model() end ==================================
2025-06-14 16:33:22,000:INFO:Creating metrics dataframe
2025-06-14 16:33:22,011:INFO:SubProcess create_model() called ==================================
2025-06-14 16:33:22,011:INFO:Initializing create_model()
2025-06-14 16:33:22,011:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001590BC53BE0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001590BC53190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:33:22,011:INFO:Checking exceptions
2025-06-14 16:33:22,011:INFO:Importing libraries
2025-06-14 16:33:22,011:INFO:Copying training dataset
2025-06-14 16:33:22,016:INFO:Initializing SVM - Linear Kernel
2025-06-14 16:33:22,016:INFO:Total runtime is 0.8513325254122416 minutes
2025-06-14 16:33:22,031:INFO:SubProcess create_model() called ==================================
2025-06-14 16:33:22,031:INFO:Initializing create_model()
2025-06-14 16:33:22,031:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002027E6FEEF0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202025D5AB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:33:22,031:INFO:Checking exceptions
2025-06-14 16:33:22,038:INFO:Importing libraries
2025-06-14 16:33:22,038:INFO:Copying training dataset
2025-06-14 16:33:22,055:INFO:Defining folds
2025-06-14 16:33:22,055:INFO:Declaring metric variables
2025-06-14 16:33:22,055:INFO:Defining folds
2025-06-14 16:33:22,055:INFO:Declaring metric variables
2025-06-14 16:33:22,055:INFO:Importing untrained model
2025-06-14 16:33:22,071:INFO:Importing untrained model
2025-06-14 16:33:22,071:INFO:Decision Tree Classifier Imported successfully
2025-06-14 16:33:22,071:INFO:SVM - Linear Kernel Imported successfully
2025-06-14 16:33:22,089:INFO:Starting cross validation
2025-06-14 16:33:22,089:INFO:Starting cross validation
2025-06-14 16:33:22,089:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:33:22,089:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:33:22,672:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:22,747:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:22,791:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:22,816:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:22,821:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:22,834:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:22,841:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:22,857:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:22,859:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:22,884:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:22,901:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:22,909:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:22,920:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:22,924:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:22,953:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:22,967:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:23,013:INFO:Calculating mean and std
2025-06-14 16:33:23,021:INFO:Creating metrics dataframe
2025-06-14 16:33:23,035:INFO:Uploading results into container
2025-06-14 16:33:23,041:INFO:Uploading model into container now
2025-06-14 16:33:23,041:INFO:_master_model_container: 5
2025-06-14 16:33:23,043:INFO:_display_container: 2
2025-06-14 16:33:23,048:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-06-14 16:33:23,048:INFO:create_model() successfully completed......................................
2025-06-14 16:33:23,522:INFO:SubProcess create_model() end ==================================
2025-06-14 16:33:23,522:INFO:Creating metrics dataframe
2025-06-14 16:33:23,578:INFO:Initializing Ridge Classifier
2025-06-14 16:33:23,578:INFO:Total runtime is 0.877374796072642 minutes
2025-06-14 16:33:23,597:INFO:SubProcess create_model() called ==================================
2025-06-14 16:33:23,599:INFO:Initializing create_model()
2025-06-14 16:33:23,601:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002027E6FEEF0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202025D5AB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:33:23,603:INFO:Checking exceptions
2025-06-14 16:33:23,603:INFO:Importing libraries
2025-06-14 16:33:23,603:INFO:Copying training dataset
2025-06-14 16:33:23,644:INFO:Defining folds
2025-06-14 16:33:23,647:INFO:Declaring metric variables
2025-06-14 16:33:23,665:INFO:Importing untrained model
2025-06-14 16:33:23,682:INFO:Ridge Classifier Imported successfully
2025-06-14 16:33:23,716:INFO:Starting cross validation
2025-06-14 16:33:23,721:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:33:23,771:INFO:Calculating mean and std
2025-06-14 16:33:23,775:INFO:Creating metrics dataframe
2025-06-14 16:33:23,780:INFO:Uploading results into container
2025-06-14 16:33:23,782:INFO:Uploading model into container now
2025-06-14 16:33:23,783:INFO:_master_model_container: 4
2025-06-14 16:33:23,783:INFO:_display_container: 2
2025-06-14 16:33:23,785:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-06-14 16:33:23,785:INFO:create_model() successfully completed......................................
2025-06-14 16:33:23,799:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:23,845:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:23,900:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:23,905:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:23,911:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:23,916:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:23,916:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:23,920:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:23,928:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:23,932:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:23,932:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:23,936:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:23,936:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:23,938:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:23,938:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:23,959:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:23,963:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:23,969:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:23,977:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:24,003:INFO:Calculating mean and std
2025-06-14 16:33:24,009:INFO:Creating metrics dataframe
2025-06-14 16:33:24,016:INFO:Uploading results into container
2025-06-14 16:33:24,018:INFO:Uploading model into container now
2025-06-14 16:33:24,019:INFO:_master_model_container: 6
2025-06-14 16:33:24,020:INFO:_display_container: 2
2025-06-14 16:33:24,020:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-06-14 16:33:24,020:INFO:create_model() successfully completed......................................
2025-06-14 16:33:24,070:INFO:SubProcess create_model() end ==================================
2025-06-14 16:33:24,072:INFO:Creating metrics dataframe
2025-06-14 16:33:24,095:INFO:Initializing SVM - Linear Kernel
2025-06-14 16:33:24,095:INFO:Total runtime is 1.0507823427518208 minutes
2025-06-14 16:33:24,105:INFO:SubProcess create_model() called ==================================
2025-06-14 16:33:24,107:INFO:Initializing create_model()
2025-06-14 16:33:24,107:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001590BC53BE0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001590BC53190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:33:24,107:INFO:Checking exceptions
2025-06-14 16:33:24,107:INFO:Importing libraries
2025-06-14 16:33:24,107:INFO:Copying training dataset
2025-06-14 16:33:24,154:INFO:Defining folds
2025-06-14 16:33:24,155:INFO:Declaring metric variables
2025-06-14 16:33:24,165:INFO:Importing untrained model
2025-06-14 16:33:24,176:INFO:SVM - Linear Kernel Imported successfully
2025-06-14 16:33:24,197:INFO:Starting cross validation
2025-06-14 16:33:24,200:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:33:24,220:INFO:SubProcess create_model() end ==================================
2025-06-14 16:33:24,220:INFO:Creating metrics dataframe
2025-06-14 16:33:24,245:INFO:Initializing Random Forest Classifier
2025-06-14 16:33:24,247:INFO:Total runtime is 0.8884812752405803 minutes
2025-06-14 16:33:24,255:INFO:SubProcess create_model() called ==================================
2025-06-14 16:33:24,255:INFO:Initializing create_model()
2025-06-14 16:33:24,255:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002027E6FEEF0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202025D5AB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:33:24,256:INFO:Checking exceptions
2025-06-14 16:33:24,256:INFO:Importing libraries
2025-06-14 16:33:24,257:INFO:Copying training dataset
2025-06-14 16:33:24,288:INFO:Defining folds
2025-06-14 16:33:24,291:INFO:Declaring metric variables
2025-06-14 16:33:24,307:INFO:Importing untrained model
2025-06-14 16:33:24,327:INFO:Random Forest Classifier Imported successfully
2025-06-14 16:33:24,361:INFO:Starting cross validation
2025-06-14 16:33:24,367:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:33:26,729:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:26,743:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:26,799:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:26,850:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:26,869:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:26,880:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:26,978:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:27,085:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:27,130:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:27,150:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:27,162:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:27,190:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:27,215:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:27,329:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:27,331:INFO:Calculating mean and std
2025-06-14 16:33:27,337:INFO:Creating metrics dataframe
2025-06-14 16:33:27,344:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:27,348:INFO:Uploading results into container
2025-06-14 16:33:27,348:INFO:Uploading model into container now
2025-06-14 16:33:27,352:INFO:_master_model_container: 5
2025-06-14 16:33:27,354:INFO:_display_container: 2
2025-06-14 16:33:27,355:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=42, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-06-14 16:33:27,355:INFO:create_model() successfully completed......................................
2025-06-14 16:33:27,439:INFO:Calculating mean and std
2025-06-14 16:33:27,442:INFO:Creating metrics dataframe
2025-06-14 16:33:27,448:INFO:Uploading results into container
2025-06-14 16:33:27,450:INFO:Uploading model into container now
2025-06-14 16:33:27,450:INFO:_master_model_container: 7
2025-06-14 16:33:27,450:INFO:_display_container: 2
2025-06-14 16:33:27,454:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-06-14 16:33:27,455:INFO:create_model() successfully completed......................................
2025-06-14 16:33:27,571:INFO:SubProcess create_model() end ==================================
2025-06-14 16:33:27,572:INFO:Creating metrics dataframe
2025-06-14 16:33:27,598:INFO:Initializing Ridge Classifier
2025-06-14 16:33:27,598:INFO:Total runtime is 1.1091692328453062 minutes
2025-06-14 16:33:27,609:INFO:SubProcess create_model() called ==================================
2025-06-14 16:33:27,610:INFO:Initializing create_model()
2025-06-14 16:33:27,611:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001590BC53BE0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001590BC53190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:33:27,611:INFO:Checking exceptions
2025-06-14 16:33:27,611:INFO:Importing libraries
2025-06-14 16:33:27,611:INFO:Copying training dataset
2025-06-14 16:33:27,657:INFO:SubProcess create_model() end ==================================
2025-06-14 16:33:27,657:INFO:Creating metrics dataframe
2025-06-14 16:33:27,658:INFO:Defining folds
2025-06-14 16:33:27,660:INFO:Declaring metric variables
2025-06-14 16:33:27,670:INFO:Importing untrained model
2025-06-14 16:33:27,680:INFO:Ridge Classifier Imported successfully
2025-06-14 16:33:27,682:INFO:Initializing Quadratic Discriminant Analysis
2025-06-14 16:33:27,682:INFO:Total runtime is 0.9457646171251933 minutes
2025-06-14 16:33:27,691:INFO:SubProcess create_model() called ==================================
2025-06-14 16:33:27,691:INFO:Initializing create_model()
2025-06-14 16:33:27,691:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002027E6FEEF0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202025D5AB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:33:27,691:INFO:Checking exceptions
2025-06-14 16:33:27,692:INFO:Importing libraries
2025-06-14 16:33:27,692:INFO:Copying training dataset
2025-06-14 16:33:27,699:INFO:Starting cross validation
2025-06-14 16:33:27,702:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:33:27,718:INFO:Defining folds
2025-06-14 16:33:27,718:INFO:Declaring metric variables
2025-06-14 16:33:27,730:INFO:Importing untrained model
2025-06-14 16:33:27,741:INFO:Quadratic Discriminant Analysis Imported successfully
2025-06-14 16:33:27,758:INFO:Starting cross validation
2025-06-14 16:33:27,760:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:33:27,790:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:27,823:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-14 16:33:27,831:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:27,833:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:27,846:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:27,966:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-14 16:33:27,992:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:28,000:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-14 16:33:28,007:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:28,010:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:28,014:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-14 16:33:28,015:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-14 16:33:28,015:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-14 16:33:28,033:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:28,033:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:28,040:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-14 16:33:28,046:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:28,048:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:28,052:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:28,052:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:28,056:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:28,060:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-14 16:33:28,064:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:28,068:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:28,070:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:28,070:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:28,073:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-14 16:33:28,092:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:28,096:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:28,100:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:28,102:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:28,111:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:28,115:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:28,118:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:28,120:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:28,130:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:28,138:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:28,138:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:28,142:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:28,154:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:28,157:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:28,163:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:28,167:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:28,188:INFO:Calculating mean and std
2025-06-14 16:33:28,191:INFO:Creating metrics dataframe
2025-06-14 16:33:28,191:INFO:Creating metrics dataframe
2025-06-14 16:33:28,196:INFO:Uploading results into container
2025-06-14 16:33:28,198:INFO:Uploading model into container now
2025-06-14 16:33:28,198:INFO:Uploading results into container
2025-06-14 16:33:28,200:INFO:_master_model_container: 6
2025-06-14 16:33:28,200:INFO:_display_container: 2
2025-06-14 16:33:28,200:INFO:Uploading model into container now
ght=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-06-14 16:33:28,200:INFO:create_model() successfully completed......................................
2025-06-14 16:33:28,200:INFO:_master_model_container: 8
2025-06-14 16:33:28,200:INFO:_display_container: 2
2025-06-14 16:33:28,202:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-06-14 16:33:28,202:INFO:create_model() successfully completed......................................
2025-06-14 16:33:28,400:INFO:SubProcess create_model() end ==================================
2025-06-14 16:33:28,400:INFO:Creating metrics dataframe
2025-06-14 16:33:28,402:INFO:SubProcess create_model() end ==================================
2025-06-14 16:33:28,404:INFO:Creating metrics dataframe
2025-06-14 16:33:28,426:INFO:Initializing Random Forest Classifier
2025-06-14 16:33:28,427:INFO:Initializing Ada Boost Classifier
2025-06-14 16:33:28,427:INFO:Total runtime is 0.9581907153129579 minutes
2025-06-14 16:33:28,427:INFO:Total runtime is 1.1229813456535338 minutes
2025-06-14 16:33:28,439:INFO:SubProcess create_model() called ==================================
2025-06-14 16:33:28,439:INFO:Initializing create_model()
2025-06-14 16:33:28,440:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001590BC53BE0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001590BC53190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:33:28,441:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002027E6FEEF0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202025D5AB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:33:28,441:INFO:Checking exceptions
2025-06-14 16:33:28,441:INFO:Importing libraries
set
2025-06-14 16:33:28,441:INFO:Copying training dataset
2025-06-14 16:33:28,471:INFO:Defining folds
2025-06-14 16:33:28,472:INFO:Declaring metric variables
2025-06-14 16:33:28,482:INFO:Importing untrained model
2025-06-14 16:33:28,490:INFO:Defining folds
2025-06-14 16:33:28,490:INFO:Declaring metric variables
2025-06-14 16:33:28,492:INFO:Ada Boost Classifier Imported successfully
2025-06-14 16:33:28,500:INFO:Importing untrained model
2025-06-14 16:33:28,511:INFO:Starting cross validation
2025-06-14 16:33:28,511:INFO:Random Forest Classifier Imported successfully
2025-06-14 16:33:28,513:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:33:28,535:INFO:Starting cross validation
2025-06-14 16:33:28,537:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:33:28,568:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:33:28,623:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:33:28,646:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:33:28,663:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:33:28,681:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:33:28,702:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:33:28,725:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:33:28,753:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:33:28,782:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:33:28,814:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:33:37,292:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:38,155:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:38,234:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:38,246:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:38,270:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:38,317:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:38,355:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:38,372:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:38,372:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:38,389:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:38,389:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:38,469:INFO:Calculating mean and std
2025-06-14 16:33:38,472:INFO:Creating metrics dataframe
2025-06-14 16:33:38,478:INFO:Uploading results into container
2025-06-14 16:33:38,483:INFO:Uploading model into container now
2025-06-14 16:33:38,487:INFO:_master_model_container: 9
2025-06-14 16:33:38,487:INFO:_display_container: 2
2025-06-14 16:33:38,489:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-06-14 16:33:38,489:INFO:create_model() successfully completed......................................
2025-06-14 16:33:38,996:INFO:SubProcess create_model() end ==================================
2025-06-14 16:33:38,998:INFO:Creating metrics dataframe
2025-06-14 16:33:39,033:INFO:Initializing Gradient Boosting Classifier
2025-06-14 16:33:39,033:INFO:Total runtime is 1.1349548697471619 minutes
2025-06-14 16:33:39,045:INFO:SubProcess create_model() called ==================================
2025-06-14 16:33:39,045:INFO:Initializing create_model()
2025-06-14 16:33:39,046:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002027E6FEEF0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202025D5AB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:33:39,046:INFO:Checking exceptions
2025-06-14 16:33:39,046:INFO:Importing libraries
2025-06-14 16:33:39,046:INFO:Copying training dataset
2025-06-14 16:33:39,054:INFO:Calculating mean and std
2025-06-14 16:33:39,058:INFO:Creating metrics dataframe
2025-06-14 16:33:39,064:INFO:Uploading results into container
2025-06-14 16:33:39,066:INFO:Uploading model into container now
2025-06-14 16:33:39,066:INFO:_master_model_container: 7
2025-06-14 16:33:39,066:INFO:_display_container: 2
2025-06-14 16:33:39,068:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-06-14 16:33:39,068:INFO:create_model() successfully completed......................................
2025-06-14 16:33:39,070:INFO:Defining folds
2025-06-14 16:33:39,070:INFO:Declaring metric variables
2025-06-14 16:33:39,082:INFO:Importing untrained model
2025-06-14 16:33:39,090:INFO:Gradient Boosting Classifier Imported successfully
2025-06-14 16:33:39,108:INFO:Starting cross validation
2025-06-14 16:33:39,110:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:33:39,403:INFO:SubProcess create_model() end ==================================
2025-06-14 16:33:39,407:INFO:Creating metrics dataframe
2025-06-14 16:33:39,457:INFO:Initializing Quadratic Discriminant Analysis
2025-06-14 16:33:39,459:INFO:Total runtime is 1.3068389932314552 minutes
2025-06-14 16:33:39,480:INFO:SubProcess create_model() called ==================================
2025-06-14 16:33:39,480:INFO:Initializing create_model()
2025-06-14 16:33:39,485:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001590BC53BE0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001590BC53190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:33:39,485:INFO:Checking exceptions
2025-06-14 16:33:39,485:INFO:Importing libraries
2025-06-14 16:33:39,485:INFO:Copying training dataset
2025-06-14 16:33:39,583:INFO:Defining folds
2025-06-14 16:33:39,583:INFO:Declaring metric variables
2025-06-14 16:33:39,605:INFO:Importing untrained model
2025-06-14 16:33:39,632:INFO:Quadratic Discriminant Analysis Imported successfully
2025-06-14 16:33:39,666:INFO:Starting cross validation
2025-06-14 16:33:39,673:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:33:39,839:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:39,901:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:39,949:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:40,124:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:40,140:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:40,164:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:40,186:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:40,237:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:40,291:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:40,297:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:40,380:INFO:Calculating mean and std
2025-06-14 16:33:40,394:INFO:Creating metrics dataframe
2025-06-14 16:33:40,411:INFO:Uploading results into container
2025-06-14 16:33:40,413:INFO:Uploading model into container now
2025-06-14 16:33:40,420:INFO:_master_model_container: 8
2025-06-14 16:33:40,420:INFO:_display_container: 2
2025-06-14 16:33:40,422:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-06-14 16:33:40,422:INFO:create_model() successfully completed......................................
2025-06-14 16:33:40,931:INFO:SubProcess create_model() end ==================================
2025-06-14 16:33:40,931:INFO:Creating metrics dataframe
2025-06-14 16:33:40,984:INFO:Initializing Ada Boost Classifier
2025-06-14 16:33:40,984:INFO:Total runtime is 1.332254644234975 minutes
2025-06-14 16:33:41,001:INFO:SubProcess create_model() called ==================================
2025-06-14 16:33:41,006:INFO:Initializing create_model()
2025-06-14 16:33:41,008:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001590BC53BE0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001590BC53190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:33:41,008:INFO:Checking exceptions
2025-06-14 16:33:41,008:INFO:Importing libraries
2025-06-14 16:33:41,008:INFO:Copying training dataset
2025-06-14 16:33:41,111:INFO:Defining folds
2025-06-14 16:33:41,115:INFO:Declaring metric variables
2025-06-14 16:33:41,133:INFO:Importing untrained model
2025-06-14 16:33:41,159:INFO:Ada Boost Classifier Imported successfully
2025-06-14 16:33:41,199:INFO:Starting cross validation
2025-06-14 16:33:41,206:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:33:41,313:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:33:41,341:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:33:41,407:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:33:41,450:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:33:41,505:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:33:41,529:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:33:41,549:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:33:41,574:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:33:41,636:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:33:41,652:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-14 16:33:50,770:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:50,794:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:50,899:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:51,200:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:51,232:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:51,239:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:51,239:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:51,295:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:51,330:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:51,339:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:51,500:INFO:Calculating mean and std
2025-06-14 16:33:51,515:INFO:Creating metrics dataframe
2025-06-14 16:33:51,531:INFO:Uploading results into container
2025-06-14 16:33:51,540:INFO:Uploading model into container now
2025-06-14 16:33:51,555:INFO:_master_model_container: 9
2025-06-14 16:33:51,555:INFO:_display_container: 2
2025-06-14 16:33:51,555:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-06-14 16:33:51,555:INFO:create_model() successfully completed......................................
2025-06-14 16:33:51,992:INFO:SubProcess create_model() end ==================================
2025-06-14 16:33:51,992:INFO:Creating metrics dataframe
2025-06-14 16:33:52,072:INFO:Initializing Gradient Boosting Classifier
2025-06-14 16:33:52,077:INFO:Total runtime is 1.5171384851137795 minutes
2025-06-14 16:33:52,100:INFO:SubProcess create_model() called ==================================
2025-06-14 16:33:52,100:INFO:Initializing create_model()
2025-06-14 16:33:52,102:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001590BC53BE0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001590BC53190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:33:52,102:INFO:Checking exceptions
2025-06-14 16:33:52,106:INFO:Importing libraries
2025-06-14 16:33:52,106:INFO:Copying training dataset
2025-06-14 16:33:52,244:INFO:Defining folds
2025-06-14 16:33:52,250:INFO:Declaring metric variables
2025-06-14 16:33:52,276:INFO:Importing untrained model
2025-06-14 16:33:52,297:INFO:Gradient Boosting Classifier Imported successfully
2025-06-14 16:33:52,333:INFO:Starting cross validation
2025-06-14 16:33:52,338:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:33:55,631:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:55,858:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:55,874:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:55,891:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:55,923:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:55,948:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:33:55,956:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:55,972:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:55,980:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:56,065:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:56,232:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:56,293:INFO:Calculating mean and std
2025-06-14 16:33:56,308:INFO:Creating metrics dataframe
2025-06-14 16:33:56,314:INFO:Uploading results into container
2025-06-14 16:33:56,318:INFO:Uploading model into container now
2025-06-14 16:33:56,320:INFO:_master_model_container: 10
2025-06-14 16:33:56,320:INFO:_display_container: 2
2025-06-14 16:33:56,321:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-14 16:33:56,324:INFO:create_model() successfully completed......................................
2025-06-14 16:33:56,806:INFO:SubProcess create_model() end ==================================
2025-06-14 16:33:56,806:INFO:Creating metrics dataframe
2025-06-14 16:33:56,871:INFO:Initializing Linear Discriminant Analysis
2025-06-14 16:33:56,872:INFO:Total runtime is 1.4322667241096496 minutes
2025-06-14 16:33:56,896:INFO:SubProcess create_model() called ==================================
2025-06-14 16:33:56,898:INFO:Initializing create_model()
2025-06-14 16:33:56,898:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002027E6FEEF0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202025D5AB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:33:56,898:INFO:Checking exceptions
2025-06-14 16:33:56,898:INFO:Importing libraries
2025-06-14 16:33:56,898:INFO:Copying training dataset
2025-06-14 16:33:56,973:INFO:Defining folds
2025-06-14 16:33:56,973:INFO:Declaring metric variables
2025-06-14 16:33:56,996:INFO:Importing untrained model
2025-06-14 16:33:57,018:INFO:Linear Discriminant Analysis Imported successfully
2025-06-14 16:33:57,066:INFO:Starting cross validation
2025-06-14 16:33:57,073:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:33:57,160:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:57,334:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:57,339:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:57,351:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:57,356:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:57,369:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:57,386:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:57,392:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:57,390:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:57,414:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:33:57,509:INFO:Calculating mean and std
2025-06-14 16:33:57,516:INFO:Creating metrics dataframe
2025-06-14 16:33:57,521:INFO:Uploading results into container
2025-06-14 16:33:57,523:INFO:Uploading model into container now
2025-06-14 16:33:57,528:INFO:_master_model_container: 11
2025-06-14 16:33:57,528:INFO:_display_container: 2
2025-06-14 16:33:57,528:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-06-14 16:33:57,528:INFO:create_model() successfully completed......................................
2025-06-14 16:33:57,946:INFO:SubProcess create_model() end ==================================
2025-06-14 16:33:57,946:INFO:Creating metrics dataframe
2025-06-14 16:33:58,003:INFO:Initializing Extra Trees Classifier
2025-06-14 16:33:58,003:INFO:Total runtime is 1.451118528842926 minutes
2025-06-14 16:33:58,027:INFO:SubProcess create_model() called ==================================
2025-06-14 16:33:58,027:INFO:Initializing create_model()
2025-06-14 16:33:58,027:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002027E6FEEF0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202025D5AB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:33:58,027:INFO:Checking exceptions
2025-06-14 16:33:58,027:INFO:Importing libraries
2025-06-14 16:33:58,027:INFO:Copying training dataset
2025-06-14 16:33:58,091:INFO:Defining folds
2025-06-14 16:33:58,091:INFO:Declaring metric variables
2025-06-14 16:33:58,118:INFO:Importing untrained model
2025-06-14 16:33:58,130:INFO:Extra Trees Classifier Imported successfully
2025-06-14 16:33:58,159:INFO:Starting cross validation
2025-06-14 16:33:58,162:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:34:00,821:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:34:00,838:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:34:00,892:INFO:Calculating mean and std
2025-06-14 16:34:00,903:INFO:Creating metrics dataframe
2025-06-14 16:34:00,913:INFO:Uploading results into container
2025-06-14 16:34:00,923:INFO:Uploading model into container now
2025-06-14 16:34:00,931:INFO:_master_model_container: 12
2025-06-14 16:34:00,931:INFO:_display_container: 2
2025-06-14 16:34:00,931:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-06-14 16:34:00,934:INFO:create_model() successfully completed......................................
2025-06-14 16:34:01,524:INFO:SubProcess create_model() end ==================================
2025-06-14 16:34:01,524:INFO:Creating metrics dataframe
2025-06-14 16:34:01,600:INFO:Initializing Extreme Gradient Boosting
2025-06-14 16:34:01,600:INFO:Total runtime is 1.5110752820968627 minutes
2025-06-14 16:34:01,626:INFO:SubProcess create_model() called ==================================
2025-06-14 16:34:01,626:INFO:Initializing create_model()
2025-06-14 16:34:01,628:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002027E6FEEF0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202025D5AB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:34:01,628:INFO:Checking exceptions
2025-06-14 16:34:01,628:INFO:Importing libraries
2025-06-14 16:34:01,628:INFO:Copying training dataset
2025-06-14 16:34:01,684:INFO:Defining folds
2025-06-14 16:34:01,690:INFO:Declaring metric variables
2025-06-14 16:34:01,711:INFO:Importing untrained model
2025-06-14 16:34:01,739:INFO:Extreme Gradient Boosting Imported successfully
2025-06-14 16:34:01,776:INFO:Starting cross validation
2025-06-14 16:34:01,778:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:34:06,695:INFO:Calculating mean and std
2025-06-14 16:34:06,709:INFO:Creating metrics dataframe
2025-06-14 16:34:06,722:INFO:Uploading results into container
2025-06-14 16:34:06,728:INFO:Uploading model into container now
2025-06-14 16:34:06,730:INFO:_master_model_container: 13
2025-06-14 16:34:06,730:INFO:_display_container: 2
2025-06-14 16:34:06,736:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-06-14 16:34:06,736:INFO:create_model() successfully completed......................................
2025-06-14 16:34:07,157:INFO:SubProcess create_model() end ==================================
2025-06-14 16:34:07,163:INFO:Creating metrics dataframe
2025-06-14 16:34:07,230:INFO:Initializing Light Gradient Boosting Machine
2025-06-14 16:34:07,230:INFO:Total runtime is 1.604906149705251 minutes
2025-06-14 16:34:07,252:INFO:SubProcess create_model() called ==================================
2025-06-14 16:34:07,252:INFO:Initializing create_model()
2025-06-14 16:34:07,252:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002027E6FEEF0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202025D5AB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:34:07,252:INFO:Checking exceptions
2025-06-14 16:34:07,252:INFO:Importing libraries
2025-06-14 16:34:07,254:INFO:Copying training dataset
2025-06-14 16:34:07,308:INFO:Defining folds
2025-06-14 16:34:07,314:INFO:Declaring metric variables
2025-06-14 16:34:07,336:INFO:Importing untrained model
2025-06-14 16:34:07,353:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-14 16:34:07,392:INFO:Starting cross validation
2025-06-14 16:34:07,394:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:35:06,346:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:35:06,346:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:35:06,420:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:35:06,463:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:35:06,525:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:35:06,586:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:35:06,602:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:35:06,679:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:35:06,823:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:35:06,833:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:35:06,882:INFO:Calculating mean and std
2025-06-14 16:35:06,888:INFO:Creating metrics dataframe
2025-06-14 16:35:06,896:INFO:Uploading results into container
2025-06-14 16:35:06,896:INFO:Uploading model into container now
2025-06-14 16:35:06,899:INFO:_master_model_container: 10
2025-06-14 16:35:06,899:INFO:_display_container: 2
2025-06-14 16:35:06,901:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-14 16:35:06,901:INFO:create_model() successfully completed......................................
2025-06-14 16:35:07,127:INFO:SubProcess create_model() end ==================================
2025-06-14 16:35:07,127:INFO:Creating metrics dataframe
2025-06-14 16:35:07,157:INFO:Initializing Linear Discriminant Analysis
2025-06-14 16:35:07,159:INFO:Total runtime is 2.7685154557228087 minutes
2025-06-14 16:35:07,173:INFO:SubProcess create_model() called ==================================
2025-06-14 16:35:07,173:INFO:Initializing create_model()
2025-06-14 16:35:07,173:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001590BC53BE0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001590BC53190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:35:07,175:INFO:Checking exceptions
2025-06-14 16:35:07,175:INFO:Importing libraries
2025-06-14 16:35:07,175:INFO:Copying training dataset
2025-06-14 16:35:07,220:INFO:Defining folds
2025-06-14 16:35:07,221:INFO:Declaring metric variables
2025-06-14 16:35:07,232:INFO:Importing untrained model
2025-06-14 16:35:07,244:INFO:Linear Discriminant Analysis Imported successfully
2025-06-14 16:35:07,266:INFO:Starting cross validation
2025-06-14 16:35:07,268:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:35:07,379:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:35:07,536:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:35:07,548:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:35:07,581:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:35:07,591:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:35:07,606:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:35:07,608:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:35:07,612:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:35:07,634:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:35:07,675:INFO:Calculating mean and std
2025-06-14 16:35:07,679:INFO:Creating metrics dataframe
2025-06-14 16:35:07,686:INFO:Uploading results into container
2025-06-14 16:35:07,688:INFO:Uploading model into container now
2025-06-14 16:35:07,688:INFO:_master_model_container: 11
2025-06-14 16:35:07,688:INFO:_display_container: 2
2025-06-14 16:35:07,690:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-06-14 16:35:07,690:INFO:create_model() successfully completed......................................
2025-06-14 16:35:07,905:INFO:SubProcess create_model() end ==================================
2025-06-14 16:35:07,906:INFO:Creating metrics dataframe
2025-06-14 16:35:07,939:INFO:Initializing Extra Trees Classifier
2025-06-14 16:35:07,941:INFO:Total runtime is 2.781540334224701 minutes
2025-06-14 16:35:07,950:INFO:SubProcess create_model() called ==================================
2025-06-14 16:35:07,950:INFO:Initializing create_model()
2025-06-14 16:35:07,950:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001590BC53BE0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001590BC53190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:35:07,952:INFO:Checking exceptions
2025-06-14 16:35:07,952:INFO:Importing libraries
2025-06-14 16:35:07,952:INFO:Copying training dataset
2025-06-14 16:35:07,999:INFO:Defining folds
2025-06-14 16:35:07,999:INFO:Declaring metric variables
2025-06-14 16:35:08,010:INFO:Importing untrained model
2025-06-14 16:35:08,022:INFO:Extra Trees Classifier Imported successfully
2025-06-14 16:35:08,041:INFO:Starting cross validation
2025-06-14 16:35:08,043:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:35:12,339:INFO:Calculating mean and std
2025-06-14 16:35:12,345:INFO:Creating metrics dataframe
2025-06-14 16:35:12,351:INFO:Uploading results into container
2025-06-14 16:35:12,353:INFO:Uploading model into container now
2025-06-14 16:35:12,354:INFO:_master_model_container: 12
2025-06-14 16:35:12,354:INFO:_display_container: 2
2025-06-14 16:35:12,356:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-06-14 16:35:12,356:INFO:create_model() successfully completed......................................
2025-06-14 16:35:12,576:INFO:SubProcess create_model() end ==================================
2025-06-14 16:35:12,576:INFO:Creating metrics dataframe
2025-06-14 16:35:12,611:INFO:Initializing Extreme Gradient Boosting
2025-06-14 16:35:12,611:INFO:Total runtime is 2.8593726833661397 minutes
2025-06-14 16:35:12,621:INFO:SubProcess create_model() called ==================================
2025-06-14 16:35:12,623:INFO:Initializing create_model()
2025-06-14 16:35:12,624:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001590BC53BE0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001590BC53190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:35:12,624:INFO:Checking exceptions
2025-06-14 16:35:12,624:INFO:Importing libraries
2025-06-14 16:35:12,624:INFO:Copying training dataset
2025-06-14 16:35:12,672:INFO:Defining folds
2025-06-14 16:35:12,672:INFO:Declaring metric variables
2025-06-14 16:35:12,683:INFO:Importing untrained model
2025-06-14 16:35:12,694:INFO:Extreme Gradient Boosting Imported successfully
2025-06-14 16:35:12,715:INFO:Starting cross validation
2025-06-14 16:35:12,718:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:35:20,238:INFO:Calculating mean and std
2025-06-14 16:35:20,244:INFO:Creating metrics dataframe
2025-06-14 16:35:20,249:INFO:Uploading results into container
2025-06-14 16:35:20,250:INFO:Uploading model into container now
2025-06-14 16:35:20,251:INFO:_master_model_container: 13
2025-06-14 16:35:20,251:INFO:_display_container: 2
2025-06-14 16:35:20,253:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=None, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=None, max_bin=None, max_cat_threshold=None,
              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
              max_leaves=None, min_child_weight=None, missing=nan,
              monotone_constraints=None, multi_strategy=None, n_estimators=None,
              n_jobs=-1, num_parallel_tree=None, ...)
2025-06-14 16:35:20,253:INFO:create_model() successfully completed......................................
2025-06-14 16:35:20,479:INFO:SubProcess create_model() end ==================================
2025-06-14 16:35:20,479:INFO:Creating metrics dataframe
2025-06-14 16:35:20,519:INFO:Initializing Light Gradient Boosting Machine
2025-06-14 16:35:20,519:INFO:Total runtime is 2.991173772017161 minutes
2025-06-14 16:35:20,529:INFO:SubProcess create_model() called ==================================
2025-06-14 16:35:20,531:INFO:Initializing create_model()
2025-06-14 16:35:20,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001590BC53BE0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001590BC53190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:35:20,533:INFO:Checking exceptions
2025-06-14 16:35:20,533:INFO:Importing libraries
2025-06-14 16:35:20,533:INFO:Copying training dataset
2025-06-14 16:35:20,587:INFO:Defining folds
2025-06-14 16:35:20,587:INFO:Declaring metric variables
2025-06-14 16:35:20,598:INFO:Importing untrained model
2025-06-14 16:35:20,611:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-14 16:35:20,633:INFO:Starting cross validation
2025-06-14 16:35:20,637:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:35:24,143:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:35:24,392:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:35:25,008:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:35:25,246:INFO:Calculating mean and std
2025-06-14 16:35:25,250:INFO:Creating metrics dataframe
2025-06-14 16:35:25,258:INFO:Uploading results into container
2025-06-14 16:35:25,259:INFO:Uploading model into container now
2025-06-14 16:35:25,261:INFO:_master_model_container: 14
2025-06-14 16:35:25,261:INFO:_display_container: 2
2025-06-14 16:35:25,263:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-06-14 16:35:25,263:INFO:create_model() successfully completed......................................
2025-06-14 16:35:25,505:INFO:SubProcess create_model() end ==================================
2025-06-14 16:35:25,505:INFO:Creating metrics dataframe
2025-06-14 16:35:25,543:INFO:Initializing Dummy Classifier
2025-06-14 16:35:25,545:INFO:Total runtime is 3.5303928176561987 minutes
2025-06-14 16:35:25,555:INFO:SubProcess create_model() called ==================================
2025-06-14 16:35:25,556:INFO:Initializing create_model()
2025-06-14 16:35:25,556:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A27382E290>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A276004940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:35:25,558:INFO:Checking exceptions
2025-06-14 16:35:25,558:INFO:Importing libraries
2025-06-14 16:35:25,558:INFO:Copying training dataset
2025-06-14 16:35:25,589:INFO:Defining folds
2025-06-14 16:35:25,590:INFO:Declaring metric variables
2025-06-14 16:35:25,602:INFO:Importing untrained model
2025-06-14 16:35:25,614:INFO:Dummy Classifier Imported successfully
2025-06-14 16:35:25,637:INFO:Starting cross validation
2025-06-14 16:35:25,640:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:35:25,715:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:35:25,783:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:35:25,819:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:35:25,821:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:35:25,825:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:35:25,825:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:35:25,835:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:35:25,839:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:35:25,841:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:35:25,843:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:35:25,871:INFO:Calculating mean and std
2025-06-14 16:35:25,876:INFO:Creating metrics dataframe
2025-06-14 16:35:25,883:INFO:Uploading results into container
2025-06-14 16:35:25,884:INFO:Uploading model into container now
2025-06-14 16:35:25,887:INFO:_master_model_container: 15
2025-06-14 16:35:25,887:INFO:_display_container: 2
2025-06-14 16:35:25,887:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-06-14 16:35:25,888:INFO:create_model() successfully completed......................................
2025-06-14 16:35:26,119:INFO:SubProcess create_model() end ==================================
2025-06-14 16:35:26,120:INFO:Creating metrics dataframe
2025-06-14 16:35:26,165:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-06-14 16:35:26,196:INFO:Initializing create_model()
2025-06-14 16:35:26,196:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A27382E290>, estimator=DummyClassifier(constant=None, random_state=42, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:35:26,196:INFO:Checking exceptions
2025-06-14 16:35:26,202:INFO:Importing libraries
2025-06-14 16:35:26,202:INFO:Copying training dataset
2025-06-14 16:35:26,223:INFO:Defining folds
2025-06-14 16:35:26,223:INFO:Declaring metric variables
2025-06-14 16:35:26,225:INFO:Importing untrained model
2025-06-14 16:35:26,226:INFO:Declaring custom model
2025-06-14 16:35:26,226:INFO:Dummy Classifier Imported successfully
2025-06-14 16:35:26,228:INFO:Cross validation set to False
2025-06-14 16:35:26,228:INFO:Fitting Model
2025-06-14 16:35:26,256:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-06-14 16:35:26,256:INFO:create_model() successfully completed......................................
2025-06-14 16:35:26,583:INFO:_master_model_container: 15
2025-06-14 16:35:26,583:INFO:_display_container: 2
2025-06-14 16:35:26,584:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-06-14 16:35:26,584:INFO:compare_models() successfully completed......................................
2025-06-14 16:35:26,611:INFO:Initializing create_model()
2025-06-14 16:35:26,611:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A27382E290>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced'})
2025-06-14 16:35:26,611:INFO:Checking exceptions
2025-06-14 16:35:26,661:INFO:Importing libraries
2025-06-14 16:35:26,661:INFO:Copying training dataset
2025-06-14 16:35:26,687:INFO:Defining folds
2025-06-14 16:35:26,687:INFO:Declaring metric variables
2025-06-14 16:35:26,700:INFO:Importing untrained model
2025-06-14 16:35:26,713:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-14 16:35:26,738:INFO:Starting cross validation
2025-06-14 16:35:26,738:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:35:50,604:INFO:Calculating mean and std
2025-06-14 16:35:50,608:INFO:Creating metrics dataframe
2025-06-14 16:35:50,614:INFO:Uploading results into container
2025-06-14 16:35:50,617:INFO:Uploading model into container now
2025-06-14 16:35:50,618:INFO:_master_model_container: 14
2025-06-14 16:35:50,618:INFO:_display_container: 2
2025-06-14 16:35:50,619:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-06-14 16:35:50,620:INFO:create_model() successfully completed......................................
2025-06-14 16:35:50,830:INFO:SubProcess create_model() end ==================================
2025-06-14 16:35:50,830:INFO:Creating metrics dataframe
2025-06-14 16:35:50,866:INFO:Initializing Dummy Classifier
2025-06-14 16:35:50,867:INFO:Total runtime is 4.271763706207275 minutes
2025-06-14 16:35:50,876:INFO:SubProcess create_model() called ==================================
2025-06-14 16:35:50,878:INFO:Initializing create_model()
2025-06-14 16:35:50,878:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BDBC5ED40>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BDF481CC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:35:50,878:INFO:Checking exceptions
2025-06-14 16:35:50,879:INFO:Importing libraries
2025-06-14 16:35:50,879:INFO:Copying training dataset
2025-06-14 16:35:50,917:INFO:Defining folds
2025-06-14 16:35:50,919:INFO:Declaring metric variables
2025-06-14 16:35:50,929:INFO:Importing untrained model
2025-06-14 16:35:50,939:INFO:Dummy Classifier Imported successfully
2025-06-14 16:35:50,960:INFO:Starting cross validation
2025-06-14 16:35:50,962:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:35:51,013:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:35:51,135:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:35:51,144:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:35:51,154:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:35:51,163:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:35:51,163:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:35:51,163:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:35:51,165:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:35:51,173:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:35:51,180:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:35:51,204:INFO:Calculating mean and std
2025-06-14 16:35:51,208:INFO:Creating metrics dataframe
2025-06-14 16:35:51,215:INFO:Uploading results into container
2025-06-14 16:35:51,217:INFO:Uploading model into container now
2025-06-14 16:35:51,218:INFO:_master_model_container: 15
2025-06-14 16:35:51,218:INFO:_display_container: 2
2025-06-14 16:35:51,220:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-06-14 16:35:51,220:INFO:create_model() successfully completed......................................
2025-06-14 16:35:51,433:INFO:SubProcess create_model() end ==================================
2025-06-14 16:35:51,435:INFO:Creating metrics dataframe
2025-06-14 16:35:51,475:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-06-14 16:35:51,497:INFO:Initializing create_model()
2025-06-14 16:35:51,497:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BDBC5ED40>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:35:51,497:INFO:Checking exceptions
2025-06-14 16:35:51,505:INFO:Importing libraries
2025-06-14 16:35:51,505:INFO:Copying training dataset
2025-06-14 16:35:51,541:INFO:Defining folds
2025-06-14 16:35:51,541:INFO:Declaring metric variables
2025-06-14 16:35:51,542:INFO:Importing untrained model
2025-06-14 16:35:51,542:INFO:Declaring custom model
2025-06-14 16:35:51,545:INFO:Gradient Boosting Classifier Imported successfully
2025-06-14 16:35:51,548:INFO:Cross validation set to False
2025-06-14 16:35:51,548:INFO:Fitting Model
2025-06-14 16:36:01,156:INFO:Calculating mean and std
2025-06-14 16:36:01,160:INFO:Creating metrics dataframe
2025-06-14 16:36:01,166:INFO:Uploading results into container
2025-06-14 16:36:01,167:INFO:Uploading model into container now
2025-06-14 16:36:01,169:INFO:_master_model_container: 14
2025-06-14 16:36:01,169:INFO:_display_container: 2
2025-06-14 16:36:01,171:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-06-14 16:36:01,171:INFO:create_model() successfully completed......................................
2025-06-14 16:36:01,387:INFO:SubProcess create_model() end ==================================
2025-06-14 16:36:01,387:INFO:Creating metrics dataframe
2025-06-14 16:36:01,416:INFO:Initializing Dummy Classifier
2025-06-14 16:36:01,418:INFO:Total runtime is 3.5080427487691246 minutes
2025-06-14 16:36:01,428:INFO:SubProcess create_model() called ==================================
2025-06-14 16:36:01,429:INFO:Initializing create_model()
2025-06-14 16:36:01,430:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002027E6FEEF0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202025D5AB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:36:01,431:INFO:Checking exceptions
2025-06-14 16:36:01,431:INFO:Importing libraries
2025-06-14 16:36:01,431:INFO:Copying training dataset
2025-06-14 16:36:01,454:INFO:Defining folds
2025-06-14 16:36:01,454:INFO:Declaring metric variables
2025-06-14 16:36:01,465:INFO:Importing untrained model
2025-06-14 16:36:01,475:INFO:Dummy Classifier Imported successfully
2025-06-14 16:36:01,494:INFO:Starting cross validation
2025-06-14 16:36:01,496:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:36:01,548:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:36:01,626:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:36:01,637:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:36:01,655:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:36:01,659:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:36:01,663:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:36:01,666:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:36:01,667:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:36:01,677:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:36:01,688:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:36:01,719:INFO:Calculating mean and std
2025-06-14 16:36:01,724:INFO:Creating metrics dataframe
2025-06-14 16:36:01,729:INFO:Uploading results into container
2025-06-14 16:36:01,732:INFO:Uploading model into container now
2025-06-14 16:36:01,732:INFO:_master_model_container: 15
2025-06-14 16:36:01,733:INFO:_display_container: 2
2025-06-14 16:36:01,733:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-06-14 16:36:01,733:INFO:create_model() successfully completed......................................
2025-06-14 16:36:01,928:INFO:SubProcess create_model() end ==================================
2025-06-14 16:36:01,929:INFO:Creating metrics dataframe
2025-06-14 16:36:01,968:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-06-14 16:36:01,992:INFO:Initializing create_model()
2025-06-14 16:36:01,993:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002027E6FEEF0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:36:01,993:INFO:Checking exceptions
2025-06-14 16:36:01,998:INFO:Importing libraries
2025-06-14 16:36:01,998:INFO:Copying training dataset
2025-06-14 16:36:02,023:INFO:Defining folds
2025-06-14 16:36:02,024:INFO:Declaring metric variables
2025-06-14 16:36:02,024:INFO:Importing untrained model
2025-06-14 16:36:02,025:INFO:Declaring custom model
2025-06-14 16:36:02,026:INFO:Ridge Classifier Imported successfully
2025-06-14 16:36:02,028:INFO:Cross validation set to False
2025-06-14 16:36:02,028:INFO:Fitting Model
2025-06-14 16:36:02,062:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-06-14 16:36:02,062:INFO:create_model() successfully completed......................................
2025-06-14 16:36:02,359:INFO:_master_model_container: 15
2025-06-14 16:36:02,359:INFO:_display_container: 2
2025-06-14 16:36:02,360:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2025-06-14 16:36:02,360:INFO:compare_models() successfully completed......................................
2025-06-14 16:36:02,377:INFO:Initializing create_model()
2025-06-14 16:36:02,377:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002027E6FEEF0>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:36:02,377:INFO:Checking exceptions
2025-06-14 16:36:02,420:INFO:Importing libraries
2025-06-14 16:36:02,422:INFO:Copying training dataset
2025-06-14 16:36:02,449:INFO:Defining folds
2025-06-14 16:36:02,449:INFO:Declaring metric variables
2025-06-14 16:36:02,459:INFO:Importing untrained model
2025-06-14 16:36:02,471:INFO:Gradient Boosting Classifier Imported successfully
2025-06-14 16:36:02,488:INFO:Starting cross validation
2025-06-14 16:36:02,490:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:36:12,274:INFO:Calculating mean and std
2025-06-14 16:36:12,286:INFO:Creating metrics dataframe
2025-06-14 16:36:12,324:INFO:Finalizing model
2025-06-14 16:36:12,582:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069644 seconds.
2025-06-14 16:36:12,582:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-06-14 16:36:12,582:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-06-14 16:36:12,582:INFO:[LightGBM] [Info] Total Bins 1682
2025-06-14 16:36:12,588:INFO:[LightGBM] [Info] Number of data points in the train set: 541, number of used features: 24
2025-06-14 16:36:12,588:INFO:[LightGBM] [Info] Start training from score -1.098612
2025-06-14 16:36:12,590:INFO:[LightGBM] [Info] Start training from score -1.098612
2025-06-14 16:36:12,590:INFO:[LightGBM] [Info] Start training from score -1.098612
2025-06-14 16:36:12,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:13,061:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:36:13,142:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:36:13,144:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:36:13,165:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:36:13,170:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:36:13,174:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:36:13,174:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:36:13,202:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:36:13,202:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:36:13,209:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:36:13,241:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:36:13,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:13,269:INFO:Calculating mean and std
2025-06-14 16:36:13,274:INFO:Creating metrics dataframe
2025-06-14 16:36:13,289:INFO:Finalizing model
2025-06-14 16:36:13,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:13,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:13,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:13,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:13,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:13,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:13,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:13,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:13,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:13,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:13,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:13,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:13,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:13,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:14,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:14,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:14,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:14,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:14,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:14,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:14,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:14,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:14,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:14,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:14,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:14,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:14,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:14,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:14,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:14,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:14,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:14,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:15,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:15,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:15,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:15,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:15,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:15,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:15,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:15,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:15,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:15,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:15,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:15,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:15,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:15,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:15,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:15,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:15,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:15,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:15,941:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-14 16:36:15,942:INFO:create_model() successfully completed......................................
2025-06-14 16:36:15,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:15,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:16,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:16,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:16,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:16,188:INFO:_master_model_container: 15
2025-06-14 16:36:16,188:INFO:_display_container: 2
2025-06-14 16:36:16,189:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-14 16:36:16,190:INFO:compare_models() successfully completed......................................
2025-06-14 16:36:16,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:16,201:INFO:Initializing create_model()
2025-06-14 16:36:16,202:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BDBC5ED40>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced'})
2025-06-14 16:36:16,202:INFO:Checking exceptions
2025-06-14 16:36:16,238:INFO:Importing libraries
2025-06-14 16:36:16,238:INFO:Copying training dataset
2025-06-14 16:36:16,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:16,266:INFO:Defining folds
2025-06-14 16:36:16,266:INFO:Declaring metric variables
2025-06-14 16:36:16,275:INFO:Importing untrained model
2025-06-14 16:36:16,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:16,285:INFO:Extreme Gradient Boosting Imported successfully
2025-06-14 16:36:16,299:INFO:Starting cross validation
2025-06-14 16:36:16,301:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:36:16,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:16,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:16,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:17,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:17,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:18,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:18,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:18,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:19,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:19,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:20,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:20,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:20,539:INFO:Uploading results into container
2025-06-14 16:36:20,544:INFO:Uploading model into container now
2025-06-14 16:36:20,589:INFO:_master_model_container: 16
2025-06-14 16:36:20,589:INFO:_display_container: 3
2025-06-14 16:36:20,594:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-14 16:36:20,594:INFO:create_model() successfully completed......................................
2025-06-14 16:36:20,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:21,053:INFO:Initializing tune_model()
2025-06-14 16:36:21,053:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002027E6FEEF0>)
2025-06-14 16:36:21,053:INFO:Checking exceptions
2025-06-14 16:36:21,150:INFO:Copying training dataset
2025-06-14 16:36:21,175:INFO:Checking base model
2025-06-14 16:36:21,177:INFO:Base model : Gradient Boosting Classifier
2025-06-14 16:36:21,201:INFO:Declaring metric variables
2025-06-14 16:36:21,215:INFO:Defining Hyperparameters
2025-06-14 16:36:21,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:21,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:21,451:INFO:Calculating mean and std
2025-06-14 16:36:21,455:INFO:Creating metrics dataframe
2025-06-14 16:36:21,469:INFO:Finalizing model
2025-06-14 16:36:21,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:21,481:INFO:Tuning with n_jobs=-1
2025-06-14 16:36:21,481:INFO:Initializing RandomizedSearchCV
2025-06-14 16:36:21,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:21,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:22,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:22,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:23,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:24,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:25,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:25,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:26,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:27,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:28,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:28,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:29,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:30,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:31,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:31,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:32,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:33,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:34,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:34,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:35,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:36,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:37,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:37,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:38,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:39,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:39,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:40,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:41,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:42,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:42,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:43,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:44,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:44,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:45,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:46,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:47,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:48,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:48,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:49,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:50,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:51,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:51,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:52,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:53,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:54,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:54,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:55,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:56,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:57,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:58,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:58,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:36:59,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:00,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:01,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:01,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:02,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:03,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:03,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:04,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:05,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:06,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:07,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:07,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:08,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:09,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:09,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:10,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:11,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:11,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:12,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:12,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:13,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:14,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:14,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:14,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:15,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:15,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:16,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:16,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:16,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:17,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:17,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:17,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:18,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:18,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:18,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:18,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:18,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,864:INFO:Uploading results into container
2025-06-14 16:37:19,866:INFO:Uploading model into container now
2025-06-14 16:37:19,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,888:INFO:_master_model_container: 16
2025-06-14 16:37:19,889:INFO:_display_container: 3
2025-06-14 16:37:19,891:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1, ...)
2025-06-14 16:37:19,891:INFO:create_model() successfully completed......................................
2025-06-14 16:37:19,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:19,990:INFO:best_params: {'actual_estimator__subsample': 0.65, 'actual_estimator__n_estimators': 120, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 6, 'actual_estimator__learning_rate': 0.05}
2025-06-14 16:37:19,997:INFO:Hyperparameter search completed
2025-06-14 16:37:19,999:INFO:SubProcess create_model() called ==================================
2025-06-14 16:37:19,999:INFO:Initializing create_model()
2025-06-14 16:37:19,999:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002027E6FEEF0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000202025D5E10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.65, 'n_estimators': 120, 'min_samples_split': 5, 'min_samples_leaf': 3, 'min_impurity_decrease': 0.0002, 'max_features': 'sqrt', 'max_depth': 6, 'learning_rate': 0.05})
2025-06-14 16:37:20,001:INFO:Checking exceptions
2025-06-14 16:37:20,001:INFO:Importing libraries
2025-06-14 16:37:20,001:INFO:Copying training dataset
2025-06-14 16:37:20,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:20,019:INFO:Defining folds
2025-06-14 16:37:20,020:INFO:Declaring metric variables
2025-06-14 16:37:20,027:INFO:Importing untrained model
2025-06-14 16:37:20,028:INFO:Declaring custom model
2025-06-14 16:37:20,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:20,038:INFO:Gradient Boosting Classifier Imported successfully
2025-06-14 16:37:20,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:20,053:INFO:Starting cross validation
2025-06-14 16:37:20,054:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:37:20,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:20,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:20,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:20,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:20,174:INFO:Initializing tune_model()
2025-06-14 16:37:20,176:INFO:tune_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1, ...), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BDBC5ED40>)
2025-06-14 16:37:20,176:INFO:Checking exceptions
2025-06-14 16:37:20,282:INFO:Copying training dataset
2025-06-14 16:37:20,330:INFO:Checking base model
2025-06-14 16:37:20,331:INFO:Base model : Extreme Gradient Boosting
2025-06-14 16:37:20,357:INFO:Declaring metric variables
2025-06-14 16:37:20,379:INFO:Defining Hyperparameters
2025-06-14 16:37:20,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:20,674:INFO:Calculating mean and std
2025-06-14 16:37:20,684:INFO:Creating metrics dataframe
2025-06-14 16:37:20,694:INFO:Uploading results into container
2025-06-14 16:37:20,698:INFO:Uploading model into container now
2025-06-14 16:37:20,701:INFO:_master_model_container: 14
2025-06-14 16:37:20,702:INFO:_display_container: 2
2025-06-14 16:37:20,704:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-06-14 16:37:20,704:INFO:create_model() successfully completed......................................
2025-06-14 16:37:20,773:INFO:Tuning with n_jobs=-1
2025-06-14 16:37:20,773:INFO:Initializing RandomizedSearchCV
2025-06-14 16:37:20,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:21,232:INFO:SubProcess create_model() end ==================================
2025-06-14 16:37:21,232:INFO:Creating metrics dataframe
2025-06-14 16:37:21,379:INFO:Initializing Dummy Classifier
2025-06-14 16:37:21,380:INFO:Total runtime is 5.0055365840593975 minutes
2025-06-14 16:37:21,430:INFO:SubProcess create_model() called ==================================
2025-06-14 16:37:21,441:INFO:Initializing create_model()
2025-06-14 16:37:21,441:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001590BC53BE0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001590BC53190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:37:21,441:INFO:Checking exceptions
2025-06-14 16:37:21,441:INFO:Importing libraries
2025-06-14 16:37:21,441:INFO:Copying training dataset
2025-06-14 16:37:21,684:INFO:Defining folds
2025-06-14 16:37:21,685:INFO:Declaring metric variables
2025-06-14 16:37:21,748:INFO:Importing untrained model
2025-06-14 16:37:21,811:INFO:Dummy Classifier Imported successfully
2025-06-14 16:37:21,897:INFO:Starting cross validation
2025-06-14 16:37:21,899:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:37:21,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:21,989:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:37:22,062:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:37:22,132:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:37:22,177:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:37:22,473:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:37:22,589:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:37:22,591:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:37:22,593:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:37:22,599:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:37:22,650:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:37:22,739:INFO:Calculating mean and std
2025-06-14 16:37:22,743:INFO:Creating metrics dataframe
2025-06-14 16:37:22,783:INFO:Uploading results into container
2025-06-14 16:37:22,783:INFO:Uploading model into container now
2025-06-14 16:37:22,796:INFO:_master_model_container: 15
2025-06-14 16:37:22,796:INFO:_display_container: 2
2025-06-14 16:37:22,796:INFO:DummyClassifier(constant=None, random_state=42, strategy='prior')
2025-06-14 16:37:22,806:INFO:create_model() successfully completed......................................
2025-06-14 16:37:23,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:23,918:INFO:SubProcess create_model() end ==================================
2025-06-14 16:37:23,921:INFO:Creating metrics dataframe
2025-06-14 16:37:24,217:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-06-14 16:37:24,341:INFO:Initializing create_model()
2025-06-14 16:37:24,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001590BC53BE0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:37:24,351:INFO:Checking exceptions
2025-06-14 16:37:24,377:INFO:Importing libraries
2025-06-14 16:37:24,377:INFO:Copying training dataset
2025-06-14 16:37:24,612:INFO:Defining folds
2025-06-14 16:37:24,614:INFO:Declaring metric variables
2025-06-14 16:37:24,614:INFO:Importing untrained model
2025-06-14 16:37:24,614:INFO:Declaring custom model
2025-06-14 16:37:24,616:INFO:Random Forest Classifier Imported successfully
2025-06-14 16:37:24,629:INFO:Cross validation set to False
2025-06-14 16:37:24,629:INFO:Fitting Model
2025-06-14 16:37:24,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:26,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:27,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:28,079:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-06-14 16:37:28,089:INFO:create_model() successfully completed......................................
2025-06-14 16:37:28,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:29,516:INFO:_master_model_container: 15
2025-06-14 16:37:29,516:INFO:_display_container: 2
2025-06-14 16:37:29,516:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-06-14 16:37:29,528:INFO:compare_models() successfully completed......................................
2025-06-14 16:37:29,576:INFO:Initializing create_model()
2025-06-14 16:37:29,576:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001590BC53BE0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced'})
2025-06-14 16:37:29,578:INFO:Checking exceptions
2025-06-14 16:37:29,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:29,762:INFO:Importing libraries
2025-06-14 16:37:29,773:INFO:Copying training dataset
2025-06-14 16:37:30,063:INFO:Defining folds
2025-06-14 16:37:30,063:INFO:Declaring metric variables
2025-06-14 16:37:30,125:INFO:Importing untrained model
2025-06-14 16:37:30,192:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-14 16:37:30,262:INFO:Starting cross validation
2025-06-14 16:37:30,275:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:37:31,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:32,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:33,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:34,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:35,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:36,819:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:37:36,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:36,877:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:37:37,297:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:37:37,400:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:37:37,456:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:37:37,569:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:37:37,797:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:37:37,844:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:37:37,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:38,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:39,114:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:37:39,338:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:37:39,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:39,755:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:37:39,912:INFO:Calculating mean and std
2025-06-14 16:37:39,933:INFO:Creating metrics dataframe
2025-06-14 16:37:40,005:INFO:Finalizing model
2025-06-14 16:37:40,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:41,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:41,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:42,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:43,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:44,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:45,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:46,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:46,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:47,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:48,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:49,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:49,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:50,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:51,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:52,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:53,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:54,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:54,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:55,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:56,030:INFO:Uploading results into container
2025-06-14 16:37:56,040:INFO:Uploading model into container now
2025-06-14 16:37:56,048:INFO:_master_model_container: 17
2025-06-14 16:37:56,048:INFO:_display_container: 4
2025-06-14 16:37:56,056:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='log_loss', max_depth=6,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.0002, min_samples_leaf=3,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=120, n_iter_no_change=None,
                           random_state=42, subsample=0.65, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-14 16:37:56,056:INFO:create_model() successfully completed......................................
2025-06-14 16:37:56,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:56,890:INFO:SubProcess create_model() end ==================================
2025-06-14 16:37:56,890:INFO:choose_better activated
2025-06-14 16:37:56,922:INFO:SubProcess create_model() called ==================================
2025-06-14 16:37:56,924:INFO:Initializing create_model()
2025-06-14 16:37:56,926:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002027E6FEEF0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:37:56,926:INFO:Checking exceptions
2025-06-14 16:37:56,946:INFO:Importing libraries
2025-06-14 16:37:56,946:INFO:Copying training dataset
2025-06-14 16:37:57,035:INFO:Defining folds
2025-06-14 16:37:57,037:INFO:Declaring metric variables
2025-06-14 16:37:57,043:INFO:Importing untrained model
2025-06-14 16:37:57,045:INFO:Declaring custom model
2025-06-14 16:37:57,047:INFO:Gradient Boosting Classifier Imported successfully
2025-06-14 16:37:57,047:INFO:Starting cross validation
2025-06-14 16:37:57,065:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:37:57,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:58,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:37:59,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:01,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:02,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:03,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:04,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:05,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:06,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:06,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:06,951:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__scale_pos_weight': 38.0, 'actual_estimator__reg_lambda': 0.7, 'actual_estimator__reg_alpha': 0.001, 'actual_estimator__n_estimators': 60, 'actual_estimator__min_child_weight': 1, 'actual_estimator__max_depth': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__colsample_bytree': 0.7}
2025-06-14 16:38:06,957:INFO:Hyperparameter search completed
2025-06-14 16:38:06,958:INFO:SubProcess create_model() called ==================================
2025-06-14 16:38:06,962:INFO:Initializing create_model()
2025-06-14 16:38:06,962:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BDBC5ED40>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000021BDF1817E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.7, 'scale_pos_weight': 38.0, 'reg_lambda': 0.7, 'reg_alpha': 0.001, 'n_estimators': 60, 'min_child_weight': 1, 'max_depth': 6, 'learning_rate': 0.4, 'colsample_bytree': 0.7})
2025-06-14 16:38:06,964:INFO:Checking exceptions
2025-06-14 16:38:06,964:INFO:Importing libraries
2025-06-14 16:38:06,964:INFO:Copying training dataset
2025-06-14 16:38:07,035:INFO:Defining folds
2025-06-14 16:38:07,035:INFO:Declaring metric variables
2025-06-14 16:38:07,054:INFO:Importing untrained model
2025-06-14 16:38:07,054:INFO:Declaring custom model
2025-06-14 16:38:07,077:INFO:Extreme Gradient Boosting Imported successfully
2025-06-14 16:38:07,115:INFO:Starting cross validation
2025-06-14 16:38:07,119:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:38:07,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:07,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:08,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:09,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:10,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:11,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:12,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:12,522:INFO:Calculating mean and std
2025-06-14 16:38:12,522:INFO:Creating metrics dataframe
2025-06-14 16:38:12,559:INFO:Finalizing model
2025-06-14 16:38:12,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:13,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:13,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:14,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:14,488:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:38:14,570:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:38:14,589:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:38:14,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:14,625:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:38:14,681:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:38:14,691:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:38:14,724:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:38:14,736:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:38:14,748:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:38:14,748:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:38:14,752:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-06-14 16:38:14,762:WARNING:C:\Users\omslu\anaconda3\envs\pycaret_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-14 16:38:14,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:14,793:INFO:Calculating mean and std
2025-06-14 16:38:14,796:INFO:Creating metrics dataframe
2025-06-14 16:38:14,800:INFO:Finalizing model
2025-06-14 16:38:14,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:14,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:14,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:15,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:15,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:15,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:15,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:15,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:15,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:15,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:15,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:38:15,453:INFO:Uploading results into container
2025-06-14 16:38:15,457:INFO:Uploading model into container now
2025-06-14 16:38:15,485:INFO:_master_model_container: 16
2025-06-14 16:38:15,485:INFO:_display_container: 3
2025-06-14 16:38:15,487:INFO:LGBMClassifier(boosting_type='gbdt', class_weight='balanced',
               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-06-14 16:38:15,487:INFO:create_model() successfully completed......................................
2025-06-14 16:38:15,688:INFO:Initializing tune_model()
2025-06-14 16:38:15,688:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight='balanced',
               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A27382E290>)
2025-06-14 16:38:15,688:INFO:Checking exceptions
2025-06-14 16:38:15,738:INFO:Copying training dataset
2025-06-14 16:38:15,754:INFO:Checking base model
2025-06-14 16:38:15,754:INFO:Base model : Light Gradient Boosting Machine
2025-06-14 16:38:15,766:INFO:Declaring metric variables
2025-06-14 16:38:15,777:INFO:Defining Hyperparameters
2025-06-14 16:38:15,986:INFO:Tuning with n_jobs=-1
2025-06-14 16:38:15,989:INFO:Initializing RandomizedSearchCV
2025-06-14 16:38:20,416:INFO:Uploading results into container
2025-06-14 16:38:20,420:INFO:Uploading model into container now
2025-06-14 16:38:20,420:INFO:_master_model_container: 18
2025-06-14 16:38:20,422:INFO:_display_container: 5
2025-06-14 16:38:20,422:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-14 16:38:20,422:INFO:create_model() successfully completed......................................
2025-06-14 16:38:20,637:INFO:SubProcess create_model() end ==================================
2025-06-14 16:38:20,637:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.8095
2025-06-14 16:38:20,639:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.05, loss='log_loss', max_depth=6,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.0002, min_samples_leaf=3,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=120, n_iter_no_change=None,
                           random_state=42, subsample=0.65, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for F1 is 0.8061
2025-06-14 16:38:20,641:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2025-06-14 16:38:20,641:INFO:choose_better completed
2025-06-14 16:38:20,643:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-14 16:38:20,671:INFO:_master_model_container: 18
2025-06-14 16:38:20,671:INFO:_display_container: 4
2025-06-14 16:38:20,673:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-14 16:38:20,673:INFO:tune_model() successfully completed......................................
2025-06-14 16:38:20,922:INFO:Initializing finalize_model()
2025-06-14 16:38:20,923:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002027E6FEEF0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-14 16:38:20,923:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-14 16:38:20,942:INFO:Initializing create_model()
2025-06-14 16:38:20,943:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002027E6FEEF0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:38:20,943:INFO:Checking exceptions
2025-06-14 16:38:20,947:INFO:Importing libraries
2025-06-14 16:38:20,949:INFO:Copying training dataset
2025-06-14 16:38:20,951:INFO:Defining folds
2025-06-14 16:38:20,951:INFO:Declaring metric variables
2025-06-14 16:38:20,951:INFO:Importing untrained model
2025-06-14 16:38:20,953:INFO:Declaring custom model
2025-06-14 16:38:20,955:INFO:Gradient Boosting Classifier Imported successfully
2025-06-14 16:38:20,957:INFO:Cross validation set to False
2025-06-14 16:38:20,957:INFO:Fitting Model
2025-06-14 16:38:21,621:INFO:Uploading results into container
2025-06-14 16:38:21,622:INFO:Uploading model into container now
2025-06-14 16:38:21,622:INFO:_master_model_container: 17
2025-06-14 16:38:21,622:INFO:_display_container: 4
2025-06-14 16:38:21,626:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=0.7, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=-1, ...)
2025-06-14 16:38:21,626:INFO:create_model() successfully completed......................................
2025-06-14 16:38:21,852:INFO:SubProcess create_model() end ==================================
2025-06-14 16:38:21,854:INFO:choose_better activated
2025-06-14 16:38:21,862:INFO:SubProcess create_model() called ==================================
2025-06-14 16:38:21,866:INFO:Initializing create_model()
2025-06-14 16:38:21,866:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BDBC5ED40>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:38:21,866:INFO:Checking exceptions
2025-06-14 16:38:21,872:INFO:Importing libraries
2025-06-14 16:38:21,872:INFO:Copying training dataset
2025-06-14 16:38:21,907:INFO:Defining folds
2025-06-14 16:38:21,907:INFO:Declaring metric variables
2025-06-14 16:38:21,909:INFO:Importing untrained model
2025-06-14 16:38:21,909:INFO:Declaring custom model
2025-06-14 16:38:21,913:INFO:Extreme Gradient Boosting Imported successfully
2025-06-14 16:38:21,913:INFO:Starting cross validation
2025-06-14 16:38:21,915:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:38:27,401:INFO:Calculating mean and std
2025-06-14 16:38:27,403:INFO:Creating metrics dataframe
2025-06-14 16:38:27,409:INFO:Finalizing model
2025-06-14 16:38:31,888:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['isSchool', 'rental_count',
                                             'return_count', 'apart',
                                             'closest_hospital_dist',
                                             'closest_convenience_dist',
                                             'closest_culture_dist', 'age_20s',
                                             'age_30s', 'age_40s',
                                             'crosswalk_count',
                                             'closest_cross_dist', 'bus_count',
                                             'closest_bus_dist', 'subway_count',
                                             'clos...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-06-14 16:38:31,888:INFO:create_model() successfully completed......................................
2025-06-14 16:38:32,103:INFO:_master_model_container: 18
2025-06-14 16:38:32,103:INFO:_display_container: 4
2025-06-14 16:38:32,119:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['isSchool', 'rental_count',
                                             'return_count', 'apart',
                                             'closest_hospital_dist',
                                             'closest_convenience_dist',
                                             'closest_culture_dist', 'age_20s',
                                             'age_30s', 'age_40s',
                                             'crosswalk_count',
                                             'closest_cross_dist', 'bus_count',
                                             'closest_bus_dist', 'subway_count',
                                             'clos...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-06-14 16:38:32,119:INFO:finalize_model() successfully completed......................................
2025-06-14 16:38:32,362:INFO:Initializing predict_model()
2025-06-14 16:38:32,364:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002027E6FEEF0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['isSchool', 'rental_count',
                                             'return_count', 'apart',
                                             'closest_hospital_dist',
                                             'closest_convenience_dist',
                                             'closest_culture_dist', 'age_20s',
                                             'age_30s', 'age_40s',
                                             'crosswalk_count',
                                             'closest_cross_dist', 'bus_count',
                                             'closest_bus_dist', 'subway_count',
                                             'clos...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=42, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000202027F3D90>)
2025-06-14 16:38:32,364:INFO:Checking exceptions
2025-06-14 16:38:32,364:INFO:Preloading libraries
2025-06-14 16:38:32,368:INFO:Set up data.
2025-06-14 16:38:32,393:INFO:Set up index.
2025-06-14 16:38:40,065:INFO:Uploading results into container
2025-06-14 16:38:40,067:INFO:Uploading model into container now
2025-06-14 16:38:40,067:INFO:_master_model_container: 18
2025-06-14 16:38:40,069:INFO:_display_container: 5
2025-06-14 16:38:40,070:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1, ...)
2025-06-14 16:38:40,070:INFO:create_model() successfully completed......................................
2025-06-14 16:38:40,284:INFO:SubProcess create_model() end ==================================
2025-06-14 16:38:40,288:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=None, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1, ...) result for F1 is 0.7286
2025-06-14 16:38:40,292:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=0.7, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=-1, ...) result for F1 is 0.7307
2025-06-14 16:38:40,294:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=0.7, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=-1, ...) is best model
2025-06-14 16:38:40,294:INFO:choose_better completed
2025-06-14 16:38:40,318:INFO:_master_model_container: 18
2025-06-14 16:38:40,318:INFO:_display_container: 4
2025-06-14 16:38:40,320:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=0.7, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=-1, ...)
2025-06-14 16:38:40,322:INFO:tune_model() successfully completed......................................
2025-06-14 16:38:40,766:INFO:Initializing finalize_model()
2025-06-14 16:38:40,766:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BDBC5ED40>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=0.7, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=-1, ...), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-14 16:38:40,770:INFO:Finalizing XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=0.7, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=-1, ...)
2025-06-14 16:38:40,792:INFO:Initializing create_model()
2025-06-14 16:38:40,794:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BDBC5ED40>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              class_weight='balanced', colsample_bylevel=None,
              colsample_bynode=None, colsample_bytree=0.7, device='cpu',
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, feature_weights=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.4, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=6, max_leaves=None,
              min_child_weight=1, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=60, n_jobs=-1, ...), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:38:40,794:INFO:Checking exceptions
2025-06-14 16:38:40,800:INFO:Importing libraries
2025-06-14 16:38:40,800:INFO:Copying training dataset
2025-06-14 16:38:40,802:INFO:Defining folds
2025-06-14 16:38:40,804:INFO:Declaring metric variables
2025-06-14 16:38:40,804:INFO:Importing untrained model
2025-06-14 16:38:40,804:INFO:Declaring custom model
2025-06-14 16:38:40,808:INFO:Extreme Gradient Boosting Imported successfully
2025-06-14 16:38:40,810:INFO:Cross validation set to False
2025-06-14 16:38:40,812:INFO:Fitting Model
2025-06-14 16:38:48,829:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['isSchool', 'rental_count',
                                             'return_count', 'apart',
                                             'closest_hospital_dist',
                                             'closest_convenience_dist',
                                             'closest_culture_dist', 'age_20s',
                                             'age_30s', 'age_40s',
                                             'crosswalk_count',
                                             'closest_cross_dist', 'bus_count',
                                             'closest_bus_dist', 'subway_count',
                                             'clos...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=-1, ...))],
         verbose=False)
2025-06-14 16:38:48,829:INFO:create_model() successfully completed......................................
2025-06-14 16:38:49,040:INFO:_master_model_container: 18
2025-06-14 16:38:49,042:INFO:_display_container: 4
2025-06-14 16:38:49,063:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['isSchool', 'rental_count',
                                             'return_count', 'apart',
                                             'closest_hospital_dist',
                                             'closest_convenience_dist',
                                             'closest_culture_dist', 'age_20s',
                                             'age_30s', 'age_40s',
                                             'crosswalk_count',
                                             'closest_cross_dist', 'bus_count',
                                             'closest_bus_dist', 'subway_count',
                                             'clos...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=-1, ...))],
         verbose=False)
2025-06-14 16:38:49,063:INFO:finalize_model() successfully completed......................................
2025-06-14 16:38:49,294:INFO:Initializing predict_model()
2025-06-14 16:38:49,296:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000021BDBC5ED40>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['isSchool', 'rental_count',
                                             'return_count', 'apart',
                                             'closest_hospital_dist',
                                             'closest_convenience_dist',
                                             'closest_culture_dist', 'age_20s',
                                             'age_30s', 'age_40s',
                                             'crosswalk_count',
                                             'closest_cross_dist', 'bus_count',
                                             'closest_bus_dist', 'subway_count',
                                             'clos...
                               feature_types=None, feature_weights=None,
                               gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.4,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=6, max_leaves=None, min_child_weight=1,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=60, n_jobs=-1, ...))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000021BDF17AB90>)
2025-06-14 16:38:49,296:INFO:Checking exceptions
2025-06-14 16:38:49,296:INFO:Preloading libraries
2025-06-14 16:38:49,302:INFO:Set up data.
2025-06-14 16:38:49,336:INFO:Set up index.
2025-06-14 16:39:04,571:INFO:Calculating mean and std
2025-06-14 16:39:04,573:INFO:Creating metrics dataframe
2025-06-14 16:39:04,588:INFO:Finalizing model
2025-06-14 16:39:04,727:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016190 seconds.
2025-06-14 16:39:04,727:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-14 16:39:04,727:INFO:[LightGBM] [Info] Total Bins 4921
2025-06-14 16:39:04,729:INFO:[LightGBM] [Info] Number of data points in the train set: 10484, number of used features: 27
2025-06-14 16:39:04,729:INFO:[LightGBM] [Info] Start training from score -1.098612
2025-06-14 16:39:04,731:INFO:[LightGBM] [Info] Start training from score -1.098612
2025-06-14 16:39:04,731:INFO:[LightGBM] [Info] Start training from score -1.098612
2025-06-14 16:39:34,816:INFO:Uploading results into container
2025-06-14 16:39:34,818:INFO:Uploading model into container now
2025-06-14 16:39:34,841:INFO:_master_model_container: 16
2025-06-14 16:39:34,841:INFO:_display_container: 3
2025-06-14 16:39:34,843:INFO:LGBMClassifier(boosting_type='gbdt', class_weight='balanced',
               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-06-14 16:39:34,843:INFO:create_model() successfully completed......................................
2025-06-14 16:39:35,065:INFO:Initializing tune_model()
2025-06-14 16:39:35,065:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight='balanced',
               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001590BC53BE0>)
2025-06-14 16:39:35,067:INFO:Checking exceptions
2025-06-14 16:39:35,118:INFO:Copying training dataset
2025-06-14 16:39:35,145:INFO:Checking base model
2025-06-14 16:39:35,145:INFO:Base model : Light Gradient Boosting Machine
2025-06-14 16:39:35,157:INFO:Declaring metric variables
2025-06-14 16:39:35,167:INFO:Defining Hyperparameters
2025-06-14 16:39:35,376:INFO:Tuning with n_jobs=-1
2025-06-14 16:39:35,383:INFO:Initializing RandomizedSearchCV
2025-06-14 16:39:58,575:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2025-06-14 16:39:58,579:INFO:Hyperparameter search completed
2025-06-14 16:39:58,580:INFO:SubProcess create_model() called ==================================
2025-06-14 16:39:58,582:INFO:Initializing create_model()
2025-06-14 16:39:58,582:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A27382E290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight='balanced',
               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A275DB6170>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2025-06-14 16:39:58,583:INFO:Checking exceptions
2025-06-14 16:39:58,583:INFO:Importing libraries
2025-06-14 16:39:58,583:INFO:Copying training dataset
2025-06-14 16:39:58,607:INFO:Defining folds
2025-06-14 16:39:58,607:INFO:Declaring metric variables
2025-06-14 16:39:58,617:INFO:Importing untrained model
2025-06-14 16:39:58,617:INFO:Declaring custom model
2025-06-14 16:39:58,631:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-14 16:39:58,651:INFO:Starting cross validation
2025-06-14 16:39:58,652:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:40:29,218:INFO:Calculating mean and std
2025-06-14 16:40:29,224:INFO:Creating metrics dataframe
2025-06-14 16:40:29,241:INFO:Finalizing model
2025-06-14 16:40:29,268:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-06-14 16:40:29,270:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-06-14 16:40:29,270:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-14 16:40:29,276:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-06-14 16:40:29,276:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-06-14 16:40:29,276:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-14 16:40:29,295:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011095 seconds.
2025-06-14 16:40:29,295:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-06-14 16:40:29,295:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-06-14 16:40:29,297:INFO:[LightGBM] [Info] Total Bins 1686
2025-06-14 16:40:29,297:INFO:[LightGBM] [Info] Number of data points in the train set: 541, number of used features: 25
2025-06-14 16:40:29,299:INFO:[LightGBM] [Info] Start training from score -1.098612
2025-06-14 16:40:29,299:INFO:[LightGBM] [Info] Start training from score -1.098612
2025-06-14 16:40:29,299:INFO:[LightGBM] [Info] Start training from score -1.098612
2025-06-14 16:40:29,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:29,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:29,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:29,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:29,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:29,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:29,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:29,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:29,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:29,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:29,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:29,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:29,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:29,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:30,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:30,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:30,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:30,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:30,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:30,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:30,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:30,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:30,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:30,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:30,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:30,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:30,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:30,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:30,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:30,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:30,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:30,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:30,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:30,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:30,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:30,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:30,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:30,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:30,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:31,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:32,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:33,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,542:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:34,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,911:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:34,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:34,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,137:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:35,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,496:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:35,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,582:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:35,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,635:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:35,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,946:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:35,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:35,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,078:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:36,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,173:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:36,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,223:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:36,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,378:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:36,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,420:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:36,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,462:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:36,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,569:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:36,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,584:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:36,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:36,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,738:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:36,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,836:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:36,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,946:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:36,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:36,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,026:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:37,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:37,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,096:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:37,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,137:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:37,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,218:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:37,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,317:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:37,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,607:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:37,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,626:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:37,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:37,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:37,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,707:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:37,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,826:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:37,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,881:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:37,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,894:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:37,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,956:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:37,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:37,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,004:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:38,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,020:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:38,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,061:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:38,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,156:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-06-14 16:40:38,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:40:38,230:INFO:Uploading results into container
2025-06-14 16:40:38,232:INFO:Uploading model into container now
2025-06-14 16:40:38,233:INFO:_master_model_container: 17
2025-06-14 16:40:38,234:INFO:_display_container: 4
2025-06-14 16:40:38,235:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight='balanced', colsample_bytree=1.0,
               feature_fraction=0.8, importance_type='split', learning_rate=0.5,
               max_depth=-1, min_child_samples=11, min_child_weight=0.001,
               min_split_gain=0.3, n_estimators=250, n_jobs=-1, num_leaves=30,
               objective=None, random_state=42, reg_alpha=0.7, reg_lambda=2,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-06-14 16:40:38,237:INFO:create_model() successfully completed......................................
2025-06-14 16:40:38,464:INFO:SubProcess create_model() end ==================================
2025-06-14 16:40:38,464:INFO:choose_better activated
2025-06-14 16:40:38,475:INFO:SubProcess create_model() called ==================================
2025-06-14 16:40:38,479:INFO:Initializing create_model()
2025-06-14 16:40:38,479:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A27382E290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight='balanced',
               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:40:38,479:INFO:Checking exceptions
2025-06-14 16:40:38,485:INFO:Importing libraries
2025-06-14 16:40:38,485:INFO:Copying training dataset
2025-06-14 16:40:38,507:INFO:Defining folds
2025-06-14 16:40:38,507:INFO:Declaring metric variables
2025-06-14 16:40:38,507:INFO:Importing untrained model
2025-06-14 16:40:38,507:INFO:Declaring custom model
2025-06-14 16:40:38,511:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-14 16:40:38,511:INFO:Starting cross validation
2025-06-14 16:40:38,516:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:41:08,176:INFO:Calculating mean and std
2025-06-14 16:41:08,178:INFO:Creating metrics dataframe
2025-06-14 16:41:08,186:INFO:Finalizing model
2025-06-14 16:41:08,241:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011458 seconds.
2025-06-14 16:41:08,241:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-06-14 16:41:08,241:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-06-14 16:41:08,241:INFO:[LightGBM] [Info] Total Bins 1682
2025-06-14 16:41:08,243:INFO:[LightGBM] [Info] Number of data points in the train set: 541, number of used features: 24
2025-06-14 16:41:08,243:INFO:[LightGBM] [Info] Start training from score -1.098612
2025-06-14 16:41:08,243:INFO:[LightGBM] [Info] Start training from score -1.098612
2025-06-14 16:41:08,243:INFO:[LightGBM] [Info] Start training from score -1.098612
2025-06-14 16:41:08,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:08,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:08,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:08,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:08,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:08,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:08,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:08,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:08,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:09,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:09,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:09,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:09,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:09,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:09,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:09,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:09,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:09,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:09,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:09,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:09,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:10,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:10,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:10,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:10,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:10,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:10,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:10,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:10,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:10,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:10,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:10,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:11,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:11,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:11,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:11,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:11,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:11,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:11,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:11,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:11,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:11,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:11,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:11,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:11,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:12,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:12,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:12,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:12,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:12,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:12,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:12,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:12,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:12,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:12,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:12,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:12,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:12,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:12,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:13,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:13,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:13,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:13,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:13,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:13,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:13,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:13,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:13,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:13,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:13,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:13,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:13,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:13,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:14,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:14,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:14,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:14,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:14,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:14,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:14,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:14,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:14,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:14,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:14,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:14,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:14,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:14,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:15,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:15,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:15,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:15,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:15,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:15,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:15,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:15,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:15,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:15,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:15,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:15,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:15,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:16,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:16,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:16,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:16,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:16,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:16,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:16,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:16,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:16,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:16,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:16,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:16,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:17,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:17,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:17,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:17,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:17,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:17,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:17,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:17,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:17,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:17,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:17,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:17,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:18,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:18,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:18,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:18,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:18,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:18,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:18,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:18,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:18,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:18,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:18,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:18,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:19,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:19,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:19,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:19,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:19,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:19,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:19,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:19,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:19,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:19,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:19,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:19,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:19,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:20,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:20,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:20,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:20,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:20,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:20,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:20,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:20,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:20,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:20,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:20,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:20,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:20,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:21,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:21,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:21,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:21,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:21,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:21,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:21,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:21,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:21,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:21,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:21,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:21,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:21,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:22,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:22,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:22,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:22,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:22,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:22,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:22,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:22,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:22,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:22,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:22,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:23,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:23,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:23,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:23,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:23,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:23,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:23,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:23,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:23,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:23,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:23,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:23,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:24,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:24,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:24,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:24,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:24,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:24,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:24,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:24,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:24,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:25,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:25,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:25,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:25,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:25,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:25,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:25,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:25,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:25,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:25,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:26,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:26,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:26,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:26,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:26,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:26,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:26,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:26,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:26,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:26,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:26,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:26,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:27,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:27,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:27,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:27,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:27,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:27,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:27,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:27,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:27,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:27,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:27,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:28,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:28,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:28,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:28,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:28,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:28,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:28,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:28,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:28,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:28,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:28,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:28,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:29,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:29,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:29,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:29,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:29,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:29,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:29,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:29,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:29,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:29,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:29,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:29,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:30,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:30,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:30,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:30,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:30,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:30,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:30,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:30,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:30,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:30,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:30,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:30,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:31,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:31,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:31,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:31,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:31,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:31,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:31,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:31,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:31,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:31,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:31,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:32,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:32,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:32,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:32,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:32,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:32,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:32,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:32,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:32,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:32,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:32,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:32,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:33,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:33,069:INFO:Uploading results into container
2025-06-14 16:41:33,072:INFO:Uploading model into container now
2025-06-14 16:41:33,073:INFO:_master_model_container: 18
2025-06-14 16:41:33,073:INFO:_display_container: 5
2025-06-14 16:41:33,075:INFO:LGBMClassifier(boosting_type='gbdt', class_weight='balanced',
               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-06-14 16:41:33,075:INFO:create_model() successfully completed......................................
2025-06-14 16:41:33,318:INFO:SubProcess create_model() end ==================================
2025-06-14 16:41:33,322:INFO:LGBMClassifier(boosting_type='gbdt', class_weight='balanced',
               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.6924
2025-06-14 16:41:33,326:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight='balanced', colsample_bytree=1.0,
               feature_fraction=0.8, importance_type='split', learning_rate=0.5,
               max_depth=-1, min_child_samples=11, min_child_weight=0.001,
               min_split_gain=0.3, n_estimators=250, n_jobs=-1, num_leaves=30,
               objective=None, random_state=42, reg_alpha=0.7, reg_lambda=2,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.6557
2025-06-14 16:41:33,326:INFO:LGBMClassifier(boosting_type='gbdt', class_weight='balanced',
               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2025-06-14 16:41:33,326:INFO:choose_better completed
2025-06-14 16:41:33,327:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-14 16:41:33,357:INFO:_master_model_container: 18
2025-06-14 16:41:33,359:INFO:_display_container: 4
2025-06-14 16:41:33,360:INFO:LGBMClassifier(boosting_type='gbdt', class_weight='balanced',
               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-06-14 16:41:33,362:INFO:tune_model() successfully completed......................................
2025-06-14 16:41:33,632:INFO:Initializing finalize_model()
2025-06-14 16:41:33,632:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A27382E290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight='balanced',
               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-14 16:41:33,635:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight='balanced',
               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-06-14 16:41:33,653:INFO:Initializing create_model()
2025-06-14 16:41:33,654:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A27382E290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight='balanced',
               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:41:33,654:INFO:Checking exceptions
2025-06-14 16:41:33,658:INFO:Importing libraries
2025-06-14 16:41:33,660:INFO:Copying training dataset
2025-06-14 16:41:33,662:INFO:Defining folds
2025-06-14 16:41:33,662:INFO:Declaring metric variables
2025-06-14 16:41:33,662:INFO:Importing untrained model
2025-06-14 16:41:33,662:INFO:Declaring custom model
2025-06-14 16:41:33,668:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-14 16:41:33,670:INFO:Cross validation set to False
2025-06-14 16:41:33,670:INFO:Fitting Model
2025-06-14 16:41:33,726:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013856 seconds.
2025-06-14 16:41:33,728:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-06-14 16:41:33,728:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-06-14 16:41:33,728:INFO:[LightGBM] [Info] Total Bins 2261
2025-06-14 16:41:33,730:INFO:[LightGBM] [Info] Number of data points in the train set: 773, number of used features: 24
2025-06-14 16:41:33,730:INFO:[LightGBM] [Info] Start training from score -1.098612
2025-06-14 16:41:33,730:INFO:[LightGBM] [Info] Start training from score -1.098612
2025-06-14 16:41:33,730:INFO:[LightGBM] [Info] Start training from score -1.098612
2025-06-14 16:41:33,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:34,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:34,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:34,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:36,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:36,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:36,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:36,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:37,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:37,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:37,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:37,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:38,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:38,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:38,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:39,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:39,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:40,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:41,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:41,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:42,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:42,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:43,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:44,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:44,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:44,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:45,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:45,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:48,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:51,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:51,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:53,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:54,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:54,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:55,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:55,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:56,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:57,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:58,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:41:59,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:42:00,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:42:01,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:42:03,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:42:03,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:42:04,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:42:05,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:42:05,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:42:06,142:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['isSchool', 'rental_count',
                                             'return_count', 'apart',
                                             'closest_hospital_dist',
                                             'closest_convenience_dist',
                                             'closest_culture_dist', 'age_20s',
                                             'age_30s', 'age_40s',
                                             'crosswalk_count',
                                             'closest_cross_dist', 'bus_count',
                                             'closest_bus_dist', 'subway_count',
                                             'clos...
                 LGBMClassifier(boosting_type='gbdt', class_weight='balanced',
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-06-14 16:42:06,142:INFO:create_model() successfully completed......................................
2025-06-14 16:42:06,360:INFO:_master_model_container: 18
2025-06-14 16:42:06,362:INFO:_display_container: 4
2025-06-14 16:42:06,378:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['isSchool', 'rental_count',
                                             'return_count', 'apart',
                                             'closest_hospital_dist',
                                             'closest_convenience_dist',
                                             'closest_culture_dist', 'age_20s',
                                             'age_30s', 'age_40s',
                                             'crosswalk_count',
                                             'closest_cross_dist', 'bus_count',
                                             'closest_bus_dist', 'subway_count',
                                             'clos...
                 LGBMClassifier(boosting_type='gbdt', class_weight='balanced',
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-06-14 16:42:06,378:INFO:finalize_model() successfully completed......................................
2025-06-14 16:42:06,588:INFO:Initializing predict_model()
2025-06-14 16:42:06,588:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A27382E290>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['isSchool', 'rental_count',
                                             'return_count', 'apart',
                                             'closest_hospital_dist',
                                             'closest_convenience_dist',
                                             'closest_culture_dist', 'age_20s',
                                             'age_30s', 'age_40s',
                                             'crosswalk_count',
                                             'closest_cross_dist', 'bus_count',
                                             'closest_bus_dist', 'subway_count',
                                             'clos...
                 LGBMClassifier(boosting_type='gbdt', class_weight='balanced',
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=42,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001A275D27C70>)
2025-06-14 16:42:06,590:INFO:Checking exceptions
2025-06-14 16:42:06,590:INFO:Preloading libraries
2025-06-14 16:42:06,594:INFO:Set up data.
2025-06-14 16:42:06,624:INFO:Set up index.
2025-06-14 16:43:06,935:INFO:best_params: {'actual_estimator__reg_lambda': 2, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.5, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 1, 'actual_estimator__bagging_fraction': 0.5}
2025-06-14 16:43:06,937:INFO:Hyperparameter search completed
2025-06-14 16:43:06,937:INFO:SubProcess create_model() called ==================================
2025-06-14 16:43:06,939:INFO:Initializing create_model()
2025-06-14 16:43:06,939:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001590BC53BE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight='balanced',
               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001590E4C6950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 2, 'reg_alpha': 0.7, 'num_leaves': 30, 'n_estimators': 250, 'min_split_gain': 0.3, 'min_child_samples': 11, 'learning_rate': 0.5, 'feature_fraction': 0.8, 'bagging_freq': 1, 'bagging_fraction': 0.5})
2025-06-14 16:43:06,939:INFO:Checking exceptions
2025-06-14 16:43:06,939:INFO:Importing libraries
2025-06-14 16:43:06,941:INFO:Copying training dataset
2025-06-14 16:43:06,975:INFO:Defining folds
2025-06-14 16:43:06,975:INFO:Declaring metric variables
2025-06-14 16:43:06,983:INFO:Importing untrained model
2025-06-14 16:43:06,984:INFO:Declaring custom model
2025-06-14 16:43:06,993:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-14 16:43:07,007:INFO:Starting cross validation
2025-06-14 16:43:07,009:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:43:37,014:INFO:Calculating mean and std
2025-06-14 16:43:37,018:INFO:Creating metrics dataframe
2025-06-14 16:43:37,029:INFO:Finalizing model
2025-06-14 16:43:37,066:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-06-14 16:43:37,066:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-06-14 16:43:37,066:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-14 16:43:37,084:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-06-14 16:43:37,085:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-06-14 16:43:37,085:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-14 16:43:37,092:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004106 seconds.
2025-06-14 16:43:37,092:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-14 16:43:37,093:INFO:[LightGBM] [Info] Total Bins 4921
2025-06-14 16:43:37,094:INFO:[LightGBM] [Info] Number of data points in the train set: 10484, number of used features: 27
2025-06-14 16:43:37,095:INFO:[LightGBM] [Info] Start training from score -1.098612
2025-06-14 16:43:37,095:INFO:[LightGBM] [Info] Start training from score -1.098612
2025-06-14 16:43:37,096:INFO:[LightGBM] [Info] Start training from score -1.098612
2025-06-14 16:43:39,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:39,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:43:40,792:INFO:Uploading results into container
2025-06-14 16:43:40,794:INFO:Uploading model into container now
2025-06-14 16:43:40,794:INFO:_master_model_container: 17
2025-06-14 16:43:40,795:INFO:_display_container: 4
2025-06-14 16:43:40,796:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight='balanced', colsample_bytree=1.0,
               feature_fraction=0.8, importance_type='split', learning_rate=0.5,
               max_depth=-1, min_child_samples=11, min_child_weight=0.001,
               min_split_gain=0.3, n_estimators=250, n_jobs=-1, num_leaves=30,
               objective=None, random_state=42, reg_alpha=0.7, reg_lambda=2,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-06-14 16:43:40,797:INFO:create_model() successfully completed......................................
2025-06-14 16:43:40,949:INFO:SubProcess create_model() end ==================================
2025-06-14 16:43:40,949:INFO:choose_better activated
2025-06-14 16:43:40,957:INFO:SubProcess create_model() called ==================================
2025-06-14 16:43:40,959:INFO:Initializing create_model()
2025-06-14 16:43:40,959:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001590BC53BE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight='balanced',
               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:43:40,959:INFO:Checking exceptions
2025-06-14 16:43:40,963:INFO:Importing libraries
2025-06-14 16:43:40,963:INFO:Copying training dataset
2025-06-14 16:43:40,994:INFO:Defining folds
2025-06-14 16:43:40,995:INFO:Declaring metric variables
2025-06-14 16:43:40,995:INFO:Importing untrained model
2025-06-14 16:43:40,995:INFO:Declaring custom model
2025-06-14 16:43:40,997:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-14 16:43:40,998:INFO:Starting cross validation
2025-06-14 16:43:41,000:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-14 16:44:01,166:INFO:Calculating mean and std
2025-06-14 16:44:01,168:INFO:Creating metrics dataframe
2025-06-14 16:44:01,171:INFO:Finalizing model
2025-06-14 16:44:01,223:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004257 seconds.
2025-06-14 16:44:01,223:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-14 16:44:01,224:INFO:[LightGBM] [Info] Total Bins 4921
2025-06-14 16:44:01,224:INFO:[LightGBM] [Info] Number of data points in the train set: 10484, number of used features: 27
2025-06-14 16:44:01,226:INFO:[LightGBM] [Info] Start training from score -1.098612
2025-06-14 16:44:01,226:INFO:[LightGBM] [Info] Start training from score -1.098612
2025-06-14 16:44:01,226:INFO:[LightGBM] [Info] Start training from score -1.098612
2025-06-14 16:44:03,607:INFO:Uploading results into container
2025-06-14 16:44:03,609:INFO:Uploading model into container now
2025-06-14 16:44:03,610:INFO:_master_model_container: 18
2025-06-14 16:44:03,610:INFO:_display_container: 5
2025-06-14 16:44:03,612:INFO:LGBMClassifier(boosting_type='gbdt', class_weight='balanced',
               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-06-14 16:44:03,612:INFO:create_model() successfully completed......................................
2025-06-14 16:44:03,765:INFO:SubProcess create_model() end ==================================
2025-06-14 16:44:03,767:INFO:LGBMClassifier(boosting_type='gbdt', class_weight='balanced',
               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.7232
2025-06-14 16:44:03,769:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight='balanced', colsample_bytree=1.0,
               feature_fraction=0.8, importance_type='split', learning_rate=0.5,
               max_depth=-1, min_child_samples=11, min_child_weight=0.001,
               min_split_gain=0.3, n_estimators=250, n_jobs=-1, num_leaves=30,
               objective=None, random_state=42, reg_alpha=0.7, reg_lambda=2,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.742
2025-06-14 16:44:03,769:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight='balanced', colsample_bytree=1.0,
               feature_fraction=0.8, importance_type='split', learning_rate=0.5,
               max_depth=-1, min_child_samples=11, min_child_weight=0.001,
               min_split_gain=0.3, n_estimators=250, n_jobs=-1, num_leaves=30,
               objective=None, random_state=42, reg_alpha=0.7, reg_lambda=2,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2025-06-14 16:44:03,771:INFO:choose_better completed
2025-06-14 16:44:03,794:INFO:_master_model_container: 18
2025-06-14 16:44:03,795:INFO:_display_container: 4
2025-06-14 16:44:03,796:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight='balanced', colsample_bytree=1.0,
               feature_fraction=0.8, importance_type='split', learning_rate=0.5,
               max_depth=-1, min_child_samples=11, min_child_weight=0.001,
               min_split_gain=0.3, n_estimators=250, n_jobs=-1, num_leaves=30,
               objective=None, random_state=42, reg_alpha=0.7, reg_lambda=2,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-06-14 16:44:03,796:INFO:tune_model() successfully completed......................................
2025-06-14 16:44:03,963:INFO:Initializing finalize_model()
2025-06-14 16:44:03,963:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001590BC53BE0>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight='balanced', colsample_bytree=1.0,
               feature_fraction=0.8, importance_type='split', learning_rate=0.5,
               max_depth=-1, min_child_samples=11, min_child_weight=0.001,
               min_split_gain=0.3, n_estimators=250, n_jobs=-1, num_leaves=30,
               objective=None, random_state=42, reg_alpha=0.7, reg_lambda=2,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-06-14 16:44:03,965:INFO:Finalizing LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight='balanced', colsample_bytree=1.0,
               feature_fraction=0.8, importance_type='split', learning_rate=0.5,
               max_depth=-1, min_child_samples=11, min_child_weight=0.001,
               min_split_gain=0.3, n_estimators=250, n_jobs=-1, num_leaves=30,
               objective=None, random_state=42, reg_alpha=0.7, reg_lambda=2,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-06-14 16:44:03,988:INFO:Initializing create_model()
2025-06-14 16:44:03,988:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001590BC53BE0>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=1, boosting_type='gbdt',
               class_weight='balanced', colsample_bytree=1.0,
               feature_fraction=0.8, importance_type='split', learning_rate=0.5,
               max_depth=-1, min_child_samples=11, min_child_weight=0.001,
               min_split_gain=0.3, n_estimators=250, n_jobs=-1, num_leaves=30,
               objective=None, random_state=42, reg_alpha=0.7, reg_lambda=2,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-06-14 16:44:03,990:INFO:Checking exceptions
2025-06-14 16:44:03,993:INFO:Importing libraries
2025-06-14 16:44:03,993:INFO:Copying training dataset
2025-06-14 16:44:03,996:INFO:Defining folds
2025-06-14 16:44:03,996:INFO:Declaring metric variables
2025-06-14 16:44:03,997:INFO:Importing untrained model
2025-06-14 16:44:03,997:INFO:Declaring custom model
2025-06-14 16:44:03,999:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-14 16:44:04,000:INFO:Cross validation set to False
2025-06-14 16:44:04,001:INFO:Fitting Model
2025-06-14 16:44:04,039:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-06-14 16:44:04,041:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-06-14 16:44:04,041:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-14 16:44:04,067:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-06-14 16:44:04,067:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-06-14 16:44:04,067:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2025-06-14 16:44:04,074:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004757 seconds.
2025-06-14 16:44:04,075:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-06-14 16:44:04,075:INFO:[LightGBM] [Info] Total Bins 4931
2025-06-14 16:44:04,075:INFO:[LightGBM] [Info] Number of data points in the train set: 14978, number of used features: 27
2025-06-14 16:44:04,076:INFO:[LightGBM] [Info] Start training from score -1.098612
2025-06-14 16:44:04,077:INFO:[LightGBM] [Info] Start training from score -1.098612
2025-06-14 16:44:04,077:INFO:[LightGBM] [Info] Start training from score -1.098612
2025-06-14 16:44:07,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:07,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-06-14 16:44:08,958:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['isSchool', 'rental_count',
                                             'return_count', 'apart',
                                             'closest_hospital_dist',
                                             'closest_convenience_dist',
                                             'closest_culture_dist', 'age_20s',
                                             'age_30s', 'age_40s',
                                             'crosswalk_count',
                                             'closest_cross_dist', 'bus_count',
                                             'closest_bus_dist', 'subway_count',
                                             'clos...
                                boosting_type='gbdt', class_weight='balanced',
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.5,
                                max_depth=-1, min_child_samples=11,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=250, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.7,
                                reg_lambda=2, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-06-14 16:44:08,960:INFO:create_model() successfully completed......................................
2025-06-14 16:44:09,128:INFO:_master_model_container: 18
2025-06-14 16:44:09,128:INFO:_display_container: 4
2025-06-14 16:44:09,142:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['isSchool', 'rental_count',
                                             'return_count', 'apart',
                                             'closest_hospital_dist',
                                             'closest_convenience_dist',
                                             'closest_culture_dist', 'age_20s',
                                             'age_30s', 'age_40s',
                                             'crosswalk_count',
                                             'closest_cross_dist', 'bus_count',
                                             'closest_bus_dist', 'subway_count',
                                             'clos...
                                boosting_type='gbdt', class_weight='balanced',
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.5,
                                max_depth=-1, min_child_samples=11,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=250, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.7,
                                reg_lambda=2, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-06-14 16:44:09,142:INFO:finalize_model() successfully completed......................................
2025-06-14 16:44:09,307:INFO:Initializing predict_model()
2025-06-14 16:44:09,307:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001590BC53BE0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['isSchool', 'rental_count',
                                             'return_count', 'apart',
                                             'closest_hospital_dist',
                                             'closest_convenience_dist',
                                             'closest_culture_dist', 'age_20s',
                                             'age_30s', 'age_40s',
                                             'crosswalk_count',
                                             'closest_cross_dist', 'bus_count',
                                             'closest_bus_dist', 'subway_count',
                                             'clos...
                                boosting_type='gbdt', class_weight='balanced',
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.5,
                                max_depth=-1, min_child_samples=11,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=250, n_jobs=-1, num_leaves=30,
                                objective=None, random_state=42, reg_alpha=0.7,
                                reg_lambda=2, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001590E558EE0>)
2025-06-14 16:44:09,307:INFO:Checking exceptions
2025-06-14 16:44:09,307:INFO:Preloading libraries
2025-06-14 16:44:09,313:INFO:Set up data.
2025-06-14 16:44:09,333:INFO:Set up index.
